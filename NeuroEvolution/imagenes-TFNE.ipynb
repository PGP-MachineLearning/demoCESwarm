{"cells":[{"cell_type":"markdown","metadata":{"id":"1Tu5MvS864Vv"},"source":["#Demo NeuroEvolution usando Tensorflow-Neuroevolution framework (TFNE) para generar una red ConvNet que pueda aprender a clasificar en base a imágenes\n","\n","Con TFNE se busca optimizar la topoloǵía de la red (definda a través de conceptos de \"blueprints\" y \"modules\") y sus pesos de las conexiones para un cojunto de datos. Para esto último, la red es entrenada con los datos suministrados como si fuera una red normal usando las mismas funciones de Keras / TensorFlow. Por lo tanto  la red generada no es compatible con modelos creados con esa tecnología.\n","\n","- Nota:  se recomienda ejecutar con GPU para hacer la ejecución más rápido pero pueden producirse errores de sesión por falta de memoria RAM si son demasiadas imágenes o muy grandes.\n","\n","Fuente TFNE: https://github.com/PaulPauls/Tensorflow-Neuroevolution\n","\n","Explicación de conceptos en: https://tfne.readthedocs.io/en/latest/codeepneat/codeepneat-overview.html"]},{"cell_type":"code","source":["#@title Cambia a Keras 2 para compatbilidad con la librería TFNE\n","import os\n","os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n","\n","!pip install tf-keras~=2.16"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"5s8yc_KpWxfU","executionInfo":{"status":"ok","timestamp":1722958997004,"user_tz":180,"elapsed":8052,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}},"outputId":"fc6be8bd-5257-4529-e649-a3b13ae17b5c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tf-keras~=2.16 in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: tensorflow<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tf-keras~=2.16) (2.17.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (0.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (2.17.0)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (3.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras~=2.16) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf-keras~=2.16) (0.43.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras~=2.16) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras~=2.16) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras~=2.16) (0.12.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras~=2.16) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras~=2.16) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras~=2.16) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras~=2.16) (2024.7.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras~=2.16) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras~=2.16) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras~=2.16) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras~=2.16) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras~=2.16) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras~=2.16) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras~=2.16) (0.1.2)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","id":"i79ux8zd64wv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722959025887,"user_tz":180,"elapsed":28901,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}},"outputId":"a902aadb-dbb2-49a1-c9a6-abb61ad7a9d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tfne\n","  Downloading tfne-0.21.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from tfne) (2.17.0)\n","Collecting ray (from tfne)\n","  Downloading ray-2.34.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from tfne) (0.20.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tfne) (3.7.1)\n","Collecting PyQt5 (from tfne)\n","  Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from tfne) (1.4.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (0.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (2.17.0)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (3.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (1.26.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (2.8.2)\n","Collecting PyQt5-sip<13,>=12.15 (from PyQt5->tfne)\n","  Downloading PyQt5_sip-12.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (421 bytes)\n","Collecting PyQt5-Qt5<5.16.0,>=5.15.2 (from PyQt5->tfne)\n","  Downloading PyQt5_Qt5-5.15.14-py3-none-manylinux2014_x86_64.whl.metadata (536 bytes)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (8.1.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (3.15.4)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (4.23.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (1.0.8)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (6.0.1)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (1.4.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->tfne) (0.43.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.0.0->tfne) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.0.0->tfne) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.0.0->tfne) (0.12.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.0.0->tfne) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.0.0->tfne) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.0.0->tfne) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.0.0->tfne) (2024.7.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.0.0->tfne) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.0.0->tfne) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.0.0->tfne) (3.0.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->tfne) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->tfne) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->tfne) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->tfne) (0.19.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow>=2.0.0->tfne) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.0.0->tfne) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.0.0->tfne) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow>=2.0.0->tfne) (0.1.2)\n","Downloading tfne-0.21.1-py3-none-any.whl (125 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.0/125.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl (8.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ray-2.34.0-cp310-cp310-manylinux2014_x86_64.whl (64.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyQt5_Qt5-5.15.14-py3-none-manylinux2014_x86_64.whl (60.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyQt5_sip-12.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.whl (270 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.5/270.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyQt5-Qt5, PyQt5-sip, PyQt5, ray, tfne\n","Successfully installed PyQt5-5.15.11 PyQt5-Qt5-5.15.14 PyQt5-sip-12.15.0 ray-2.34.0 tfne-0.21.1\n"]}],"source":["#@title Instalar TFNE\n","!pip install tfne\n","\n","###!git clone https://github.com/PaulPauls/Tensorflow-Neuroevolution\n","###%cd Tensorflow-Neuroevolution\n","###!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"b4oaPcXw-uzT","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722959033076,"user_tz":180,"elapsed":7209,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}},"outputId":"f00872e7-4e06-4136-e59d-3cb3527dcd4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Librerías cargadas\n"]}],"source":["#@title Librerías a usar\n","from __future__ import annotations\n","from absl import app, flags, logging\n","\n","import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","import os\n","import csv\n","\n","import tfne\n","from tfne.environments import BaseEnvironment\n","from tfne.helper_functions import read_option_from_config\n","\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","import ipywidgets as widgets\n","from ipywidgets import Box, Layout\n","import random\n","import math\n","\n","print(\"Librerías cargadas\")"]},{"cell_type":"markdown","source":["##Imágenes:"],"metadata":{"id":"3yXLEB3GClPR"}},{"cell_type":"code","metadata":{"id":"ysaIl300nDud","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722959534166,"user_tz":180,"elapsed":12003,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}},"outputId":"b06036ef-667b-400b-f398-01bde156c8a9"},"source":["#@title Acceder al Drive\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# directorio local en Google Drive\n","path = 'gdrive/My Drive/IA/demoML/imagenes/NUMEROS' #@param {type:\"string\"}\n","path_entrenamiento = '/train'  #@param {type:\"string\"}\n","path_prueba = '/test'  #@param {type:\"string\"}\n","\n","imagPath_train = path + path_entrenamiento\n","imagPath_test = path + path_prueba"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"uYz8mV4SnJ4O","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1722959714926,"user_tz":180,"elapsed":180763,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}},"outputId":"3d0b977b-87d4-47e3-f035-fc425760b809"},"source":["#@title Cargar imágenes\n","\n","#@markdown ### Parámetros para imágenes:\n","imagen_ancho =  32#@param {type:\"integer\"}\n","imagen_largo =  32#@param {type:\"integer\"}\n","imagen_color = True #@param {type:\"boolean\"}\n","\n","# tamaño de las imágenes\n","if imagen_ancho<=10:\n","  imagen_largo = 10\n","if imagen_largo<=10:\n","  imagen_largo = 10\n","IMAGE_SHAPE = (imagen_ancho, imagen_largo, (3 if imagen_color else 1))\n","\n","# define función para cargar las imágenes\n","def cargarImagenes(imagPath):\n","  classes_ori = []\n","  images_ori = []\n","\n","  all_dirs = os.listdir( imagPath )\n","  for each_dir in all_dirs:\n","\n","      auxiPath = imagPath + '/' + each_dir\n","      imagFN  = os.listdir( auxiPath )\n","      for each_imagFN in imagFN:\n","\n","\n","            # abre la imagen\n","            imag = Image.open(auxiPath + \"/\" + each_imagFN)\n","\n","            # ajusta el tamaño\n","            if IMAGE_SHAPE[2]==1:\n","              tipoImage = 'L'\n","            else:\n","              tipoImage = 'RGB'\n","            imag = imag.convert(tipoImage)\n","            imag = imag.resize((IMAGE_SHAPE[0], IMAGE_SHAPE[1]), Image.LANCZOS)\n","\n","            # transforma a un vector de nros\n","            arImag = np.array(imag)\n","\n","            # agrega a los vectores\n","            classes_ori.append( each_dir )\n","            images_ori.append( arImag )\n","\n","  return classes_ori, images_ori, tipoImage\n","\n","# carga las imagenes de entrenamiento\n","classes_train, images_train, tipoImage_train = cargarImagenes(imagPath_train)\n","print(\"> Para Entrenamiento: \")\n","print(\"- Clases cargadas: \", len(np.unique(classes_train)))\n","print(\"- Imágenes cargadas: \", len(classes_train))\n","\n","if len(classes_train)>0:\n","  print(\"- Ejemplo \", classes_train[0], \" \", images_train[0].shape, \": \")\n","  display( Image.fromarray(images_train[0], tipoImage_train) )\n","\n","# carga las imagenes de prueba\n","classes_test, images_test, tipoImage_test = cargarImagenes(imagPath_test)\n","print(\"\\n\\n> Para Prueba: \")\n","print(\"- Clases cargadas: \", len(np.unique(classes_test)))\n","print(\"- Imágenes cargadas: \", len(images_test))\n","\n","if len(classes_test)>0:\n","  print(\"- Ejemplo \", classes_test[0], \" \", images_test[0].shape, \": \")\n","  display( Image.fromarray(images_test[0], tipoImage_test) )"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["> Para Entrenamiento: \n","- Clases cargadas:  10\n","- Imágenes cargadas:  240\n","- Ejemplo  7   (32, 32, 3) : \n"]},{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=32x32>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAACS0lEQVR4nMVWu6rqQBTd49uAghYRFMFGsREEO0VB/Bt7G8Ff8BNsxFLsBRtBsbD3BRaWPlFQg8nMPsW+V+TexCQHD2dVycyevdZe82SICD8Jl1GHXWLGmH77r1VwuVw454yZKKAAh8MRCAQcDodOwD/jEZExxjkvFAqr1eoNwWt7OBwej8eyLNNwSxVst9vj8fhG+ysURdE0TbfLkECW5fP5bFSBEMLn8+12O8aYpmnpdDoYDP4vH95MstEcUEa/39/pdKrVKuc8Go2ORqNEIiGE0JkG/BZms1kwGGSMeTye4XCIiJqm6UYaEgg9cM5VVb1er5lMhvQ1m01EfDweRnnsVUAya7UaZa9UKoioquqbITYIKPt0OnW5XE6nU5KkxWKBiJzzzxBQonK5TPIbjQaaybdBQPK73S4tpFgsdjqdOOdCiM8QCCEej0c2m6WVTnNrtHJsE5APvV6P5EcikePxSOvqMwRP90l+vV5HC+5bJSAfJpMJZfd6vcvlkvaEFQKdA1YX7XYbEQGgVColk0lE1D2cdfCen1y+3W6JRILiW62WEMKiP2hqEfkzGAwouyRJm80GzTbXK0zKREQA6Pf79JvL5eLxOFr3B8Akzul0AsB4PKbfYrEIAJxzi9lNCBCRMXY6nebzObXk83kwfkB8hwAANpvNfr8HALfbnUqlPk+wXq/h7/kTi8XsEhjeyU+Cw+FAH+FwWJKkTxIQNE0LhUIAkE6nAUD/4jWG+ctOUZT7/Q4AXq+XKrCF33s6vuIpwpb7f4b8dAVfMc+89oUv4XIAAAAASUVORK5CYII=\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","> Para Prueba: \n","- Clases cargadas:  10\n","- Imágenes cargadas:  60\n","- Ejemplo  6   (32, 32, 3) : \n"]},{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=32x32>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAADdElEQVR4nLVWO0trQRCe3fNQOaSITUQDRgsLYyxEtBJLRRAJghYpVLAQf4BNCgW1EVII2mtKLUTEzkfpo0whNgpq8AGiRHyck+zu3GKu54Zrzrkmcrc67Jn5vtmZnW+WISL8z6X/xNkNjjHmZcMrwFVKCSEQkX0upZSXMSsrRYiIiJz/Duvl5UUpFQgENE37h893FkWNiGdnZzMzM62trYZhBIPBaDQ6OzurlJJSfvX6LkGhUEDEu7u78fFxANB1vaurq7u72zRNAJiamnJtKiEgz52dnXA4DABzc3NPT0/06+LiYmhoaG9vr/iI5RGQ2+rqKiU6nU7TvpTSzUnJ5HyLgNDX19epYGNjY4joOE4xtFLKB8GPgNBPT09N02SMWZZ1eXnpVcyyCQjIcZz29nYAYIwlEgn0SHQlBAS0vLwMAIZhAMD+/r6U0rZtIYSUUghRKBT88+NJQG4fHx+NjY0kA01NTa+vrz7GXqu0FkkpdV3f3d29uroyTTOfz/f29lqWlc1mNzc3Dw8P39/fQ6FQX19fIpHQNA0RPeXIJz8jIyOMsaqqKgDY2NjY2tr66t7T03N7e+tT+RIEdOS3tzdqK8aYYRgDAwOc89HR0YWFhXg8ToUh7v7+fvRuhRIEFP7JyYkrlqRu29vbrs3i4iIAaJqm6zoAHB0d4fc7mYQhnU4XQ0xOTiKi4zjUZfl8vqGhgc7BGEulUuihRZ7z4Pr6mvIjpQSAiYkJpZSmadR0hmG0tLQAAOccEW9ubrxwPAkeHx+JABHr6+tjsRjnnHJFRQoGg64xnbI8AkSEz1kYDocDgQAUjUbGmOM4rnEkEimbgISeEEOhEABQrgCAZPXh4QEAhBAA0NHRAR6T2ZMgHA67DpZl/XWyXC6XzWZpGsdisc7OTkQsOThLEBBuW1sb9QQAPD8/u/tUgEwmc39/bxgGIiaTScMwPOe+V6Plcrm6ujqqaiQSEUKQutm2jYjT09MU7z8l1k8qUqkUAFRXV3PO19bW3L/n5+eUtHg8Tm3ho3eeakohDw8P00Framrm5+cPDg5WVlbogiaTSYKucKKRpxBiaWmpubn5T9E4HxwcPD4+dm180BHR7+GFnyLsOE4mk7FtGwCi0WhtbS0ASCn93lvulfEhIA5SiOJNujDu++5HBMU09M0593nqVkjwk/ULopPcYmwxYTQAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"code","source":["#@title Ajustar imágenes para reducir el fondo (opcional)\n","\n","accion_realizar = \"-\" #@param [\"-\", \"Blur Fondo\", \"Eliminar Fondo y pasar a Negro\", \"Eliminar Fondo y pasar a Blanco\"]\n","\n","def cambiarColorNegro(img, nuevoColor=[255, 255, 255]):\n","    black_pixels = np.where(\n","        (img[:, :, 0] == 0) &\n","        (img[:, :, 1] == 0) &\n","        (img[:, :, 2] == 0)\n","    )\n","    img[black_pixels] = nuevoColor\n","    return img\n","\n","def blurFondoImagen(im):\n","  # Convert to the HSV color space\n","  hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n","  # aplica filtro Otsu threshold para obtener máscara\n","  ret, maskthresh = cv2.threshold(hsv[:,:,0], 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","  # Genera la máscara negada\n","  maskthresh = 255 - maskthresh\n","  # We need a to copy the mask 3 times to fit the frames\n","  maskthresh = np.repeat(maskthresh[:, :, np.newaxis], 3, axis=2)\n","  #  Create a blurred frame using Gaussian blur\n","  blurred_frame = cv2.GaussianBlur(im, (25, 25), 0)\n","  # Combine the original with the blurred frame based on mask\n","  return np.where(maskthresh == (255, 255, 255), im, blurred_frame)\n","\n","def reducirFondoImagen(im):\n","  # aplica filtro Hue\n","  imhsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n","  # aplica filtro Otsu threshold para obtener máscara\n","  ret, maskthresh = cv2.threshold(imhsv[:,:,0], 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","  # Genera la máscara negada\n","  maskthresh = 255 - maskthresh\n","  # aplica la máscara sobre la imagen\n","  imgfin = cv2.bitwise_and(im, im, mask = maskthresh)\n","  return imgfin\n","\n","def procesarImgRedFondo(imgList):\n","  nList = []\n","  for im in imgList:\n","    if accion_realizar == \"Blur Fondo\":\n","      # hacer blur del fondo\n","      imn = blurFondoImagen(im)\n","    elif accion_realizar == \"Eliminar Fondo y pasar a Negro\":\n","      # eliminar fondo y dejar negro\n","      imn = reducirFondoImagen(im)\n","    elif accion_realizar == \"Eliminar Fondo y pasar a Blanco\":\n","        # cambia fondo negro a casi negro\n","        # (para que no cambié después)\n","        imn = cambiarColorNegro(im, [0, 0, 1])\n","        # eliminar fondo\n","        imn = reducirFondoImagen(imn)\n","        # cambiar fondo a blanco\n","        imn = cambiarColorNegro(imn, [255, 255, 255])\n","    else:\n","      print(\"Acción no definida!\")\n","      break\n","    nList.append( imn )\n","  return nList\n","\n","\n","# degermina si hace algo o no\n","if accion_realizar != \"-\":\n","  # aplica filtros para intentar reducir el fondo de la imagen\n","  # cambiando las imágenes disponibles\n","  images_train = procesarImgRedFondo(images_train)\n","  images_test = procesarImgRedFondo(images_test)\n","\n","  if len(classes_train)>0:\n","    print(\"- Ejemplo Entrenamiento con fondo reducido \", classes_train[0], \" \", images_train[0].shape, \": \")\n","    display( Image.fromarray(images_train[0], tipoImage_train) )\n","\n","  if len(classes_test)>0:\n","    print(\"- Ejemplo Prueba con fondo reducido \", classes_test[0], \" \", images_test[0].shape, \": \")\n","    display( Image.fromarray(images_test[0], tipoImage_test) )"],"metadata":{"cellView":"form","id":"g-Z21zWxFG_Y","executionInfo":{"status":"ok","timestamp":1722959714927,"user_tz":180,"elapsed":16,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPPvnkjTnTQN","colab":{"base_uri":"https://localhost:8080/","height":701},"cellView":"form","executionInfo":{"status":"ok","timestamp":1722959714927,"user_tz":180,"elapsed":13,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}},"outputId":"9b831841-3caa-4d31-b7db-333b929c3dce"},"source":["#@title Preparar imágenes para usar en el modelo\n","\n","# define función auxiliar para mostrar imágenes preparadas\n","def plot_image(imag):\n","  if IMAGE_SHAPE[2]==1:\n","    plt.imshow((imag).reshape(IMAGE_SHAPE[0], IMAGE_SHAPE[1]).astype(np.uint8)) ## *255\n","    plt.gray()\n","  else:\n","    plt.imshow((imag).reshape(IMAGE_SHAPE).astype(np.uint8)) ## *255\n","  plt.axis(\"off\")\n","\n","# define función auxiliar para preparar la lista de imágenes a procesar\n","def prepare_imageList(imagList):\n","  auxiAr = np.array(imagList) ##.astype('float32') / 255.\n","  auxiAr = auxiAr.reshape((len(auxiAr), IMAGE_SHAPE[0], IMAGE_SHAPE[1], IMAGE_SHAPE[2]))\n","  return auxiAr\n","\n","# define función auxiliar para preparar lista de clases\n","def prepare_clasesList(classesList, dictMapeo=None):\n","  if dictMapeo==None:\n","    # genera diccionario de mapeo\n","    auxDict = list(set(classesList))\n","    dictMapeo = dict( zip( auxDict, range(len(auxDict)) ) )\n","  # realiza el mapeo\n","  y = []\n","  for cl in classesList:\n","      y.append( dictMapeo[cl] )\n","  # convierte valores numéricos a columnas de vakores binarios (i.e. one hot encoded)\n","  dummy_y = to_categorical(y)\n","  # devuelve\n","  return np.array(y), np.array(dummy_y), dictMapeo\n","\n","# define vector auxiliar de datos de entrada para usar en el entrenamiento y prueba\n","x_train = prepare_imageList(images_train)\n","x_test = prepare_imageList(images_test)\n","\n","# define vector auxiliar de datos de salida para usar en el entrenamiento y prueba\n","# también usa esta información para determinar la cantida de neuronas de salida\n","y_train, y_trainEnc, dictMapeo = prepare_clasesList(classes_train)\n","y_test, y_testEnc,_ = prepare_clasesList(classes_test, dictMapeo)\n","\n","# genera diccionario auxiliar para poder convertir de ID de clase a nombre de clase\n","clases_map = [ x for x,y in dictMapeo.items() ]\n","\n","print(\"> Para Entrenamiento: \")\n","print(\" - x_train (cant ejemplos, datos entrada): \", x_train.shape)\n","print(\" - y_trainEnc (cant): \", len(y_trainEnc))\n","print(\" - y_train (cant): \", len(y_train))\n","print(\"\\n\\n> Para Prueba: \")\n","print(\" - x_test (cant ejemplos, datos entrada): \", x_test.shape)\n","print(\" - y_testEnc (cant): \", len(y_testEnc))\n","print(\" - y_test (cant): \", len(y_test))\n","print(\"\\n\\n> Para Ambos: \")\n","print(\" - dictMapeo: \", dictMapeo)\n","print(\" - clases_map: \", clases_map)\n","if len(y_train)>0:\n","  print(\"\\n - Imagen reconstruida de \", clases_map[y_train[0]],  \"(\", y_train[0], \" / \", y_trainEnc[0], \")\")\n","  plot_image(x_train[0])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["> Para Entrenamiento: \n"," - x_train (cant ejemplos, datos entrada):  (240, 32, 32, 3)\n"," - y_trainEnc (cant):  240\n"," - y_train (cant):  240\n","\n","\n","> Para Prueba: \n"," - x_test (cant ejemplos, datos entrada):  (60, 32, 32, 3)\n"," - y_testEnc (cant):  60\n"," - y_test (cant):  60\n","\n","\n","> Para Ambos: \n"," - dictMapeo:  {'2': 0, '8': 1, '9': 2, '0': 3, '1': 4, '6': 5, '3': 6, '7': 7, '5': 8, '4': 9}\n"," - clases_map:  ['2', '8', '9', '0', '1', '6', '3', '7', '5', '4']\n","\n"," - Imagen reconstruida de  7 ( 7  /  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] )\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# Modelo:"],"metadata":{"id":"ahxUAovUyQFR"}},{"cell_type":"code","execution_count":9,"metadata":{"cellView":"form","id":"yU_Vllt7GzIW","executionInfo":{"status":"ok","timestamp":1722959715500,"user_tz":180,"elapsed":584,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8db0146d-3a68-4c7c-f660-018049be45a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["[EVALUATION]\n","epochs        = 50\n","batch_size    = None\n","preprocessing = None\n","increase_epochs_every_n_genomes = 80\n","increase_epochs_add_epochs = 25\n","\n","\n","[FITNESS]\n","calc_using_accuracy = 'E+V'\n","penalize_based_on_topology  = False\n","\n","\n","[POPULATION]\n","bp_pop_size    = 8\n","mod_pop_size   = 5\n","genomes_per_bp = 10\n","\n","\n","[GENOME]\n","dtype                = 'float32'\n","available_modules    = ['Conv2DMaxPool2DDropout']\n","available_optimizers = ['SGD', 'Adam']\n","output_layers        = [{'class_name': 'Flatten', 'config': {}}, \n","                        {'class_name': 'Dense', 'config': {'units': 10, 'activation': 'softmax'}}] \n","\n","\n","[MODULE_SPECIATION]\n","mod_spec_type            = 'param-distance-dynamic'\n","mod_spec_species_count   = 4\n","mod_spec_distance        = 0.3\n","mod_spec_mod_elitism     = 2\n","mod_spec_min_offspring   = 1\n","mod_spec_reprod_thres    = 0.5\n","mod_spec_max_stagnation  = 15\n","mod_spec_species_elitism = 2\n","mod_spec_rebase_repr     = True\n","mod_spec_reinit_extinct  = False\n","\n","\n","[MODULE_EVOLUTION]\n","mod_max_mutation   = 0.5\n","mod_mutation_prob  = 0.6\n","mod_crossover_prob = 0.4\n","\n","\n","[BP_SPECIATION]\n","bp_spec_type            = 'gene-overlap-dynamic'\n","bp_spec_species_count   = 3\n","bp_spec_distance        = 0.3\n","bp_spec_bp_elitism      = 2\n","bp_spec_min_offspring   = 1\n","bp_spec_reprod_thres    = 0.5\n","bp_spec_max_stagnation  = 15\n","bp_spec_species_elitism = 2\n","bp_spec_rebase_repr     = True\n","bp_spec_reinit_extinct  = True\n","\n","\n","[BP_EVOLUTION]\n","bp_max_mutation            = 0.3\n","bp_mutation_add_conn_prob  = 0.2\n","bp_mutation_add_node_prob  = 0.2\n","bp_mutation_rem_conn_prob  = 0.05\n","bp_mutation_rem_node_prob  = 0.05\n","bp_mutation_node_spec_prob = 0.3\n","bp_mutation_optimizer_prob = 0.1\n","bp_crossover_prob          = 0.1\n","\n","\n","[MODULE_CONV2DMAXPOOL2DDROPOUT]\n","merge_method  = [{'class_name': 'Concatenate', 'config': {'axis': -1}}, \n","                 {'class_name': 'Add', 'config': {}}]\n","filters       = {'min': 8, 'max': 256, 'step': 8, 'stddev': 4}\n","kernel_size   = [1,2,3]\n","strides       = [1]\n","padding       = ['valid', 'same']\n","activation    = ['linear', 'elu', 'relu']\n","kernel_init   = ['glorot_uniform']\n","bias_init     = ['zeros']\n","max_pool_flag = 0.8\n","max_pool_size = [1,2,3]\n","dropout_flag  = 0.5\n","dropout_rate  = {'min': 0.1, 'max': 0.7, 'step': 0.1, 'stddev': 0.2}\n","\n","\n","[OPTIMIZER_SGD]\n","learning_rate = {'min': 0.001, 'max': 0.3, 'step': 0.001, 'stddev': 0.02}\n","momentum      = {'min': 0.3, 'max': 0.7, 'step': 0.1, 'stddev': 0.1}\n","nesterov      = [True, False] \n","\n","\n","[OPTIMIZER_ADAM]\n","learning_rate = {'min': 0.0001, 'max': 0.3, 'step': 0.0001, 'stddev': 0.02}\n","beta_1        = {'min': 0.6, 'max': 1.5, 'step': 0.05, 'stddev': 0.2}\n","beta_2        = {'min': 0.8, 'max': 1.2, 'step': 0.001, 'stddev': 0.1}\n","epsilon       = {'min': 1e-8, 'max': 1e-6, 'step': 1e-8, 'stddev': 1e-7}\n","\n","\n"]}],"source":["#@title Crear Archivo Configuración de Parámetros para TFNE\n","# ver explicación en https://tfne.readthedocs.io/en/latest/codeepneat/codeepneat-config.html\n","\n","#@markdown Criterio de Paro:\n","ce_maximo_generaciones_procesar = 5 #@param {type:\"integer\"}\n","ce_finalizar_al_encontrar_max_fitness = True #@param {type:\"boolean\"}\n","#@markdown Función de Aptitud:\n","fitness_calc_usando = \"Entrenamiento + Validacion\" #@param [\"Entrenamiento\", \"Validacion\", \"Entrenamiento + Validacion\"]\n","fitness_penalizar_x_topologia = False #param {type:\"boolean\"}\n","#@markdown Blueprints (topología & optimizador):\n","ce_cant_poblacion_blueprints =  8#@param {type:\"integer\"}\n","#@markdown  Genomas (instancias de RNAs):\n","ce_cant_genomas_por_blueprint =  10#@param {type:\"integer\"}\n","#@markdown Módulos (capas RNA):\n","ce_cant_poblacion_modulos =  5#@param {type:\"integer\"}\n","ce_tipo_generacion_modulos = \"Dinamica\" #@param [\"Basica\", \"Dinamica\", \"Fija\"]\n","#@markdown Operadores Genéticos:\n","ce_max_mutacion = 0.5 #@param {type:\"number\"}\n","ce_probab_mutacion = 0.6 #@param {type:\"number\"}\n","ce_probab_cruzamiento = 0.4 #@param {type:\"number\"}\n","#@markdown Entrenamiento RNA:\n","rna_cant_epocas_entrenamiento = 50#@param {type:\"integer\"}\n","rna_cant_epocas_entrenamiento_incrementa_por_generacion = 25#@param {type:\"integer\"}\n","\n","confFileName = './codeepneat_config.cfg'\n","\n","s = \"\"\n","with open(confFileName, 'w') as f:\n","    s = s + \"[EVALUATION]\\n\"\n","    s = s + \"epochs        = \" + str(rna_cant_epocas_entrenamiento) + \"\\n\"\n","    s = s + \"batch_size    = None\\n\"\n","    s = s + \"preprocessing = None\\n\"\n","    if rna_cant_epocas_entrenamiento_incrementa_por_generacion > 0:\n","      s = s + \"increase_epochs_every_n_genomes = \" + str(ce_cant_poblacion_blueprints*ce_cant_genomas_por_blueprint) + \"\\n\"\n","      s = s + \"increase_epochs_add_epochs = \" + str(rna_cant_epocas_entrenamiento_incrementa_por_generacion) + \"\\n\"\n","    else:\n","      s = s + \"increase_epochs_every_n_genomes = 0\\n\"\n","      s = s + \"increase_epochs_add_epochs = 0\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[FITNESS]\\n\"\n","    if fitness_calc_usando == \"Entrenamiento\":\n","      s = s + \"calc_using_accuracy  = 'E'\\n\"\n","    elif fitness_calc_usando == \"Validacion\":\n","      s = s + \"calc_using_accuracy = 'V'\\n\"\n","    else:\n","      s = s + \"calc_using_accuracy = 'E+V'\\n\"\n","    s = s + \"penalize_based_on_topology  = \" + str(fitness_penalizar_x_topologia) + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[POPULATION]\\n\"\n","    s = s + \"bp_pop_size    = \" + str(ce_cant_poblacion_blueprints) + \"\\n\"\n","    s = s + \"mod_pop_size   = \" + str(ce_cant_poblacion_modulos) + \"\\n\"\n","    s = s + \"genomes_per_bp = \" + str(ce_cant_genomas_por_blueprint ) + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[GENOME]\\n\"\n","    s = s + \"dtype                = 'float32'\\n\"\n","    s = s + \"available_modules    = ['Conv2DMaxPool2DDropout']\\n\"\n","    s = s + \"available_optimizers = ['SGD', 'Adam']\\n\" # 'SGD',\n","    s = s + \"output_layers        = [{'class_name': 'Flatten', 'config': {}}, \\n\"\n","    s = s + \"                        {'class_name': 'Dense', 'config': {'units': \"+ str(len(clases_map)) + \", 'activation': 'softmax'}}] \\n\"\n","    tipo_output_softMax = True\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[MODULE_SPECIATION]\\n\"\n","    if ce_tipo_generacion_modulos == \"Dinamica\":\n","      # Dinamica\n","      s = s + \"mod_spec_type            = 'param-distance-dynamic'\\n\"\n","      s = s + \"mod_spec_species_count   = 4\\n\"\n","      s = s + \"mod_spec_distance        = 0.3\\n\"\n","      s = s + \"mod_spec_mod_elitism     = 2\\n\"\n","      s = s + \"mod_spec_min_offspring   = 1\\n\"\n","      s = s + \"mod_spec_reprod_thres    = 0.5\\n\"\n","      s = s + \"mod_spec_max_stagnation  = 15\\n\"\n","      s = s + \"mod_spec_species_elitism = 2\\n\"\n","      s = s + \"mod_spec_rebase_repr     = True\\n\"\n","      s = s + \"mod_spec_reinit_extinct  = False\\n\"\n","    elif ce_tipo_generacion_modulos == \"Fija\":\n","      # Fija\n","      s = s + \"mod_spec_type            = 'param-distance-fixed'\\n\"\n","      s = s + \"mod_spec_distance        = 0.3\\n\"\n","      s = s + \"mod_spec_mod_elitism     = 2\\n\"\n","      s = s + \"mod_spec_min_offspring   = 1\\n\"\n","      s = s + \"mod_spec_reprod_thres    = 0.5\\n\"\n","      s = s + \"mod_spec_max_stagnation  = 10\\n\"\n","      s = s + \"mod_spec_species_elitism = 2\\n\"\n","      s = s + \"mod_spec_rebase_repr     = True\\n\"\n","      s = s + \"mod_spec_reinit_extinct  = False\\n\"\n","    else:\n","      # Basica\n","      s = s + \"mod_spec_type          = 'basic'\\n\"\n","      s = s + \"mod_spec_mod_elitism   = 4\\n\"\n","      s = s + \"mod_spec_min_offspring = 1\\n\"\n","      s = s + \"mod_spec_reprod_thres  = 0.5\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[MODULE_EVOLUTION]\\n\"\n","    s = s + \"mod_max_mutation   = \" + str(ce_max_mutacion) + \"\\n\"\n","    s = s + \"mod_mutation_prob  = \" + str(ce_probab_mutacion) + \"\\n\"\n","    s = s + \"mod_crossover_prob = \" + str(ce_probab_cruzamiento) + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[BP_SPECIATION]\\n\"\n","    if ce_tipo_generacion_modulos == \"Dinamica\":\n","      # Dinamica\n","      s = s + \"bp_spec_type            = 'gene-overlap-dynamic'\\n\"\n","      s = s + \"bp_spec_species_count   = 3\\n\"\n","      s = s + \"bp_spec_distance        = 0.3\\n\"\n","      s = s + \"bp_spec_bp_elitism      = 2\\n\"\n","      s = s + \"bp_spec_min_offspring   = 1\\n\"\n","      s = s + \"bp_spec_reprod_thres    = 0.5\\n\"\n","      s = s + \"bp_spec_max_stagnation  = 15\\n\"\n","      s = s + \"bp_spec_species_elitism = 2\\n\"\n","      s = s + \"bp_spec_rebase_repr     = True\\n\"\n","      s = s + \"bp_spec_reinit_extinct  = True\\n\"\n","    elif ce_tipo_generacion_modulos == \"Fija\":\n","      # Fija\n","      s = s + \"bp_spec_type            = 'gene-overlap-fixed'\\n\"\n","      s = s + \"bp_spec_distance        = 0.3\\n\"\n","      s = s + \"bp_spec_bp_elitism      = 2\\n\"\n","      s = s + \"bp_spec_min_offspring   = 1\\n\"\n","      s = s + \"bp_spec_reprod_thres    = 0.5\\n\"\n","      s = s + \"bp_spec_max_stagnation  = 15\\n\"\n","      s = s + \"bp_spec_species_elitism = 2\\n\"\n","      s = s + \"bp_spec_rebase_repr     = True\\n\"\n","      s = s + \"bp_spec_reinit_extinct  = True\\n\"\n","    else:\n","      # Basica\n","      s = s + \"bp_spec_type          = 'basic'\\n\"\n","      s = s + \"bp_spec_bp_elitism    = 2\\n\"\n","      s = s + \"bp_spec_min_offspring = 1\\n\"\n","      s = s + \"bp_spec_reprod_thres  = 0.5\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[BP_EVOLUTION]\\n\"\n","    if ce_tipo_generacion_modulos == \"Dinamica\":\n","      # Dinamica\n","      s = s + \"bp_max_mutation            = 0.3\\n\"\n","      s = s + \"bp_mutation_add_conn_prob  = 0.2\\n\"\n","      s = s + \"bp_mutation_add_node_prob  = 0.2\\n\"\n","      s = s + \"bp_mutation_rem_conn_prob  = 0.05\\n\"\n","      s = s + \"bp_mutation_rem_node_prob  = 0.05\\n\"\n","      s = s + \"bp_mutation_node_spec_prob = 0.3\\n\"\n","      s = s + \"bp_mutation_optimizer_prob = 0.1\\n\"\n","      s = s + \"bp_crossover_prob          = 0.1\\n\"\n","    else:\n","      # Fija o Basica\n","      s = s + \"bp_max_mutation            = 0.3\\n\"\n","      s = s + \"bp_mutation_add_conn_prob  = 0.3\\n\"\n","      s = s + \"bp_mutation_add_node_prob  = 0.3\\n\"\n","      s = s + \"bp_mutation_rem_conn_prob  = 0.05\\n\"\n","      s = s + \"bp_mutation_rem_node_prob  = 0.05\\n\"\n","      s = s + \"bp_mutation_node_spec_prob = 0.1\\n\"\n","      s = s + \"bp_mutation_optimizer_prob = 0.1\\n\"\n","      s = s + \"bp_crossover_prob          = 0.1\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[MODULE_CONV2DMAXPOOL2DDROPOUT]\\n\"\n","    s = s + \"merge_method  = [{'class_name': 'Concatenate', 'config': {'axis': -1}}, \\n\"\n","    s = s + \"                 {'class_name': 'Add', 'config': {}}]\\n\"\n","    s = s + \"filters       = {'min': 8, 'max': 256, 'step': 8, 'stddev': 4}\\n\"\n","    s = s + \"kernel_size   = [1,2,3]\\n\"\n","    s = s + \"strides       = [1]\\n\"\n","    s = s + \"padding       = ['valid', 'same']\\n\"\n","    s = s + \"activation    = ['linear', 'elu', 'relu']\\n\"\n","    s = s + \"kernel_init   = ['glorot_uniform']\\n\"\n","    s = s + \"bias_init     = ['zeros']\\n\"\n","    s = s + \"max_pool_flag = 0.8\\n\"\n","    s = s + \"max_pool_size = [1,2,3]\\n\"\n","    s = s + \"dropout_flag  = 0.5\\n\"\n","    s = s + \"dropout_rate  = {'min': 0.1, 'max': 0.7, 'step': 0.1, 'stddev': 0.2}\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[OPTIMIZER_SGD]\\n\"\n","    s = s + \"learning_rate = {'min': 0.001, 'max': 0.3, 'step': 0.001, 'stddev': 0.02}\\n\"\n","    s = s + \"momentum      = {'min': 0.3, 'max': 0.7, 'step': 0.1, 'stddev': 0.1}\\n\"\n","    s = s + \"nesterov      = [True, False] \\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[OPTIMIZER_ADAM]\\n\"\n","    s = s + \"learning_rate = {'min': 0.0001, 'max': 0.3, 'step': 0.0001, 'stddev': 0.02}\\n\"\n","    s = s + \"beta_1        = {'min': 0.6, 'max': 1.5, 'step': 0.05, 'stddev': 0.2}\\n\"\n","    s = s + \"beta_2        = {'min': 0.8, 'max': 1.2, 'step': 0.001, 'stddev': 0.1}\\n\"\n","    s = s + \"epsilon       = {'min': 1e-8, 'max': 1e-6, 'step': 1e-8, 'stddev': 1e-7}\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","\n","    f.write(s)\n","\n","# muestra nuevo archivo modificado\n","%cat {confFileName}\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"6QNOESjoDj6B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722959715500,"user_tz":180,"elapsed":3,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}},"outputId":"9aae5055-c5fe-4a5c-90a2-45b62e790a55","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["Clase RNAEnvironment definida\n"]}],"source":["#@title Definir clase para el ambiente RNAEnvironment\n","\n","class RNAEnvironment(BaseEnvironment):\n","    \"\"\"\n","    TFNE compatible environment for the RNA\n","    \"\"\"\n","\n","    def __init__(self, weight_training, data_x, data_y, config=None, verbosity=0, **kwargs):\n","        \"\"\"\n","        Initializes environment by setting up the dataset and processing the supplied config or supplied config\n","        parameters. The configuration of the environment can either be supplied via a config file or via seperate config\n","        parameters in the initialization.\n","        @param weight_training: bool flag, indicating wether evaluation should be weight training or not\n","        @param config: ConfigParser instance holding an 'Environment' section specifying the required environment\n","                       parameters for the chosen evaluation method.\n","        @param verbosity: integer specifying the verbosity of the evaluation\n","        @param kwargs: Optionally supplied dict of each configuration parameter seperately in order to allow the\n","                       creation of the evaluation environment without the requirement of a config file.\n","        \"\"\"\n","        # Initialize corresponding input and output mappings\n","        print(\"> Preparando el ambiente...\")\n","\n","        # Initialize loss function to evaluate performance on either evaluation method and safe verbosity parameter\n","        self.accuracy_metric = tf.keras.metrics.Accuracy()\n","        self.verbosity = verbosity\n","\n","        # Determine and setup explicit evaluation method in accordance to supplied parameters\n","        if not weight_training:\n","              raise NotImplementedError(\"RNA environment is being set up as non-weight training, though non-weight \"\n","                                      \"training evaluation not yet implemented for RNA environment\")\n","\n","\n","        elif config is None and len(kwargs) == 0:\n","            raise RuntimeError(\"No se han definido los parámetros para poder realizar la evolución y el entrenamiento de las RNA\")\n","\n","        elif len(kwargs) == 0:\n","            # Set up environment as weight training and with a supplied config file\n","            self.eval_genome_fitness = self._eval_genome_fitness_weight_training\n","            self.epochs = read_option_from_config(config, 'EVALUATION', 'epochs')\n","            self.batch_size = read_option_from_config(config, 'EVALUATION', 'batch_size')\n","            self.increase_epochs_every_n_genomes = read_option_from_config(config, 'EVALUATION', 'increase_epochs_every_n_genomes')\n","            self.increase_epochs_add_epochs = read_option_from_config(config, 'EVALUATION', 'increase_epochs_add_epochs')\n","            #  parámetros para calculo fitness\n","            self.calcFitness = read_option_from_config(config, 'FITNESS', 'calc_using_accuracy')\n","            self.penalFitness = read_option_from_config(config, 'FITNESS', 'penalize_based_on_topology')\n","\n","        elif config is None:\n","            # Set up environment as weight training and explicitely supplied parameters\n","            self.eval_genome_fitness = self._eval_genome_fitness_weight_training\n","            self.epochs = kwargs['epochs']\n","            self.batch_size = kwargs['batch_size']\n","            self.increase_epochs_every_n_genomes = kwargs['increase_epochs_every_n_genomes']\n","            self.increase_epochs_add_epochs = kwargs['increase_epochs_add_epochs']\n","            # determina parámetros para calculo fitness\n","            self.calcFitness = kwargs['fitness_calc_using_accuracy']\n","            self.penalFitness = kwargs['fitness_penalize_based_on_topology']\n","\n","        # para problema de clasificación\n","        print(\" Configurado para problema de Clasificación.\")\n","        # Initialize loss function to evaluate performance on either evaluation method\n","        self.accuracy_metric = tf.keras.metrics.Accuracy()\n","        # determina neuronas de entrada y salida\n","        if len(data_x)>0:\n","          self.cantX = data_x[0].shape\n","        else:\n","          self.cantX = None\n","        self.cantY = data_y.shape[1]\n","\n","        print(\" Definiendo parámetros para cálculo de aptitud: \")\n","        print(\"        calcFitness = \", self.calcFitness)\n","        print(\"        penalFitness = \", self.penalFitness)\n","\n","        if self.calcFitness == \"E\":\n","            # se toman todos los datos para entrenamiento\n","            self.x_train, self.y_train, data_x, data_y\n","            self.x_val, self.y_val = [], []\n","            self.x_eval, self.y_eval = data_x, data_y\n","        else:\n","            # separa al azar usando muestreo al azar del 10%\n","            # para tomar algunos como datos de validación\n","            self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(data_x, data_y,\n","                                                                                    test_size=0.1)\n","            if self.calcFitness == \"V\":\n","              # para calculo de fitness (eval) se usa solamente los de valiadación\n","              self.x_eval, self.y_eval = self.x_val, self.y_val\n","            else: #  \"E+V\":\n","              # para calculo de fitness (eval) se usan todos (pero los de validación no se usan para entrenar)\n","              self.x_eval, self.y_eval = data_x, data_y\n","\n","        print(\"  Definiendo datos: de los \", len(data_x), \"ejemplos de entrenamiento: \")\n","        print(\"                      se usan \", len(self.x_train), \"ejemplos para entrenar \")\n","        print(\"                      se usan \", len(self.x_val), \"ejemplos para validar\")\n","        print(\"                      y \", len(self.x_eval), \"ejemplos para calcular fitness.\")\n","\n","        # prepara datos entrenamiento como array\n","        self.x_train = np.array(self.x_train)\n","        self.y_train = np.array(self.y_train).reshape(len(self.y_train), self.cantY)\n","        # prepara datos validación como array\n","        self.x_val = np.array(self.x_val)\n","        self.y_val = np.array(self.y_val).reshape(len(self.y_val), self.cantY)\n","        # prepara datos evaluación\n","        self.x_eval = np.array(self.x_eval)\n","        self.y_eval = np.array(self.y_eval).reshape(len(self.y_eval), self.cantY)\n","        # obtiene id único para evaluar\n","        self.y_eval = np.argmax(self.y_eval, axis=-1)\n","\n","        print(\" Topología base de la red: \")\n","        print(\"\\t -Capa Entrada: \", self.cantX,  \" / x_train: \",  self.x_train.shape)\n","        print(\"\\t -Capa Salida: \", self.cantY,  \" / y_train \" ,  self.y_train.shape)\n","        print(\"\\n\")\n","\n","        return\n","\n","    def eval_genome_fitness(self, genome) -> float:\n","        # TO BE OVERRIDEN\n","        raise RuntimeError()\n","\n","    def _apply_penalize_fitness(self, evaluated_fitness, model):\n","        # penaliza fitness si el modelo es complejo\n","        maxFit = self.return_MaxFitness()\n","          # sólo se aplica la penalización\n","          # si está cercano a alcanzar la aptitud máxima\n","        if evaluated_fitness >= (maxFit - 11):\n","          # penaliza aptitud teniendo en cuenta la complejidad de la RNA\n","          penalLayers = -1.5\n","          ajusteCantPesos = self.cantX\n","          for i in range(len(model.layers)):\n","            l = model.layers[i]\n","            tipoLay = str(type(l))\n","            if \"Dense\" in tipoLay:\n","              if i > 1:\n","                # contabiliza en base a la cantidad de pesos de las conexiones\n","                # nota: no tiene en cuenta los pesos de la capa de entrada ni de salida\n","                cantPesos = len(l.get_weights()[0])\n","                penalLayers = penalLayers + (cantPesos / ajusteCantPesos)\n","            elif \"Dropout\" in tipoLay:\n","              penalLayers = penalLayers + 0.8\n","            elif \"Concatenate\" in tipoLay:\n","              penalLayers = penalLayers + 0.9\n","          if penalLayers > 0:\n","            evaluated_fitness = evaluated_fitness + 10.0 - (penalLayers / 10.0)\n","        return evaluated_fitness\n","\n","\n","    def _calculate_fitness(self, model, penalFitness=False) -> float:\n","        \"\"\"\n","        The genomes fitness is then calculated and returned as\n","        the percentage of training and/or validation examples classified correctly.\n","        \"\"\"\n","        try:\n","            # calcula con datos de evaluación (definidas antes)\n","            if (len(self.x_eval)>0) and (len(self.y_eval)>0):\n","              self.accuracy_metric.reset_states()\n","              # ejecuta modelo con datos de evaluación\n","              resModel = model(self.x_eval)\n","              # toma ID de clase generada por modelo\n","              resModel = np.argmax(resModel, axis=-1)\n","              # calcula métrica\n","              self.accuracy_metric.update_state(self.y_eval, resModel)\n","              valAcc = self.accuracy_metric.result().numpy()\n","              if math.isnan(valAcc):\n","                evaluated_fitness = 0.0001\n","              elif valAcc <= 0:\n","                evaluated_fitness = 0.0002\n","              else:\n","                evaluated_fitness = round(valAcc* 100.0, 4)\n","            else:\n","              evaluated_fitness = 0.0001\n","            if penalFitness:\n","              # ejecuta aplicación de penalización del modelo si corresponde\n","              evaluated_fitness = self._apply_penalize_fitness(evaluated_fitness, model)\n","            if math.isnan(evaluated_fitness) or (evaluated_fitness<=0.0):\n","              return 0.0001\n","            else:\n","              return round(evaluated_fitness, 5)\n","        except Exception as e:\n","          print(\"Error calculate_fitness: \", e)\n","          return 0.0001\n","\n","    def return_MaxFitness(self) -> float:\n","      # devuelve valor máximo posible para la aptitud\n","      valMaxFit = 100.0\n","      if self.penalFitness:\n","        valMaxFit = valMaxFit + 10\n","      return valMaxFit\n","\n","    def _eval_genome_fitness_weight_training(self, genome) -> float:\n","        \"\"\"\n","        Evaluates the genome's fitness by obtaining the associated Tensorflow model and optimizer,\n","        compiling them and then training them for the config specified duration.\n","        @param genome: TFNE compatible genome that is to be evaluated\n","        @return: genome calculated fitness\n","        \"\"\"\n","        # Get model and optimizer required for compilation\n","        model = genome.get_model()\n","        optimizer = genome.get_optimizer()\n","\n","        # si corresponde incrementa la cantidad de épocas\n","        gen_id = genome.get_id()\n","        if gen_id > self.increase_epochs_every_n_genomes:\n","          cantEpochsIncr = int((gen_id / self.increase_epochs_every_n_genomes) * self.increase_epochs_add_epochs)\n","          cant_epochs = self.epochs + cantEpochsIncr\n","          #print(\"  > \", gen_id, self.epochs, cantEpochsIncr, cant_epochs)\n","        else:\n","          cant_epochs = self.epochs\n","\n","        # Compile and train model\n","        model.compile(optimizer=optimizer,\n","                      loss='categorical_crossentropy', metrics=['accuracy'])\n","        model.fit(x=self.x_train,\n","                  y=self.y_train,\n","                  epochs=cant_epochs,\n","                  batch_size=self.batch_size,\n","                  verbose=self.verbosity)\n","\n","        # Evaluate and return its fitness\n","        return self._calculate_fitness(model, self.penalFitness)\n","\n","    def _eval_genome_fitness_non_weight_training(self, genome) -> float:\n","        raise NotImplementedError(\"Non-Weight training evaluation not yet implemented for Environment\")\n","\n","    def replay_genome(self, genome):\n","        \"\"\"\n","        Replay genome on environment by calculating its fitness and printing it.\n","        @param genome: TFNE compatible genome that is to be evaluated\n","        \"\"\"\n","        print(\"> Probando Genome #{}:\".format(genome.get_id()))\n","\n","        # Determine fitness by creating model predictions with test images and then judging the fitness based on the\n","        # achieved model accuracy.\n","        model = genome.get_model()\n","        evaluated_fitness = self._calculate_fitness(model, False)\n","        print(\"  Aptitud lograda:\\t{}\\n\".format(evaluated_fitness))\n","\n","    def duplicate(self) -> RNAEnvironment:\n","        \"\"\"\n","        @return: New instance of the environment with identical parameters\n","        \"\"\"\n","        x = self.x_train.extend(self.x_val)\n","        y = self.y_train.extend(self.y_val)\n","        # fuerza forma de y\n","        y = np.array(y).reshape(len(y), self.cantY)\n","\n","        if hasattr(self, 'epochs'):\n","            return RNAEnvironment(True, data_x=x, data_y=y, verbosity=self.verbosity,\n","                                  epochs=self.epochs, batch_size=self.batch_size)\n","        else:\n","            return RNAEnvironment(False, data_x=x, data_y=y, verbosity=self.verbosity)\n","\n","    def get_input_shape(self) -> (int, int, int):\n","        \"\"\"\"\"\"\n","        return self.cantX\n","\n","    def get_output_shape(self) ->  (int,):\n","        \"\"\"\"\"\"\n","        return (self.cantY,)\n","\n","\n","print(\"Clase RNAEnvironment definida\")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"kHIt18d-AUTc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722963299944,"user_tz":180,"elapsed":1461761,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}},"outputId":"b4fbbccc-7335-41c9-ccf0-f5c590a11aec","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["> Preparando el ambiente...\n","Config value for 'EVALUATION/epochs': 50\n","Config value for 'EVALUATION/batch_size': None\n","Config value for 'EVALUATION/increase_epochs_every_n_genomes': 80\n","Config value for 'EVALUATION/increase_epochs_add_epochs': 25\n","Config value for 'FITNESS/calc_using_accuracy': E+V\n","Config value for 'FITNESS/penalize_based_on_topology': False\n"," Configurado para problema de Clasificación.\n"," Definiendo parámetros para cálculo de aptitud: \n","        calcFitness =  E+V\n","        penalFitness =  False\n","  Definiendo datos: de los  240 ejemplos de entrenamiento: \n","                      se usan  216 ejemplos para entrenar \n","                      se usan  24 ejemplos para validar\n","                      y  240 ejemplos para calcular fitness.\n"," Topología base de la red: \n","\t -Capa Entrada:  (32, 32, 3)  / x_train:  (216, 32, 32, 3)\n","\t -Capa Salida:  10  / y_train  (216, 10)\n","\n","\n",">  Definiendo configuración:\n","Config value for 'POPULATION/bp_pop_size': 8\n","Config value for 'POPULATION/mod_pop_size': 5\n","Config value for 'POPULATION/genomes_per_bp': 10\n","Config value for 'GENOME/dtype': float32\n","Config value for 'GENOME/available_modules': ['Conv2DMaxPool2DDropout']\n","Config value for 'GENOME/available_optimizers': ['SGD', 'Adam']\n","Config value for 'GENOME/output_layers': [{'class_name': 'Flatten', 'config': {}}, {'class_name': 'Dense', 'config': {'units': 10, 'activation': 'softmax'}}]\n","Config value for 'MODULE_SPECIATION/mod_spec_type': param-distance-dynamic\n","Config value for 'MODULE_SPECIATION/mod_spec_species_count': 4\n","Config value for 'MODULE_SPECIATION/mod_spec_distance': 0.3\n","Config value for 'MODULE_SPECIATION/mod_spec_mod_elitism': 2\n","Config value for 'MODULE_SPECIATION/mod_spec_min_offspring': 1\n","Config value for 'MODULE_SPECIATION/mod_spec_reprod_thres': 0.5\n","Config value for 'MODULE_SPECIATION/mod_spec_max_stagnation': 15\n","Config value for 'MODULE_SPECIATION/mod_spec_species_elitism': 2\n","Config value for 'MODULE_SPECIATION/mod_spec_rebase_repr': True\n","Config value for 'MODULE_SPECIATION/mod_spec_reinit_extinct': False\n","Config value for 'MODULE_EVOLUTION/mod_max_mutation': 0.5\n","Config value for 'MODULE_EVOLUTION/mod_mutation_prob': 0.6\n","Config value for 'MODULE_EVOLUTION/mod_crossover_prob': 0.4\n","Config value for 'BP_SPECIATION/bp_spec_type': gene-overlap-dynamic\n","Config value for 'BP_SPECIATION/bp_spec_species_count': 3\n","Config value for 'BP_SPECIATION/bp_spec_distance': 0.3\n","Config value for 'BP_SPECIATION/bp_spec_bp_elitism': 2\n","Config value for 'BP_SPECIATION/bp_spec_min_offspring': 1\n","Config value for 'BP_SPECIATION/bp_spec_reprod_thres': 0.5\n","Config value for 'BP_SPECIATION/bp_spec_max_stagnation': 15\n","Config value for 'BP_SPECIATION/bp_spec_species_elitism': 2\n","Config value for 'BP_SPECIATION/bp_spec_rebase_repr': True\n","Config value for 'BP_SPECIATION/bp_spec_reinit_extinct': True\n","Config value for 'BP_EVOLUTION/bp_max_mutation': 0.3\n","Config value for 'BP_EVOLUTION/bp_mutation_add_conn_prob': 0.2\n","Config value for 'BP_EVOLUTION/bp_mutation_add_node_prob': 0.2\n","Config value for 'BP_EVOLUTION/bp_mutation_rem_conn_prob': 0.05\n","Config value for 'BP_EVOLUTION/bp_mutation_rem_node_prob': 0.05\n","Config value for 'BP_EVOLUTION/bp_mutation_node_spec_prob': 0.3\n","Config value for 'BP_EVOLUTION/bp_mutation_optimizer_prob': 0.1\n","Config value for 'BP_EVOLUTION/bp_crossover_prob': 0.1\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/merge_method': [{'class_name': 'Concatenate', 'config': {'axis': -1}}, {'class_name': 'Add', 'config': {}}]\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/filters': {'min': 8, 'max': 256, 'step': 8, 'stddev': 4}\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/kernel_size': [1, 2, 3]\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/strides': [1]\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/padding': ['valid', 'same']\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/activation': ['linear', 'elu', 'relu']\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/kernel_init': ['glorot_uniform']\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/bias_init': ['zeros']\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/max_pool_flag': 0.8\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/max_pool_size': [1, 2, 3]\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/dropout_flag': 0.5\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/dropout_rate': {'min': 0.1, 'max': 0.7, 'step': 0.1, 'stddev': 0.2}\n","Config value for 'OPTIMIZER_SGD/learning_rate': {'min': 0.001, 'max': 0.3, 'step': 0.001, 'stddev': 0.02}\n","Config value for 'OPTIMIZER_SGD/momentum': {'min': 0.3, 'max': 0.7, 'step': 0.1, 'stddev': 0.1}\n","Config value for 'OPTIMIZER_SGD/nesterov': [True, False]\n","Config value for 'OPTIMIZER_ADAM/learning_rate': {'min': 0.0001, 'max': 0.3, 'step': 0.0001, 'stddev': 0.02}\n","Config value for 'OPTIMIZER_ADAM/beta_1': {'min': 0.6, 'max': 1.5, 'step': 0.05, 'stddev': 0.2}\n","Config value for 'OPTIMIZER_ADAM/beta_2': {'min': 0.8, 'max': 1.2, 'step': 0.001, 'stddev': 0.1}\n","Config value for 'OPTIMIZER_ADAM/epsilon': {'min': 1e-08, 'max': 1e-06, 'step': 1e-08, 'stddev': 1e-07}\n","Using Neuroevolution algorithm: CoDeepNEAT\n","Using evaluation environment: RNAEnvironment\n","Maximum number of generations to evolve the population: 5\n","Maximum fitness value to evolve population up to: 100.0\n","Creating TFNE generational Backups to directory: /content/tfne_state_backups/tfne_state_backup_2024-Aug-06_15-55-15/\n","Initializing a new population of 8 blueprints and 5 modules...\n","\n","Evaluating 80 genomes in generation 0...\n","[========================================] 80/80 Genomes | Genome ID 80 achieved fitness of 10.0\n","\n","\n","\u001b[1m############################################################  Population Summary  ############################################################\n","\n","Generation:    0  ||  Best Genome Fitness:  97.9167  ||  Avg Blueprint Fitness:  43.7083  ||  Avg Module Fitness:  44.0433\u001b[0m\n","Best Genome: CoDeepNEAT Genome | ID:     66 | Fitness: 97.9167 | Blueprint ID:      7 | Module Species: {1} | Optimizer:   adam | Origin Gen:    0\n","\n","\u001b[1mBlueprint Species       || Blueprint Species Avg Fitness       || Blueprint Species Size\u001b[0m\n","     1                  ||  43.7083                            ||        8\n","Best BP of Species 1    || CoDeepNEAT Blueprint | ID:     #1 | Fitness: 95.375 | Nodes:    2 | Module Species: {1} | Optimizer: adam\n","\n","\u001b[1mModule Species          || Module Species Avg Fitness          || Module Species Size\u001b[0m\n","     1                  ||  44.0433                            ||        5\n","Best Mod of Species 1   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #2 | Fitness: 65.0893 | Filters:   96 | Kernel:      1 | Activ:    elu | Pool Size:      1 | Dropout: None\n","\n","\u001b[1m##############################################################################################################################################\u001b[0m\n","\n","Backed up generation 0 of the CoDeepNEAT evolutionary run to file: /content/tfne_state_backups/tfne_state_backup_2024-Aug-06_15-55-15/tfne_state_backup_gen_0.json\n","\n","Evaluating 80 genomes in generation 1...\n","[========================================] 80/80 Genomes | Genome ID 160 achieved fitness of 10.0\n","\n","\n","\u001b[1m############################################################  Population Summary  ############################################################\n","\n","Generation:    1  ||  Best Genome Fitness:  98.3333  ||  Avg Blueprint Fitness:  63.0312  ||  Avg Module Fitness:  48.2828\u001b[0m\n","Best Genome: CoDeepNEAT Genome | ID:    117 | Fitness: 98.3333 | Blueprint ID:     10 | Module Species: {1} | Optimizer:   adam | Origin Gen:    1\n","\n","\u001b[1mBlueprint Species       || Blueprint Species Avg Fitness       || Blueprint Species Size\u001b[0m\n","     1                  ||  63.0312                            ||        8\n","Best BP of Species 1    || CoDeepNEAT Blueprint | ID:    #10 | Fitness: 96.7083 | Nodes:    2 | Module Species: {1} | Optimizer: adam\n","\n","\u001b[1mModule Species          || Module Species Avg Fitness          || Module Species Size\u001b[0m\n","     1                  ||  60.3536                            ||        4\n","Best Mod of Species 1   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #7 | Fitness: 76.3782 | Filters:   96 | Kernel:      1 | Activ:    elu | Pool Size:      1 | Dropout: None\n","     2                  ||        0                            ||        1\n","Best Mod of Species 2   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #6 | Fitness:      0 | Filters:  224 | Kernel:      2 | Activ: linear | Pool Size:      1 | Dropout:  0.1\n","\n","\u001b[1m##############################################################################################################################################\u001b[0m\n","\n","Backed up generation 1 of the CoDeepNEAT evolutionary run to file: /content/tfne_state_backups/tfne_state_backup_2024-Aug-06_15-55-15/tfne_state_backup_gen_1.json\n","\n","Evaluating 80 genomes in generation 2...\n","[========================================] 80/80 Genomes | Genome ID 240 achieved fitness of 97.0833\n","\n","\n","\u001b[1m############################################################  Population Summary  ############################################################\n","\n","Generation:    2  ||  Best Genome Fitness:    98.75  ||  Avg Blueprint Fitness:  72.5729  ||  Avg Module Fitness:  70.8255\u001b[0m\n","Best Genome: CoDeepNEAT Genome | ID:    211 | Fitness:  98.75 | Blueprint ID:     18 | Module Species: {2} | Optimizer:   adam | Origin Gen:    2\n","\n","\u001b[1mBlueprint Species       || Blueprint Species Avg Fitness       || Blueprint Species Size\u001b[0m\n","     1                  ||  72.5729                            ||        8\n","Best BP of Species 1    || CoDeepNEAT Blueprint | ID:    #18 | Fitness: 97.9167 | Nodes:    2 | Module Species: {2} | Optimizer: adam\n","\n","\u001b[1mModule Species          || Module Species Avg Fitness          || Module Species Size\u001b[0m\n","     1                  ||  64.0526                            ||        4\n","Best Mod of Species 1   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #7 | Fitness: 85.1812 | Filters:   96 | Kernel:      1 | Activ:    elu | Pool Size:      1 | Dropout: None\n","     2                  ||  97.9167                            ||        1\n","Best Mod of Species 2   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #6 | Fitness: 97.9167 | Filters:  224 | Kernel:      2 | Activ: linear | Pool Size:      1 | Dropout:  0.1\n","\n","\u001b[1m##############################################################################################################################################\u001b[0m\n","\n","Backed up generation 2 of the CoDeepNEAT evolutionary run to file: /content/tfne_state_backups/tfne_state_backup_2024-Aug-06_15-55-15/tfne_state_backup_gen_2.json\n","\n","Evaluating 80 genomes in generation 3...\n","[========================================] 80/80 Genomes | Genome ID 320 achieved fitness of 97.5\n","\n","\n","\u001b[1m############################################################  Population Summary  ############################################################\n","\n","Generation:    3  ||  Best Genome Fitness:  99.1667  ||  Avg Blueprint Fitness:  75.6562  ||  Avg Module Fitness:  59.0826\u001b[0m\n","Best Genome: CoDeepNEAT Genome | ID:    259 | Fitness: 99.1667 | Blueprint ID:     18 | Module Species: {2} | Optimizer:   adam | Origin Gen:    3\n","\n","\u001b[1mBlueprint Species       || Blueprint Species Avg Fitness       || Blueprint Species Size\u001b[0m\n","     1                  ||  75.6562                            ||        8\n","Best BP of Species 1    || CoDeepNEAT Blueprint | ID:    #25 | Fitness:   98.5 | Nodes:    2 | Module Species: {2} | Optimizer: adam\n","\n","\u001b[1mModule Species          || Module Species Avg Fitness          || Module Species Size\u001b[0m\n","     1                  ||  52.8838                            ||        3\n","Best Mod of Species 1   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #7 | Fitness: 55.8889 | Filters:   96 | Kernel:      1 | Activ:    elu | Pool Size:      1 | Dropout: None\n","     2                  ||  68.3808                            ||        2\n","Best Mod of Species 2   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:    #12 | Fitness: 73.5026 | Filters:  224 | Kernel:      3 | Activ: linear | Pool Size:      1 | Dropout:  0.1\n","\n","\u001b[1m##############################################################################################################################################\u001b[0m\n","\n","Backed up generation 3 of the CoDeepNEAT evolutionary run to file: /content/tfne_state_backups/tfne_state_backup_2024-Aug-06_15-55-15/tfne_state_backup_gen_3.json\n","\n","Evaluating 80 genomes in generation 4...\n","[========================================] 80/80 Genomes | Genome ID 400 achieved fitness of 97.0833\n","\n","\n","\u001b[1m############################################################  Population Summary  ############################################################\n","\n","Generation:    4  ||  Best Genome Fitness:  99.1667  ||  Avg Blueprint Fitness:  97.5729  ||  Avg Module Fitness:  97.1636\u001b[0m\n","Best Genome: CoDeepNEAT Genome | ID:    259 | Fitness: 99.1667 | Blueprint ID:     18 | Module Species: {2} | Optimizer:   adam | Origin Gen:    3\n","\n","\u001b[1mBlueprint Species       || Blueprint Species Avg Fitness       || Blueprint Species Size\u001b[0m\n","     1                  ||  97.5729                            ||        8\n","Best BP of Species 1    || CoDeepNEAT Blueprint | ID:    #31 | Fitness: 98.125 | Nodes:    2 | Module Species: {2} | Optimizer: adam\n","\n","\u001b[1mModule Species          || Module Species Avg Fitness          || Module Species Size\u001b[0m\n","     1                  ||  96.5972                            ||        3\n","Best Mod of Species 1   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:    #10 | Fitness: 96.9792 | Filters:  104 | Kernel:      2 | Activ:    elu | Pool Size:   None | Dropout:  0.7\n","     2                  ||  97.7299                            ||        3\n","Best Mod of Species 2   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:    #12 | Fitness: 98.2765 | Filters:  224 | Kernel:      3 | Activ: linear | Pool Size:      1 | Dropout:  0.1\n","\n","\u001b[1m##############################################################################################################################################\u001b[0m\n","\n","Backed up generation 4 of the CoDeepNEAT evolutionary run to file: /content/tfne_state_backups/tfne_state_backup_2024-Aug-06_15-55-15/tfne_state_backup_gen_4.json\n","\n","Evaluating 80 genomes in generation 5...\n","[========================================] 80/80 Genomes | Genome ID 480 achieved fitness of 97.0833\n","\n","\n","\u001b[1m############################################################  Population Summary  ############################################################\n","\n","Generation:    5  ||  Best Genome Fitness:  99.1667  ||  Avg Blueprint Fitness:  68.9844  ||  Avg Module Fitness:  71.9553\u001b[0m\n","Best Genome: CoDeepNEAT Genome | ID:    259 | Fitness: 99.1667 | Blueprint ID:     18 | Module Species: {2} | Optimizer:   adam | Origin Gen:    3\n","\n","\u001b[1mBlueprint Species       || Blueprint Species Avg Fitness       || Blueprint Species Size\u001b[0m\n","     1                  ||  68.5714                            ||        7\n","Best BP of Species 1    || CoDeepNEAT Blueprint | ID:    #38 | Fitness: 97.3333 | Nodes:    2 | Module Species: {1} | Optimizer: adam\n","     2                  ||   71.875                            ||        1\n","Best BP of Species 2    || CoDeepNEAT Blueprint | ID:    #33 | Fitness: 71.875 | Nodes:    3 | Module Species: {1, 2} | Optimizer: adam\n","\n","\u001b[1mModule Species          || Module Species Avg Fitness          || Module Species Size\u001b[0m\n","     1                  ||  84.3692                            ||        3\n","Best Mod of Species 1   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:    #15 | Fitness: 98.125 | Filters:  112 | Kernel:      2 | Activ:    elu | Pool Size:   None | Dropout:  0.7\n","     2                  ||  59.5414                            ||        3\n","Best Mod of Species 2   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #6 | Fitness: 84.9537 | Filters:  224 | Kernel:      2 | Activ: linear | Pool Size:      1 | Dropout:  0.1\n","\n","\u001b[1m##############################################################################################################################################\u001b[0m\n","\n","Backed up generation 5 of the CoDeepNEAT evolutionary run to file: /content/tfne_state_backups/tfne_state_backup_2024-Aug-06_15-55-15/tfne_state_backup_gen_5.json\n","Population reached specified maximum number of generations.\n","Exiting evolutionary training loop...\n","\n","> Mejor red generada por la evolución:\n","\n","CoDeepNEAT Genome | ID:    259 | Fitness: 99.1667 | Blueprint ID:     18 | Module Species: {2} | Optimizer:   adam | Origin Gen:    3\n","\n","\n","Saved CoDeepNEAT genome (ID: 259) to file: ./best_genome_genotype_ori/genome_259_genotype.json\n"]},{"output_type":"stream","name":"stderr","text":["INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to model_dense_biasadd_readvariableop_resource in the SavedModel.\n","INFO:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n","INFO:absl:Sharding callback duration: 33\n","INFO:absl:Sharding callback duration: 18\n","INFO:absl:Writing fingerprint to ./best_genome_model_ori/fingerprint.pb\n"]},{"output_type":"stream","name":"stdout","text":["\n","Modelo recuperado de  ./best_genome_model_ori/\n","\n","\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 32, 32, 224)       6272      \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 32, 32, 224)       0         \n"," D)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 32, 32, 224)       0         \n","                                                                 \n"," flatten (Flatten)           (None, 229376)            0         \n","                                                                 \n"," dense (Dense)               (None, 10)                2293770   \n","                                                                 \n","=================================================================\n","Total params: 2300042 (8.77 MB)\n","Trainable params: 2300042 (8.77 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n"]}],"source":["#@title Ejecutar NeuroEvolution con TFNE\n","\n","logging_level = logging.INFO\n","config_file_path = confFileName # './codeepneat_xor_basic_example_config.cfg'\n","backup_dir_path = './tfne_state_backups/'\n","max_generations = ce_maximo_generaciones_procesar\n","\n","# Set logging, parse config\n","logging.set_verbosity(logging_level)\n","config = tfne.parse_configuration(config_file_path)\n","\n","# Initialize the environment and the specific NE algorithm\n","environment = RNAEnvironment(weight_training=True,\n","                             data_x=x_train,\n","                             data_y=y_trainEnc,\n","                             config=config,\n","                             verbosity=logging_level)\n","\n","print(\">  Definiendo configuración:\")\n","ne_algorithm = tfne.algorithms.CoDeepNEAT(config)\n","\n","# determina si termina por alcanzar la máxima o no\n","if ce_finalizar_al_encontrar_max_fitness:\n","  max_fitness = environment.return_MaxFitness()\n","else:\n","  max_fitness = None\n","\n","\n","# Initialize evolution engine and supply config as well as initialized NE algorithm and evaluation environment.\n","engine = tfne.EvolutionEngine(ne_algorithm=ne_algorithm,\n","                              environment=environment,\n","                              backup_dir_path=backup_dir_path,\n","                              max_generations=max_generations,\n","                              max_fitness=max_fitness)\n","\n","# Start training process, returning the best genome when training ends\n","best_genome = engine.train()\n","print(\"\\n> Mejor red generada por la evolución:\\n\")\n","print(best_genome)\n","print(\"\\n\")\n","\n","# Graba mejor genotipo y su modelo TF antes del re-entrenamiento\n","best_genotype_ori_dir = './best_genome_genotype_ori/'\n","best_model_ori_dir = './best_genome_model_ori/'\n","best_genome.save_genotype(save_dir_path=best_genotype_ori_dir)\n","best_genome.save_model(file_path=best_model_ori_dir)\n","\n","# determina el mejor modelo obtenido\n","model = tf.keras.models.load_model(best_model_ori_dir)\n","print(\"\\nModelo recuperado de \", best_model_ori_dir)\n","\n","print(\"\\n\")\n","model.summary()\n","print(\"\\n\")\n"]},{"cell_type":"code","metadata":{"id":"ZzmLDXuUHkdf","colab":{"base_uri":"https://localhost:8080/","height":755,"referenced_widgets":["d3b0dc9e3c0f49b990d464540b40498a","dfec95a273a64a918606c2d2fee6bc34","ad6d078963964015b5ddab2a3ddf4307","0f592f1442a74636be68e4df2231709f","25003dc339d94a3cb710bfca2862a380","704cfb72a6434efb9d88502d1db13746","61ddfed2697c4efd812b13b7cfc91b9f","cef4e80041d44ee59cd5025cde4c6294","cba3fcd9e25143da9a91ae6f56f2c6b3","e21a8e0d49754d8589452dffa575565e","d24cfd26c7a344a4ae56b3a6c0b2672b","6125db2200a54ce29db0bdf64018d041","215e0ddca8d24157a5f7bc8dc29d49eb"]},"executionInfo":{"status":"ok","timestamp":1722963300406,"user_tz":180,"elapsed":465,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}},"outputId":"4517c357-1820-4e1e-b92f-c4d79a6ea0a6","cellView":"form"},"source":["#@title Evaluar red entrenada con datos de entrenamiento\n","\n","\n","# función auxiliar para probar el modelo entrenado en detalle\n","def probarModelo(x, y, clases_map, tipo_output_softMax, umbralClas=50.0, mostrarGradCAM=False, rtdo=\"TODOS\", cantMostrar=\"TODAS\", claseFiltrar=None):\n","\n","    # determina clase a filtrar\n","    if (claseFiltrar is None) or (claseFiltrar == \"-\"):\n","          clFiltrarID = None\n","          mostrarImagenes = False\n","    elif (claseFiltrar == \"TODOS\"):\n","          clFiltrarID = None\n","          mostrarImagenes = True\n","    else:\n","          clFiltrarID = dictMapeo[claseFiltrar]\n","          mostrarImagenes = True\n","    if umbralClas <= 0.0:\n","      umbralClas = 0.1\n","    elif umbralClas >= 100.0:\n","      umbralClas = 99.0\n","    else:\n","      umbralClas = umbralClas/100.0\n","\n","    # determina tipo de resultado a mostrar\n","    if rtdo == \"Clasificación Incorrecta\":\n","      tipoRes = -1\n","    elif rtdo == \"Clasificación Correcta\":\n","      tipoRes = 1\n","    else:\n","      tipoRes = 0\n","\n","    # determina cantidad a mostrar\n","    if (cantMostrar == \"TODAS\"):\n","      cantMostrar = len(x)\n","    elif (cantMostrar <= 0):\n","      cantMostrar = 0\n","      mostrarImagenes = False\n","\n","    # procesa las imágenes de prueba con el modelo\n","    predClass = model.predict(x, verbose=0)\n","\n","    # lista auxiliar para mostrar\n","    imgsParaMostrar = []\n","\n","    # muestra los resultados con las imágenes\n","    classPreds = []\n","    classReal = []\n","    for i in range(len(x)):\n","\n","        # asigna el nombre de la clase real\n","        clReal = clases_map[ y[i] ]\n","\n","        # determina la clase predecida\n","        if tipo_output_softMax:\n","            ## determina clase predecida de acuerdo a la que tiene mayor valor\n","            idclPred = int( np.argmax(predClass[i], axis=0) )\n","            idclPredRnd = idclPred\n","        else:\n","            ## determina clase predecida de acuerdo al umbral de clasificación\n","            idclPred = predClass[i][0]\n","            idclPredRnd = int(idclPred)\n","            if (idclPred - idclPredRnd)>umbralClas and (idclPredRnd+1)<len(clases_map):\n","                  idclPredRnd = idclPredRnd + 1\n","\n","        # asigna el nombre de la clase predecida\n","        if idclPredRnd<0 or idclPredRnd>=len(clases_map):\n","            clPred = \"CLASE \" + str(idclPredRnd) + \" INVÁLIDA!\"\n","        else:\n","            clPred = clases_map[ idclPredRnd ]\n","\n","        # agrega a vevtores auxiliares\n","        classReal.append( clReal )\n","        classPreds.append( clPred )\n","        resClasOK = (clReal==clPred)\n","\n","        if mostrarImagenes:\n","\n","          # determina si filtra por clase\n","          if (clFiltrarID is None) or (clFiltrarID == y[i]):\n","\n","            # filtra por tipo de resultado\n","            if (tipoRes==0) or \\\n","              ((tipoRes > 0) and resClasOK) or\\\n","              ((tipoRes < 0) and not(resClasOK)):\n","                # el titulo par aponer en la imagen\n","                strTitulo = 'Real: ' + str(clReal) + ' / Modelo: ' + str(clPred)\n","                if not resClasOK:\n","                  strTitulo = strTitulo + \"!\"\n","                #strTitulo = strTitulo + clPred + ' (' + str( idclPred ) +')'\n","\n","                # agrega para mostrar\n","                imgsParaMostrar.append( [strTitulo, x[i] ] )\n","\n","\n","    # cierra la imagen\n","    if mostrarImagenes and (cantMostrar>0) and (len(imgsParaMostrar)>0):\n","      print(\"\\n>Detalle: \")\n","\n","      if cantMostrar >= len(imgsParaMostrar):\n","        # muestra todas\n","        eligeImAlAzar = False\n","        cantMostrar = len(imgsParaMostrar)\n","      else:\n","        # muestra al azar\n","        eligeImAlAzar = True\n","\n","      # prepara para mostrar imagenes\n","      if mostrarGradCAM:\n","        nCols = 2\n","        nRows = cantMostrar\n","        plt.figure(figsize=(5, 3*nRows))\n","      else:\n","        nCols = 3\n","        nRows = cantMostrar // nCols\n","        if (nRows*nCols) < cantMostrar:\n","          nRows = nRows + 1\n","        plt.figure(figsize=(10, 3*nRows))\n","      posImagen = 1\n","\n","      for i in range(cantMostrar):\n","            # elige al azar o no para mostrar\n","            if eligeImAlAzar:\n","              posIm = random.randint(1, len(imgsParaMostrar))-1\n","            else:\n","              if i >= len(imgsParaMostrar):\n","                break\n","              else:\n","                posIm = i\n","            # determina datos a mostrar\n","            im = imgsParaMostrar[posIm][1]\n","            tit = imgsParaMostrar[posIm][0]\n","\n","            # muestra la imagen\n","            ax = plt.subplot(nRows, nCols, posImagen)\n","            plot_image( im )\n","            plt.title( tit, fontsize=9 )\n","            posImagen = posImagen + 1\n","\n","            # saca elemento de la lista para no elegirlo al azar de nuevo\n","            if eligeImAlAzar:\n","              if len(imgsParaMostrar) > posIm:\n","                imgsParaMostrar.pop( posIm )\n","\n","      #plt.tight_layout()\n","      fig = plt.gcf()\n","      plt.show()\n","      plt.close(fig)\n","\n","    # muestra reporte de clasificación\n","    print(\"\\n Reporte de Clasificación: \")\n","    print(classification_report(classReal, classPreds, zero_division=0))\n","\n","    # muestra matriz de confusion\n","    print('\\nMatriz de Confusión ( real / modelo ): ')\n","    cm = confusion_matrix(classReal, classPreds, labels=clases_map)\n","    cmtx = pd.DataFrame(\n","        cm,\n","        index=['r:{:}'.format(x) for x in clases_map],\n","        columns=['m:{:}'.format(x) for x in clases_map]\n","      )\n","    cmtx.sort_index(axis=0, inplace=True)\n","    cmtx.sort_index(axis=1, inplace=True)\n","    print(cmtx)\n","    print(\"\\n\")\n","\n","\n","# genera toda la interface para evaluar modeo DAE\n","def crearUI_evaluarModelo(clDefecto, clases, ruidoPorDefecto, funcionCambiaSeleccion):\n","\n","  # auxiliar para que muestre bien la descripción\n","  style_3D = {'description_width': 'initial'}\n","  childrenList = []\n","\n","  slider_umbral = widgets.FloatSlider(\n","      value=50,\n","      min=0,\n","      max=100.0,\n","      step=1.0,\n","      description='Umbral de Clasificación: ',\n","      disabled=False,\n","      continuous_update=False,\n","      orientation='horizontal',\n","      readout=True,\n","      style=style_3D,\n","      readout_format='.1f',\n","  )\n","  if not tipo_output_softMax:\n","    childrenList.append( slider_umbral )\n","\n","  # prepara combo para filtrar por clase\n","  seleccion_CLASES = [\"-\", \"TODOS\"]\n","  seleccion_CLASES.extend( clases )\n","  seleccion_CLASES.sort()\n","  combo_clase = widgets.Dropdown(\n","      options = seleccion_CLASES,\n","      value = clDefecto,\n","      description = 'Filtrar por clase:',\n","      style=style_3D,\n","      disabled = False,\n","  )\n","  childrenList.append( combo_clase )\n","\n","  # prepara combo para filtrar por resultado\n","  selecc_resutado = [ \"TODOS\", \"Clasificación Incorrecta\", \"Clasificación Correcta\" ]\n","  combo_resultado = widgets.Dropdown(\n","      options = selecc_resutado,\n","      value = selecc_resutado[0],\n","      description = 'Filtrar por resultado:',\n","      style=style_3D,\n","      disabled = False,\n","  )\n","  childrenList.append( combo_resultado )\n","\n","  # prepara combo para filtrar por cantidad\n","  selecc_cantidad = [ 3 ]\n","  selecc_cantidad.extend( range(6, 151, 9) )\n","  selecc_cantidad.append( \"TODAS\" )\n","  combo_cantidad = widgets.Dropdown(\n","      options = selecc_cantidad,\n","      value = 6,\n","      description = 'Mostrar N imágenes al azar:',\n","      style=style_3D,\n","      disabled = False,\n","  )\n","  childrenList.append( combo_cantidad )\n","\n","  prueba_ui = widgets.GridBox(children=childrenList,\n","          layout=Layout(width='100%')\n","        )\n","  out_prueba = widgets.interactive_output(funcionCambiaSeleccion, {'cant':combo_cantidad, 'rtdo': combo_resultado,'cl':combo_clase, 'umbralClas':slider_umbral})\n","\n","  return prueba_ui, out_prueba\n","\n","# función para filtrar por clase\n","def cambiaSeleccion_clase_evaluar_imEntrenamiento(cant, rtdo, cl, umbralClas):\n","\n","    # prueba con los datos de entrenamiento\n","    print(\"\\n\\n*** Resultados con datos de Entrenamiento: \")\n","    probarModelo(x_train, y_train, clases_map, tipo_output_softMax, umbralClas, False, rtdo, cant, cl)\n","\n","# muestra la interface\n","ev_entrenamiento_ui, ev_entrenamiento_out = crearUI_evaluarModelo( \"-\", clases_map, 0.0, cambiaSeleccion_clase_evaluar_imEntrenamiento)\n","display(ev_entrenamiento_ui, ev_entrenamiento_out)\n"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","*** Resultados con datos de Entrenamiento: \n","\n"," Reporte de Clasificación: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.92      0.96        24\n","           1       0.96      1.00      0.98        24\n","           2       1.00      1.00      1.00        24\n","           3       1.00      1.00      1.00        24\n","           4       1.00      1.00      1.00        24\n","           5       1.00      1.00      1.00        24\n","           6       1.00      1.00      1.00        24\n","           7       1.00      1.00      1.00        24\n","           8       0.96      1.00      0.98        24\n","           9       1.00      1.00      1.00        24\n","\n","    accuracy                           0.99       240\n","   macro avg       0.99      0.99      0.99       240\n","weighted avg       0.99      0.99      0.99       240\n","\n","\n","Matriz de Confusión ( real / modelo ): \n","     m:0  m:1  m:2  m:3  m:4  m:5  m:6  m:7  m:8  m:9\n","r:0   22    1    0    0    0    0    0    0    1    0\n","r:1    0   24    0    0    0    0    0    0    0    0\n","r:2    0    0   24    0    0    0    0    0    0    0\n","r:3    0    0    0   24    0    0    0    0    0    0\n","r:4    0    0    0    0   24    0    0    0    0    0\n","r:5    0    0    0    0    0   24    0    0    0    0\n","r:6    0    0    0    0    0    0   24    0    0    0\n","r:7    0    0    0    0    0    0    0   24    0    0\n","r:8    0    0    0    0    0    0    0    0   24    0\n","r:9    0    0    0    0    0    0    0    0    0   24\n","\n","\n"]},{"output_type":"display_data","data":{"text/plain":["GridBox(children=(Dropdown(description='Filtrar por clase:', options=('-', '0', '1', '2', '3', '4', '5', '6', …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3b0dc9e3c0f49b990d464540b40498a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6125db2200a54ce29db0bdf64018d041"}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"A15K-9TRtq7U","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":755,"referenced_widgets":["8b6212a482df4b72bf3bddd2b6c107e1","c6b922dcf14046639e8403a62e1c8753","85156a4622ea4526ba878a3c878a03cb","b20f99fddf214585bc3c2810d206456b","bd8e83343b894316b36aaad69fe34a44","0e111da4560247e7a0e485ddbaefd22c","a9c65e4400b840579e59ad18c1a0d942","a2706b8b0a34468cb1873083db905e14","01d5357f2a9e47cba8269c84a84f3a3c","ada62c26dd704be48990bf70d8df5229","aa570c0affce41098f01a2cad6296da2","5220d2a07e714317a7e81bc5b51152dd","7b16a33d712a4c4faa8ced59b4b056fb"]},"executionInfo":{"status":"ok","timestamp":1722963300408,"user_tz":180,"elapsed":4,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}},"outputId":"60205d65-d0cb-4326-ae69-58af8f247e51"},"source":["#@title Evaluar red entrenada con datos de prueba\n","\n","# función para filtrar por clase\n","def cambiaSeleccion_clase_evaluar_imEntrenamiento(cant, rtdo, cl, umbralClas):\n","\n","  # prueba con los datos de prueba\n","  print(\"\\n\\n*** Resultados con datos de Prueba: \")\n","  probarModelo(x_test, y_test, clases_map, tipo_output_softMax, umbralClas, False, rtdo, cant, cl)\n","\n","# muestra la interface\n","ev_entrenamiento_ui, ev_entrenamiento_out = crearUI_evaluarModelo( \"-\", clases_map, 0.0, cambiaSeleccion_clase_evaluar_imEntrenamiento)\n","display(ev_entrenamiento_ui, ev_entrenamiento_out)\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","*** Resultados con datos de Prueba: \n","\n"," Reporte de Clasificación: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.83      0.91         6\n","           1       1.00      1.00      1.00         6\n","           2       1.00      1.00      1.00         6\n","           3       0.86      1.00      0.92         6\n","           4       1.00      0.83      0.91         6\n","           5       0.86      1.00      0.92         6\n","           6       1.00      0.67      0.80         6\n","           7       0.75      1.00      0.86         6\n","           8       0.86      1.00      0.92         6\n","           9       1.00      0.83      0.91         6\n","\n","    accuracy                           0.92        60\n","   macro avg       0.93      0.92      0.92        60\n","weighted avg       0.93      0.92      0.92        60\n","\n","\n","Matriz de Confusión ( real / modelo ): \n","     m:0  m:1  m:2  m:3  m:4  m:5  m:6  m:7  m:8  m:9\n","r:0    5    0    0    0    0    0    0    0    1    0\n","r:1    0    6    0    0    0    0    0    0    0    0\n","r:2    0    0    6    0    0    0    0    0    0    0\n","r:3    0    0    0    6    0    0    0    0    0    0\n","r:4    0    0    0    0    5    0    0    1    0    0\n","r:5    0    0    0    0    0    6    0    0    0    0\n","r:6    0    0    0    1    0    1    4    0    0    0\n","r:7    0    0    0    0    0    0    0    6    0    0\n","r:8    0    0    0    0    0    0    0    0    6    0\n","r:9    0    0    0    0    0    0    0    1    0    5\n","\n","\n"]},{"output_type":"display_data","data":{"text/plain":["GridBox(children=(Dropdown(description='Filtrar por clase:', options=('-', '0', '1', '2', '3', '4', '5', '6', …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b6212a482df4b72bf3bddd2b6c107e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5220d2a07e714317a7e81bc5b51152dd"}},"metadata":{}}]},{"cell_type":"code","source":["#@title Guardar Modelo entrenado\n","\n","guardar_modelo = True #@param{type:\"boolean\"}\n","path_modelo = '/content/gdrive/MyDrive/IA/demoCESwarm/NeuroEvolution/modelos/imagenesTFNE'  #@param {type:\"string\"}\n","\n","if guardar_modelo:\n","\n","    # guarda el modelo entrenado\n","    model.save(path_modelo)\n","    print(\"\\n-Modelo guardado en \", path_modelo,\"\\n\")\n","\n","    if (\"IMAGE_SHAPE\" in locals()) and (IMAGE_SHAPE is not None):\n","      fn_imageShape = path_modelo+\"/IMAGE_SHAPE.txt\"\n","      with open(fn_imageShape, 'w') as f:\n","        for i in IMAGE_SHAPE:\n","          f.write(str(i)+\"\\n\")\n","      print(\"\\n-IMAGE_SHAPE para cargar las imágenes guardado en \", path_modelo,\"\\n\")\n","\n","\n","    if (\"clases_map\" in locals()) and (clases_map is not None):\n","      fn_clases = path_modelo+\"/CLASES_MAP.txt\"\n","      with open(fn_clases, 'w') as f:\n","        for i in range(len(clases_map)):\n","          f.write(str(i)+\":\"+str(clases_map[i])+\"\\n\")\n","      print(\"\\n-CLASES_MAP para mostrar los resultados guardado en \", path_modelo,\"\\n\")\n","\n","else:\n","    print(\"\\n-Modelo no guardado.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"ULW99MrSBbZN","executionInfo":{"status":"ok","timestamp":1722963302038,"user_tz":180,"elapsed":1632,"user":{"displayName":"PGP Posgrado","userId":"11221123485986209538"}},"outputId":"16aaaeda-de9a-4acd-fbed-80222eedf591"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to model_dense_biasadd_readvariableop_resource in the SavedModel.\n","INFO:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n","INFO:absl:Sharding callback duration: 6\n","INFO:absl:Sharding callback duration: 9\n","INFO:absl:Writing fingerprint to /content/gdrive/MyDrive/IA/demoCESwarm/NeuroEvolution/modelos/imagenesTFNE/fingerprint.pb\n"]},{"output_type":"stream","name":"stdout","text":["\n","-Modelo guardado en  /content/gdrive/MyDrive/IA/demoCESwarm/NeuroEvolution/modelos/imagenesTFNE \n","\n","\n","-IMAGE_SHAPE para cargar las imágenes guardado en  /content/gdrive/MyDrive/IA/demoCESwarm/NeuroEvolution/modelos/imagenesTFNE \n","\n","\n","-CLASES_MAP para mostrar los resultados guardado en  /content/gdrive/MyDrive/IA/demoCESwarm/NeuroEvolution/modelos/imagenesTFNE \n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d3b0dc9e3c0f49b990d464540b40498a":{"model_module":"@jupyter-widgets/controls","model_name":"GridBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"GridBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"GridBoxView","box_style":"","children":["IPY_MODEL_dfec95a273a64a918606c2d2fee6bc34","IPY_MODEL_ad6d078963964015b5ddab2a3ddf4307","IPY_MODEL_0f592f1442a74636be68e4df2231709f"],"layout":"IPY_MODEL_25003dc339d94a3cb710bfca2862a380"}},"dfec95a273a64a918606c2d2fee6bc34":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["-","0","1","2","3","4","5","6","7","8","9","TODOS"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Filtrar por clase:","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_704cfb72a6434efb9d88502d1db13746","style":"IPY_MODEL_61ddfed2697c4efd812b13b7cfc91b9f"}},"ad6d078963964015b5ddab2a3ddf4307":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["TODOS","Clasificación Incorrecta","Clasificación Correcta"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Filtrar por resultado:","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_cef4e80041d44ee59cd5025cde4c6294","style":"IPY_MODEL_cba3fcd9e25143da9a91ae6f56f2c6b3"}},"0f592f1442a74636be68e4df2231709f":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["3","6","15","24","33","42","51","60","69","78","87","96","105","114","123","132","141","150","TODAS"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Mostrar N imágenes al azar:","description_tooltip":null,"disabled":false,"index":1,"layout":"IPY_MODEL_e21a8e0d49754d8589452dffa575565e","style":"IPY_MODEL_d24cfd26c7a344a4ae56b3a6c0b2672b"}},"25003dc339d94a3cb710bfca2862a380":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"704cfb72a6434efb9d88502d1db13746":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61ddfed2697c4efd812b13b7cfc91b9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"cef4e80041d44ee59cd5025cde4c6294":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cba3fcd9e25143da9a91ae6f56f2c6b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"e21a8e0d49754d8589452dffa575565e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d24cfd26c7a344a4ae56b3a6c0b2672b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"6125db2200a54ce29db0bdf64018d041":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_215e0ddca8d24157a5f7bc8dc29d49eb","msg_id":"","outputs":[]}},"215e0ddca8d24157a5f7bc8dc29d49eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b6212a482df4b72bf3bddd2b6c107e1":{"model_module":"@jupyter-widgets/controls","model_name":"GridBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"GridBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"GridBoxView","box_style":"","children":["IPY_MODEL_c6b922dcf14046639e8403a62e1c8753","IPY_MODEL_85156a4622ea4526ba878a3c878a03cb","IPY_MODEL_b20f99fddf214585bc3c2810d206456b"],"layout":"IPY_MODEL_bd8e83343b894316b36aaad69fe34a44"}},"c6b922dcf14046639e8403a62e1c8753":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["-","0","1","2","3","4","5","6","7","8","9","TODOS"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Filtrar por clase:","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_0e111da4560247e7a0e485ddbaefd22c","style":"IPY_MODEL_a9c65e4400b840579e59ad18c1a0d942"}},"85156a4622ea4526ba878a3c878a03cb":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["TODOS","Clasificación Incorrecta","Clasificación Correcta"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Filtrar por resultado:","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_a2706b8b0a34468cb1873083db905e14","style":"IPY_MODEL_01d5357f2a9e47cba8269c84a84f3a3c"}},"b20f99fddf214585bc3c2810d206456b":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["3","6","15","24","33","42","51","60","69","78","87","96","105","114","123","132","141","150","TODAS"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Mostrar N imágenes al azar:","description_tooltip":null,"disabled":false,"index":1,"layout":"IPY_MODEL_ada62c26dd704be48990bf70d8df5229","style":"IPY_MODEL_aa570c0affce41098f01a2cad6296da2"}},"bd8e83343b894316b36aaad69fe34a44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"0e111da4560247e7a0e485ddbaefd22c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9c65e4400b840579e59ad18c1a0d942":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"a2706b8b0a34468cb1873083db905e14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01d5357f2a9e47cba8269c84a84f3a3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"ada62c26dd704be48990bf70d8df5229":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa570c0affce41098f01a2cad6296da2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"5220d2a07e714317a7e81bc5b51152dd":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_7b16a33d712a4c4faa8ced59b4b056fb","msg_id":"","outputs":[]}},"7b16a33d712a4c4faa8ced59b4b056fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}