{"cells":[{"cell_type":"markdown","metadata":{"id":"1Tu5MvS864Vv"},"source":["#Demo NeuroEvolution usando Tensorflow-Neuroevolution framework (TFNE) para generar una red Convolucional que pueda aprender a clasificar en base a imágenes\n","Fuente TFNE: https://github.com/PaulPauls/Tensorflow-Neuroevolution"]},{"cell_type":"markdown","metadata":{"id":"ZyCmxopcGYCB"},"source":["0) Preparar ambiente:"]},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","id":"i79ux8zd64wv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696945598197,"user_tz":180,"elapsed":23952,"user":{"displayName":"PABLO GONZALO PYTEL","userId":"07736403464797369193"}},"outputId":"24c43d7f-58e2-4f95-cd0c-7ee143e6dd30"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tfne\n","  Downloading tfne-0.21.1-py3-none-any.whl (125 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.0/125.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from tfne) (2.13.0)\n","Collecting ray (from tfne)\n","  Downloading ray-2.7.1-cp310-cp310-manylinux2014_x86_64.whl (62.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from tfne) (0.20.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tfne) (3.7.1)\n","Collecting PyQt5 (from tfne)\n","  Downloading PyQt5-5.15.9-cp37-abi3-manylinux_2_17_x86_64.whl (8.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from tfne) (1.4.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (1.59.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (3.9.0)\n","Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (2.13.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (16.0.6)\n","Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (1.16.0)\n","Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (2.13.0)\n","Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (2.13.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (2.3.0)\n","Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (1.15.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->tfne) (0.34.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (0.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (4.43.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tfne) (2.8.2)\n","Collecting PyQt5-sip<13,>=12.11 (from PyQt5->tfne)\n","  Downloading PyQt5_sip-12.12.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.whl (337 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.9/337.9 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyQt5-Qt5>=5.15.2 (from PyQt5->tfne)\n","  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (8.1.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (3.12.4)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (4.19.1)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (1.0.7)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (6.0.1)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (1.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray->tfne) (2.31.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->tfne) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->tfne) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->tfne) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->tfne) (3.4.4)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->tfne) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.0.0->tfne) (3.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray->tfne) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray->tfne) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray->tfne) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray->tfne) (2023.7.22)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->tfne) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->tfne) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->tfne) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->tfne) (0.10.4)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->tfne) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->tfne) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->tfne) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->tfne) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->tfne) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->tfne) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.0.0->tfne) (3.2.2)\n","Installing collected packages: PyQt5-Qt5, PyQt5-sip, PyQt5, ray, tfne\n","Successfully installed PyQt5-5.15.9 PyQt5-Qt5-5.15.2 PyQt5-sip-12.12.2 ray-2.7.1 tfne-0.21.1\n"]}],"source":["#@title Instalar TFNE\n","!pip install tfne\n","\n","###!git clone https://github.com/PaulPauls/Tensorflow-Neuroevolution\n","###%cd Tensorflow-Neuroevolution\n","###!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"soqbTJnR-vgh"},"source":["1) Cargar librerías:"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"b4oaPcXw-uzT","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696945604950,"user_tz":180,"elapsed":6769,"user":{"displayName":"PABLO GONZALO PYTEL","userId":"07736403464797369193"}},"outputId":"0cf2d711-d770-44d3-ecf9-ccaf17abef71"},"outputs":[{"output_type":"stream","name":"stdout","text":["Librerías cargadas\n"]}],"source":["#@title Librerías a usar\n","from __future__ import annotations\n","from absl import app, flags, logging\n","\n","import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","import os\n","import csv\n","\n","import tfne\n","from tfne.environments import BaseEnvironment\n","from tfne.helper_functions import read_option_from_config\n","\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","print(\"Librerías cargadas\")"]},{"cell_type":"markdown","metadata":{"id":"cnL_qtVxM_DN"},"source":["2) Determinar configuración:"]},{"cell_type":"code","execution_count":21,"metadata":{"cellView":"form","id":"yU_Vllt7GzIW","executionInfo":{"status":"ok","timestamp":1696946942494,"user_tz":180,"elapsed":20,"user":{"displayName":"PABLO GONZALO PYTEL","userId":"07736403464797369193"}}},"outputs":[],"source":["#@title Parámetros para NeuroEvolution\n","\n","#@markdown Criterio de Paro:\n","ce_maximo_generaciones_procesar = 5 #@param {type:\"integer\"}\n","ce_finalizar_al_encontrar_max_fitness = True #@param {type:\"boolean\"}\n","#@markdown Función de Aptitud:\n","fitness_calc_usando_exactitud = \"Suma Entrenamiento & Validacion\" #@param [\"Entrenamiento\", \"Validacion\", \"Min Entrenamiento & Validacion\", \"Promedio Entrenamiento & Validacion\", \"Suma Entrenamiento & Validacion\"]\n","fitness_penalizar_x_topologia = False #param {type:\"boolean\"}\n","#@markdown Blueprints (topología & optimizador):\n","ce_cant_poblacion_blueprints =  5#@param {type:\"integer\"}\n","#@markdown  Genomas (instancias de RNAs):\n","ce_cant_genomas_por_blueprint =  3#@param {type:\"integer\"}\n","#@markdown Módulos (capas RNA):\n","ce_cant_poblacion_modulos =  3#@param {type:\"integer\"}\n","ce_tipo_generacion_modulos = \"Dinamica\" #@param [\"Basica\", \"Dinamica\", \"Fija\"]\n","#@markdown Operadores Genéticos:\n","ce_max_mutacion = 0.5 #@param {type:\"number\"}\n","ce_probab_mutacion = 0.6 #@param {type:\"number\"}\n","ce_probab_cruzamiento = 0.4 #@param {type:\"number\"}\n","#@markdown Entrenamiento RNA:\n","rna_cant_epocas_entrenamiento = 50#@param {type:\"integer\"}\n","rna_cant_epocas_entrenamiento_incrementa_por_generacion = 25#@param {type:\"integer\"}\n","rna_cant_epocas_reentrenamiento_best_final =   350#@param {type:\"integer\"}\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"cellView":"form","id":"a8aPzMxQNCT2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696946945367,"user_tz":180,"elapsed":2891,"user":{"displayName":"PABLO GONZALO PYTEL","userId":"07736403464797369193"}},"outputId":"4e89bd23-87c2-44f2-f963-cc91bfff2951"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Tamaño Imagen:  (16, 16, 3)\n"]}],"source":["#@title Imágenes a Usar\n","\n","# monta Google Drive:\n","# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# directorio local en Google Drive\n","path = '/content/gdrive/My Drive/IA/demoML/imagenes/NUMEROS'  #@param {type:\"string\"}\n","\n","#@markdown ### Subdirectorios de las imágenes:\n","\n","path_entrenamiento = '/train'  #@param {type:\"string\"}\n","path_prueba = '/test'  #@param {type:\"string\"}\n","\n","imagPath_train = path + path_entrenamiento\n","imagPath_test = path + path_prueba\n","\n","#@markdown ### Parámetros de imágenes:\n","imagen_largo_ancho = 16 #@param {type:\"integer\"}\n","imagen_color = True #@param {type:\"boolean\"}\n","imagen_usar_generadas_data_augmentation = True #@param {type:\"boolean\"}\n","tipo_output_softMax = True\n","\n","## aplicación de los parámetros elegidos\n","\n","# tamaño de las imágenes\n","if imagen_largo_ancho<=10:\n","  imagen_largo_ancho = 10\n","IMAGE_SHAPE = (imagen_largo_ancho, imagen_largo_ancho, (3 if imagen_color else 1))\n","\n","# indica si se usan las imágenes generadas por data augmentation\n","usarDA = imagen_usar_generadas_data_augmentation\n","\n","# define tamaño de datos de entrada\n","num_inputs = IMAGE_SHAPE[0] * IMAGE_SHAPE[1] * IMAGE_SHAPE[2]\n","\n","print (\"Tamaño Imagen: \", IMAGE_SHAPE)\n"]},{"cell_type":"code","source":["#@title Cargar imágenes\n","# define función para cargar las imágenes\n","def cargarImagenes(imagPath):\n","  classes_ori = []\n","  images_ori = []\n","  esDA_ori = []\n","\n","  all_dirs = os.listdir( imagPath )\n","  for each_dir in all_dirs:\n","\n","      auxiPath = imagPath + '/' + each_dir\n","      imagFN  = os.listdir( auxiPath )\n","      for each_imagFN in imagFN:\n","\n","            esImagDA = (each_imagFN[:2] == 'da')\n","\n","            if usarDA or (not esImagDA):\n","\n","                # abre la imagen\n","                imag = Image.open(auxiPath + \"/\" + each_imagFN)\n","\n","                # ajusta el tamaño\n","                if IMAGE_SHAPE[2]==1:\n","                  tipoImage = 'L'\n","                else:\n","                  tipoImage = 'RGB'\n","                imag = imag.convert(tipoImage)\n","                imag = imag.resize((IMAGE_SHAPE[0], IMAGE_SHAPE[1]), Image.LANCZOS)\n","\n","                # transforma a un vector de nros\n","                arImag = np.array(imag)\n","\n","                # agrega a los vectores\n","                classes_ori.append( each_dir )\n","                images_ori.append( arImag )\n","                esDA_ori.append( esImagDA )\n","\n","  return classes_ori, images_ori, esDA_ori, tipoImage\n","\n","# carga las imagenes de entrenamiento\n","classes_train, images_train, esDAimag_train, tipoImage_train = cargarImagenes(imagPath_train)\n","print(\"> Para Entrenamiento: \")\n","print(\"- Clases cargadas: \", len(classes_train))\n","print(\"- Imágenes cargadas: \", len(classes_train))\n","\n","if len(classes_train)>0:\n","  print(\"- Ejemplo \", classes_train[0], \" \", images_train[0].shape, \": \")\n","  display( Image.fromarray(images_train[0], tipoImage_train) )\n","\n","# carga las imagenes de prueba\n","classes_test, images_test, esDAimag_test, tipoImage_test = cargarImagenes(imagPath_test)\n","print(\"\\n\\n> Para Prueba: \")\n","print(\"- Clases cargadas: \", len(classes_test))\n","print(\"- Imágenes cargadas: \", len(images_test))\n","\n","if len(classes_test)>0:\n","  print(\"- Ejemplo \", classes_test[0], \" \", images_test[0].shape, \": \")\n","  display( Image.fromarray(images_test[0], tipoImage_test) )"],"metadata":{"id":"MSJf_VfTtrQo","colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"status":"ok","timestamp":1696946947428,"user_tz":180,"elapsed":2073,"user":{"displayName":"PABLO GONZALO PYTEL","userId":"07736403464797369193"}},"outputId":"9d75033a-090f-4123-8ea8-cf40492e2f6d","cellView":"form"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["> Para Entrenamiento: \n","- Clases cargadas:  476\n","- Imágenes cargadas:  476\n","- Ejemplo  0   (16, 16, 3) : \n"]},{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=16x16>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAIAAACQkWg2AAABh0lEQVR4nHWSMc8xQRSFz5gNzQoF0ShEVCqCQvgHdLKt3+Bn6TVoRLKFqLbRKWSRrMYWIqzszvmKebOf3bzvrSbznHMz99wRJJEspVQmk9FnTYUQMc38pT6dTq7rCiGEEImm/KooikjudrvBYKDpaDTyPE8ppRFJpNSO45imCaDdblerVQDj8TimaUMYhv1+H8BkMiG53++z2ayU8ng8xp4fQxiGJFerFYBcLnc4HEjebrdisQhgvV7HmsTQ8/lcCNHtdpvNJoDH4/F6veKs/qdEUkr5+Xxs2yY5HA41c103CAIhRLlcjsPNxA0ul8v5fAbQ6XT0peM4ACqVSr1e/8Xg+/77/QZQq9U0tm1bv7BQKERRpA1GanFCiHw+T/J+v2+3W5KWZSXGIKmUIul5nmmaUsrFYkFyNpsBaDQaz+dTKaU16Vin0ymAUqnU6/UAGIax2WximjDo5fu+b1mWYRgAWq3Wcrn83rGu5McCAFyv1yAIdDLfP/dnyG+D7hEroiiSUqba/QNgpGMaW8vOcQAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","> Para Prueba: \n","- Clases cargadas:  120\n","- Imágenes cargadas:  120\n","- Ejemplo  0   (16, 16, 3) : \n"]},{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=16x16>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAIAAACQkWg2AAABkElEQVR4nHVSvcrqUBDc1UCwiAGxFNMGrAMi2IgWtiLWIja2PoKVL2FlIXaClZ12eQiDQdIGwT8Qc3ZucS754ue9Wxw47MzuMjMMgL5KKZXP54lId5k5beW+0SKi0WEYMnMWTXpGtpIkAbBer+v1+ng87na75/NZRJRSGkDf6OVySUSz2QyA4zi9Xi9tfRCUUiISBIFpmrZtXy4XpVStViuVSq/XC4CIfBD0jNFoRER6ahRFpmkWi8U4jn8T9IlRFFmWRUSLxUJEVqsVETmO83w+U0IuVYaIttvt7XazLKvdbjPzbrdj5kqlUigUAGi5/hL053A4MLPnedVq9fF47Pd7AJ7naWc+fMjlckQUBAGATqcDwPf9MAyJqN/vZ70ztBXMnCRJHMdE1Gq1iEjf02w2G41GauWPcSIiIq7r2rZ9v98BuK5LRL7vZ034Uen9fgOYTqeGYQDYbDZENJ/Pf6EBsI6Xfq/X63A4LJfLx+NxMBhMJpM0hf/NEoDT6aQXpvn5x4YsWSuWJIlhGN9Z/gM+BJkk4y7vhgAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"code","source":["#@title Preparar imágenes para usar en el modelo\n","\n","# define función auxiliar para mostrar imágenes preparadas\n","def plot_image(imag):\n","  if IMAGE_SHAPE[2]==1:\n","    plt.imshow((imag).reshape(IMAGE_SHAPE[0], IMAGE_SHAPE[1]).astype(np.uint8)) ## *255\n","    plt.gray()\n","  else:\n","    plt.imshow((imag).reshape(IMAGE_SHAPE).astype(np.uint8)) ## *255\n","  plt.axis(\"off\")\n","\n","# define función auxiliar para preparar la lista de imágenes a procesar\n","def prepare_imageList(imagList):\n","  auxiAr = np.array(imagList) ##.astype('float32') / 255.\n","  auxiAr = auxiAr.reshape((len(auxiAr), IMAGE_SHAPE[0], IMAGE_SHAPE[1], IMAGE_SHAPE[2]))\n","  return auxiAr\n","\n","# define función auxiliar para preparar lista de clases\n","def prepare_clasesList(classesList, dictMapeo=None):\n","  if dictMapeo==None:\n","    # genera diccionario de mapeo\n","    auxDict = list(set(classesList))\n","    dictMapeo = dict( zip( auxDict, range(len(auxDict)) ) )\n","  # realiza el mapeo\n","  y = []\n","  for cl in classesList:\n","      y.append( dictMapeo[cl] )\n","  # convierte valores numéricos a columnas de vakores binarios (i.e. one hot encoded)\n","  dummy_y = to_categorical(y)\n","  # devuelve\n","  return np.array(y), np.array(dummy_y), dictMapeo\n","\n","# define vector auxiliar de datos de entrada para usar en el entrenamiento y prueba\n","x_train = prepare_imageList(images_train)\n","x_test = prepare_imageList(images_test)\n","\n","# define vector auxiliar de datos de salida para usar en el entrenamiento y prueba\n","# también usa esta información para determinar la cantida de neuronas de salida\n","y_train, y_trainEnc, dictMapeo = prepare_clasesList(classes_train)\n","y_test, y_testEnc,_ = prepare_clasesList(classes_test, dictMapeo)\n","\n","# genera diccionario auxiliar para poder convertir de ID de clase a nombre de clase\n","clases_map = [ x for x,y in dictMapeo.items() ]\n","\n","print(\"> Para Entrenamiento: \")\n","print(\" - x_train (cant ejemplos, datos entrada): \", x_train.shape)\n","##print(\" - y_trainEnc (cant): \", y_trainEnc.shape)\n","print(\" - y_train (cant): \", y_train.shape)\n","print(\"\\n\\n> Para Prueba: \")\n","print(\" - x_test (cant ejemplos, datos entrada): \", x_test.shape)\n","##print(\" - y_testEnc (cant): \", y_testEnc.shape)\n","print(\" - y_test (cant): \", y_test.shape)\n","print(\"\\n\\n> Para Ambos: \")\n","print(\" - dictMapeo: \", dictMapeo)\n","print(\" - clases_map: \", clases_map)\n","if len(y_train)>0:\n","  print(\"\\n - Imagen reconstruida de \", clases_map[y_train[0]],  \"(\", y_train[0], \" / \", y_trainEnc[0], \")\")\n","  plot_image(x_train[0])"],"metadata":{"id":"sm0DqV9Utywf","colab":{"base_uri":"https://localhost:8080/","height":666},"executionInfo":{"status":"ok","timestamp":1696946947432,"user_tz":180,"elapsed":98,"user":{"displayName":"PABLO GONZALO PYTEL","userId":"07736403464797369193"}},"outputId":"8520989d-eebd-4604-efb6-db0b630e249d","cellView":"form"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["> Para Entrenamiento: \n"," - x_train (cant ejemplos, datos entrada):  (476, 16, 16, 3)\n"," - y_train (cant):  (476,)\n","\n","\n","> Para Prueba: \n"," - x_test (cant ejemplos, datos entrada):  (120, 16, 16, 3)\n"," - y_test (cant):  (120,)\n","\n","\n","> Para Ambos: \n"," - dictMapeo:  {'8': 0, '3': 1, '4': 2, '0': 3, '6': 4, '5': 5, '1': 6, '9': 7, '7': 8, '2': 9}\n"," - clases_map:  ['8', '3', '4', '0', '6', '5', '1', '9', '7', '2']\n","\n"," - Imagen reconstruida de  0 ( 3  /  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] )\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAIn0lEQVR4nO3bvY6NfRvG4f+91kokQjQ+GvExoxAVoRyJTkGHWmcH7IEo7IRGpZAodFSSkYloKCUiwqjER5CMEWv93+4snlfzSK7cZp7j2IAz16xxz2/dhaH33hsAtNYmYx8AwN9DFAAIUQAgRAGAEAUAQhQACFEAIEQBgJiNfQDbz2KxKNueTHyP+aet+v9Ph2EY+wR+wxMGQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAMRv7AMaxWCzKtieTrfld482bN2XblZ/JoUOHyrYr9d5L94dhKN3frrbm0wtACVEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgZmMfwO8tFovS/cmk7vvA06dPy7avX79etv3kyZOy7UoXLlwo2759+3bZ9v79+8u2W6t9hiqfn7Ft358MgH9NFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIih997HPmKrWiwWZduTSW2vX7x4Uba9srJStv39+/ey7VOnTpVtf/jwoWx7fX29bPvixYtl2w8ePCjbbm1rP59j2r4/GQD/migAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQQ++9j33EVrVYLMq2q38tZ8+eLdteW1sr27506VLZ9r1798q2nz17Vra9srJStj2fz8u2X758WbbdWmvLy8tl25XP/mQy7nd1bwoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAzMY+oNp8Pi/bnk6nZdsPHz4s226ttbW1tbLtHTt2lG3fuHGjbLvS4cOHy7Z37txZtv3ly5ey7devX5dtt9ba8vJy2XbvvWx7bN4UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIGZjH8Dv3b17t3R/GIay7TNnzpRtnzhxomy70rdv38q2NzY2yrYr9d7HPoHf8KYAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAMRv7gNZa672XbU+n07Ltnz9/lm2vrq6WbbdW+5mvrKyUbW9Vb9++Ldve3Nws2x6GoWx73759ZdvVKj+XsXlTACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgJiNfUBrrfXey7aHYSjbXl9fL9t+9+5d2Xa106dPj33CH6n8d/j8+fOy7UoHDhwo215aWirbrlb5d2Vs3hQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgZmMf0FprvfexT/gjnz9/Ltv+8eNH2Xa1I0eOjH3CHxmGoWx7dXW1bLvy7jNnzpRt79mzp2y7tdbm83nZ9nQ6LdsemzcFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiNnYBzCOYRjKtnfv3l223Xsv2/706VPZ9uPHj8u2Kz+TK1eulG1Xq/xctjNvCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCzsQ9orbXJZGu26eDBg2Xbu3btKtturbWNjY2y7VevXpVtHz9+vGz75s2bZdsfP34s2z527FjZ9uXLl8u2e+9l2621Np1OS/e3q6351xiAEqIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBADL33PvYRlebzedn2dDot27569WrZdmut3blzp2x77969ZdtHjx4t23727FnZ9mw2K9t+9OhR2fa5c+fKtiufzdZqn8/tzJsCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEEPvvY99RKXKH69y++vXr2XbrbV27dq1su379++Xbf/69ats++TJk2Xbt27dKts+f/582fZisSjbnkx8J/0b+a0AEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBADL33PvYRbC/v378v297c3CzbXlpaKtuutFgsyrYnE98b/2v8xgEIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACCG3nsf+wj+X/WvpXJ/MvFd45/m83nZ9nQ6Ldvmv8fTC0CIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCADH03vvYRwDwd/CmAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQPwPAKkQljMpwJsAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"G96unKkBIPDW"},"source":["2) Preparar para NeuroEvolution:"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"FCbZ1lpH_wgQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696946947432,"user_tz":180,"elapsed":78,"user":{"displayName":"PABLO GONZALO PYTEL","userId":"07736403464797369193"}},"outputId":"d64f3a50-6cf8-475f-fd6f-1a5cd491b7e8","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["[EVALUATION]\n","epochs        = 50\n","batch_size    = None\n","preprocessing = None\n","increase_epochs_every_n_genomes = 15\n","increase_epochs_add_epochs = 25\n","\n","\n","[FITNESS]\n","calc_using_accuracy    = 'S'\n","penalize_based_on_topology  = False\n","\n","\n","[POPULATION]\n","bp_pop_size    = 5\n","mod_pop_size   = 3\n","genomes_per_bp = 3\n","\n","\n","[GENOME]\n","dtype                = 'float32'\n","available_modules    = ['Conv2DMaxPool2DDropout']\n","available_optimizers = ['SGD', 'Adam']\n","output_layers        = [{'class_name': 'Flatten', 'config': {}}, \n","                        {'class_name': 'Dense', 'config': {'units': 10, 'activation': 'softmax'}}] \n","\n","\n","[MODULE_SPECIATION]\n","mod_spec_type            = 'param-distance-dynamic'\n","mod_spec_species_count   = 4\n","mod_spec_distance        = 0.3\n","mod_spec_mod_elitism     = 2\n","mod_spec_min_offspring   = 1\n","mod_spec_reprod_thres    = 0.5\n","mod_spec_max_stagnation  = 15\n","mod_spec_species_elitism = 2\n","mod_spec_rebase_repr     = True\n","mod_spec_reinit_extinct  = False\n","\n","\n","[MODULE_EVOLUTION]\n","mod_max_mutation   = 0.5\n","mod_mutation_prob  = 0.6\n","mod_crossover_prob = 0.4\n","\n","\n","[BP_SPECIATION]\n","bp_spec_type            = 'gene-overlap-dynamic'\n","bp_spec_species_count   = 3\n","bp_spec_distance        = 0.3\n","bp_spec_bp_elitism      = 2\n","bp_spec_min_offspring   = 1\n","bp_spec_reprod_thres    = 0.5\n","bp_spec_max_stagnation  = 15\n","bp_spec_species_elitism = 2\n","bp_spec_rebase_repr     = True\n","bp_spec_reinit_extinct  = True\n","\n","\n","[BP_EVOLUTION]\n","bp_max_mutation            = 0.3\n","bp_mutation_add_conn_prob  = 0.2\n","bp_mutation_add_node_prob  = 0.2\n","bp_mutation_rem_conn_prob  = 0.05\n","bp_mutation_rem_node_prob  = 0.05\n","bp_mutation_node_spec_prob = 0.3\n","bp_mutation_optimizer_prob = 0.1\n","bp_crossover_prob          = 0.1\n","\n","\n","[MODULE_CONV2DMAXPOOL2DDROPOUT]\n","merge_method  = [{'class_name': 'Concatenate', 'config': {'axis': -1}}, \n","                 {'class_name': 'Add', 'config': {}}]\n","filters       = {'min': 8, 'max': 256, 'step': 8, 'stddev': 4}\n","kernel_size   = [1,2,3]\n","strides       = [1]\n","padding       = ['valid', 'same']\n","activation    = ['linear', 'elu', 'relu']\n","kernel_init   = ['glorot_uniform']\n","bias_init     = ['zeros']\n","max_pool_flag = 0.8\n","max_pool_size = [1,2,3]\n","dropout_flag  = 0.5\n","dropout_rate  = {'min': 0.1, 'max': 0.7, 'step': 0.1, 'stddev': 0.2}\n","\n","\n","[OPTIMIZER_SGD]\n","learning_rate = {'min': 0.001, 'max': 0.3, 'step': 0.001, 'stddev': 0.02}\n","momentum      = {'min': 0.3, 'max': 0.7, 'step': 0.1, 'stddev': 0.1}\n","nesterov      = [True, False] \n","\n","\n","[OPTIMIZER_ADAM]\n","learning_rate = {'min': 0.0001, 'max': 0.3, 'step': 0.0001, 'stddev': 0.02}\n","beta_1        = {'min': 0.6, 'max': 1.5, 'step': 0.05, 'stddev': 0.2}\n","beta_2        = {'min': 0.8, 'max': 1.2, 'step': 0.001, 'stddev': 0.1}\n","epsilon       = {'min': 1e-8, 'max': 1e-6, 'step': 1e-8, 'stddev': 1e-7}\n","\n","\n"]}],"source":["#@title Crear Archivo Configuración\n","# ver explicación en https://tfne.readthedocs.io/en/latest/codeepneat/codeepneat-config.html\n","\n","confFileName = './codeepneat_config.cfg'\n","\n","s = \"\"\n","with open(confFileName, 'w') as f:\n","    s = s + \"[EVALUATION]\\n\"\n","    s = s + \"epochs        = \" + str(rna_cant_epocas_entrenamiento) + \"\\n\"\n","    s = s + \"batch_size    = None\\n\"\n","    s = s + \"preprocessing = None\\n\"\n","    if rna_cant_epocas_entrenamiento_incrementa_por_generacion > 0:\n","      s = s + \"increase_epochs_every_n_genomes = \" + str(ce_cant_poblacion_blueprints*ce_cant_genomas_por_blueprint) + \"\\n\"\n","      s = s + \"increase_epochs_add_epochs = \" + str(rna_cant_epocas_entrenamiento_incrementa_por_generacion) + \"\\n\"\n","    else:\n","      s = s + \"increase_epochs_every_n_genomes = 0\\n\"\n","      s = s + \"increase_epochs_add_epochs = 0\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[FITNESS]\\n\"\n","    if fitness_calc_usando_exactitud == \"Entrenamiento\":\n","      s = s + \"calc_using_accuracy    = 'E'\\n\"\n","    elif fitness_calc_usando_exactitud == \"Validacion\":\n","      s = s + \"calc_using_accuracy    = 'V'\\n\"\n","    elif fitness_calc_usando_exactitud == \"Min Entrenamiento & Validacion\":\n","      s = s + \"calc_using_accuracy    = 'M'\\n\"\n","    elif fitness_calc_usando_exactitud == \"Promedio Entrenamiento & Validacion\":\n","      s = s + \"calc_using_accuracy    = 'P'\\n\"\n","    else:\n","      s = s + \"calc_using_accuracy    = 'S'\\n\"\n","    s = s + \"penalize_based_on_topology  = \" + str(fitness_penalizar_x_topologia) + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[POPULATION]\\n\"\n","    s = s + \"bp_pop_size    = \" + str(ce_cant_poblacion_blueprints) + \"\\n\"\n","    s = s + \"mod_pop_size   = \" + str(ce_cant_poblacion_modulos) + \"\\n\"\n","    s = s + \"genomes_per_bp = \" + str(ce_cant_genomas_por_blueprint ) + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[GENOME]\\n\"\n","    s = s + \"dtype                = 'float32'\\n\"\n","  ##s = s + \"available_modules    = ['DenseDropout', 'Conv2DMaxPool2DDropout']\\n\"\n","    s = s + \"available_modules    = ['Conv2DMaxPool2DDropout']\\n\"\n","    s = s + \"available_optimizers = ['SGD', 'Adam']\\n\" # 'SGD',\n","    s = s + \"output_layers        = [{'class_name': 'Flatten', 'config': {}}, \\n\"\n","  ##s = s + \"                        {'class_name': 'Dense', 'config': {'units': \"+ str(len(clases_map)*2) + \", 'activation': 'relu'}}, \\n\"\n","    s = s + \"                        {'class_name': 'Dense', 'config': {'units': \"+ str(len(clases_map)) + \", 'activation': 'softmax'}}] \\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[MODULE_SPECIATION]\\n\"\n","    if ce_tipo_generacion_modulos == \"Dinamica\":\n","      # Dinamica\n","      s = s + \"mod_spec_type            = 'param-distance-dynamic'\\n\"\n","      s = s + \"mod_spec_species_count   = 4\\n\"\n","      s = s + \"mod_spec_distance        = 0.3\\n\"\n","      s = s + \"mod_spec_mod_elitism     = 2\\n\"\n","      s = s + \"mod_spec_min_offspring   = 1\\n\"\n","      s = s + \"mod_spec_reprod_thres    = 0.5\\n\"\n","      s = s + \"mod_spec_max_stagnation  = 15\\n\"\n","      s = s + \"mod_spec_species_elitism = 2\\n\"\n","      s = s + \"mod_spec_rebase_repr     = True\\n\"\n","      s = s + \"mod_spec_reinit_extinct  = False\\n\"\n","    elif ce_tipo_generacion_modulos == \"Fija\":\n","      # Fija\n","      s = s + \"mod_spec_type            = 'param-distance-fixed'\\n\"\n","      s = s + \"mod_spec_distance        = 0.3\\n\"\n","      s = s + \"mod_spec_mod_elitism     = 2\\n\"\n","      s = s + \"mod_spec_min_offspring   = 1\\n\"\n","      s = s + \"mod_spec_reprod_thres    = 0.5\\n\"\n","      s = s + \"mod_spec_max_stagnation  = 10\\n\"\n","      s = s + \"mod_spec_species_elitism = 2\\n\"\n","      s = s + \"mod_spec_rebase_repr     = True\\n\"\n","      s = s + \"mod_spec_reinit_extinct  = False\\n\"\n","    else:\n","      # Basica\n","      s = s + \"mod_spec_type          = 'basic'\\n\"\n","      s = s + \"mod_spec_mod_elitism   = 4\\n\"\n","      s = s + \"mod_spec_min_offspring = 1\\n\"\n","      s = s + \"mod_spec_reprod_thres  = 0.5\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[MODULE_EVOLUTION]\\n\"\n","    s = s + \"mod_max_mutation   = \" + str(ce_max_mutacion) + \"\\n\"\n","    s = s + \"mod_mutation_prob  = \" + str(ce_probab_mutacion) + \"\\n\"\n","    s = s + \"mod_crossover_prob = \" + str(ce_probab_cruzamiento) + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[BP_SPECIATION]\\n\"\n","    if ce_tipo_generacion_modulos == \"Dinamica\":\n","      # Dinamica\n","      s = s + \"bp_spec_type            = 'gene-overlap-dynamic'\\n\"\n","      s = s + \"bp_spec_species_count   = 3\\n\"\n","      s = s + \"bp_spec_distance        = 0.3\\n\"\n","      s = s + \"bp_spec_bp_elitism      = 2\\n\"\n","      s = s + \"bp_spec_min_offspring   = 1\\n\"\n","      s = s + \"bp_spec_reprod_thres    = 0.5\\n\"\n","      s = s + \"bp_spec_max_stagnation  = 15\\n\"\n","      s = s + \"bp_spec_species_elitism = 2\\n\"\n","      s = s + \"bp_spec_rebase_repr     = True\\n\"\n","      s = s + \"bp_spec_reinit_extinct  = True\\n\"\n","    elif ce_tipo_generacion_modulos == \"Fija\":\n","      # Fija\n","      s = s + \"bp_spec_type            = 'gene-overlap-fixed'\\n\"\n","      s = s + \"bp_spec_distance        = 0.3\\n\"\n","      s = s + \"bp_spec_bp_elitism      = 2\\n\"\n","      s = s + \"bp_spec_min_offspring   = 1\\n\"\n","      s = s + \"bp_spec_reprod_thres    = 0.5\\n\"\n","      s = s + \"bp_spec_max_stagnation  = 15\\n\"\n","      s = s + \"bp_spec_species_elitism = 2\\n\"\n","      s = s + \"bp_spec_rebase_repr     = True\\n\"\n","      s = s + \"bp_spec_reinit_extinct  = True\\n\"\n","    else:\n","      # Basica\n","      s = s + \"bp_spec_type          = 'basic'\\n\"\n","      s = s + \"bp_spec_bp_elitism    = 2\\n\"\n","      s = s + \"bp_spec_min_offspring = 1\\n\"\n","      s = s + \"bp_spec_reprod_thres  = 0.5\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[BP_EVOLUTION]\\n\"\n","    if ce_tipo_generacion_modulos == \"Dinamica\":\n","      # Dinamica\n","      s = s + \"bp_max_mutation            = 0.3\\n\"\n","      s = s + \"bp_mutation_add_conn_prob  = 0.2\\n\"\n","      s = s + \"bp_mutation_add_node_prob  = 0.2\\n\"\n","      s = s + \"bp_mutation_rem_conn_prob  = 0.05\\n\"\n","      s = s + \"bp_mutation_rem_node_prob  = 0.05\\n\"\n","      s = s + \"bp_mutation_node_spec_prob = 0.3\\n\"\n","      s = s + \"bp_mutation_optimizer_prob = 0.1\\n\"\n","      s = s + \"bp_crossover_prob          = 0.1\\n\"\n","    else:\n","      # Fija o Basica\n","      s = s + \"bp_max_mutation            = 0.3\\n\"\n","      s = s + \"bp_mutation_add_conn_prob  = 0.3\\n\"\n","      s = s + \"bp_mutation_add_node_prob  = 0.3\\n\"\n","      s = s + \"bp_mutation_rem_conn_prob  = 0.05\\n\"\n","      s = s + \"bp_mutation_rem_node_prob  = 0.05\\n\"\n","      s = s + \"bp_mutation_node_spec_prob = 0.1\\n\"\n","      s = s + \"bp_mutation_optimizer_prob = 0.1\\n\"\n","      s = s + \"bp_crossover_prob          = 0.1\\n\"\n","##    s = s + \"\\n\"\n","##    s = s + \"\\n\"\n","##    s = s + \"[MODULE_DENSEDROPOUT]\\n\"\n","##    s = s + \"merge_method = [{'class_name': 'Concatenate', 'config': {'axis': -1}}, {'class_name': 'Add', 'config': {}},{'class_name': 'Flatten', 'config': {}}]\\n\"\n","##    s = s + \"units        = {'min': 2, 'max': 100, 'step': 4, 'stddev': 6}\\n\"\n","##    s = s + \"activation   = ['linear', 'relu', 'sigmoid', 'softmax', 'tanh']\\n\"\n","##    s = s + \"kernel_init  = ['glorot_normal', 'he_normal']\\n\"\n","##    s = s + \"bias_init    = ['zeros']\\n\"\n","##    s = s + \"dropout_flag = 0.5\\n\"\n","##    s = s + \"dropout_rate = {'min': 0.1, 'max': 0.4, 'step': 0.1, 'stddev': 0.1}\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[MODULE_CONV2DMAXPOOL2DDROPOUT]\\n\"\n","    s = s + \"merge_method  = [{'class_name': 'Concatenate', 'config': {'axis': -1}}, \\n\"\n","    s = s + \"                 {'class_name': 'Add', 'config': {}}]\\n\"\n","    s = s + \"filters       = {'min': 8, 'max': 256, 'step': 8, 'stddev': 4}\\n\"\n","    s = s + \"kernel_size   = [1,2,3]\\n\"\n","    s = s + \"strides       = [1]\\n\"\n","    s = s + \"padding       = ['valid', 'same']\\n\"\n","    s = s + \"activation    = ['linear', 'elu', 'relu']\\n\"\n","    s = s + \"kernel_init   = ['glorot_uniform']\\n\"\n","    s = s + \"bias_init     = ['zeros']\\n\"\n","    s = s + \"max_pool_flag = 0.8\\n\"\n","    s = s + \"max_pool_size = [1,2,3]\\n\"\n","    s = s + \"dropout_flag  = 0.5\\n\"\n","    s = s + \"dropout_rate  = {'min': 0.1, 'max': 0.7, 'step': 0.1, 'stddev': 0.2}\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[OPTIMIZER_SGD]\\n\"\n","    s = s + \"learning_rate = {'min': 0.001, 'max': 0.3, 'step': 0.001, 'stddev': 0.02}\\n\"\n","    s = s + \"momentum      = {'min': 0.3, 'max': 0.7, 'step': 0.1, 'stddev': 0.1}\\n\"\n","    s = s + \"nesterov      = [True, False] \\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[OPTIMIZER_ADAM]\\n\"\n","    s = s + \"learning_rate = {'min': 0.0001, 'max': 0.3, 'step': 0.0001, 'stddev': 0.02}\\n\"\n","    s = s + \"beta_1        = {'min': 0.6, 'max': 1.5, 'step': 0.05, 'stddev': 0.2}\\n\"\n","    s = s + \"beta_2        = {'min': 0.8, 'max': 1.2, 'step': 0.001, 'stddev': 0.1}\\n\"\n","    s = s + \"epsilon       = {'min': 1e-8, 'max': 1e-6, 'step': 1e-8, 'stddev': 1e-7}\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","\n","    f.write(s)\n","\n","# muestra nuevo archivo modificado\n","%cat {confFileName}"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"6QNOESjoDj6B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696946947433,"user_tz":180,"elapsed":66,"user":{"displayName":"PABLO GONZALO PYTEL","userId":"07736403464797369193"}},"outputId":"3439f60e-8ad1-479a-8a50-b3ddd331e9e9","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["Clase RNAEnvironment definida\n"]}],"source":["#@title Definir clase para el ambiente RNAEnvironment\n","\n","class RNAEnvironment(BaseEnvironment):\n","    \"\"\"\n","    TFNE compatible environment for the RNA\n","    \"\"\"\n","\n","    def __init__(self, weight_training, data_x, data_y, config=None, verbosity=0, **kwargs):\n","        \"\"\"\n","        Initializes environment by setting up the dataset and processing the supplied config or supplied config\n","        parameters. The configuration of the environment can either be supplied via a config file or via seperate config\n","        parameters in the initialization.\n","        @param weight_training: bool flag, indicating wether evaluation should be weight training or not\n","        @param config: ConfigParser instance holding an 'Environment' section specifying the required environment\n","                       parameters for the chosen evaluation method.\n","        @param verbosity: integer specifying the verbosity of the evaluation\n","        @param kwargs: Optionally supplied dict of each configuration parameter seperately in order to allow the\n","                       creation of the evaluation environment without the requirement of a config file.\n","        \"\"\"\n","        # Initialize corresponding input and output mappings\n","        print(\"> Preparando el ambiente...\")\n","\n","        # Initialize loss function to evaluate performance on either evaluation method and safe verbosity parameter\n","        self.accuracy_metric = tf.keras.metrics.Accuracy()\n","        self.verbosity = verbosity\n","\n","        # Determine and setup explicit evaluation method in accordance to supplied parameters\n","        if not weight_training:\n","              raise NotImplementedError(\"RNA environment is being set up as non-weight training, though non-weight \"\n","                                      \"training evaluation not yet implemented for RNA environment\")\n","\n","\n","        elif config is None and len(kwargs) == 0:\n","            raise RuntimeError(\"No se han definido los parámetros para poder realizar la evolución y el entrenamiento de las RNA\")\n","\n","        elif len(kwargs) == 0:\n","            # Set up environment as weight training and with a supplied config file\n","            self.eval_genome_fitness = self._eval_genome_fitness_weight_training\n","            self.epochs = read_option_from_config(config, 'EVALUATION', 'epochs')\n","            self.batch_size = read_option_from_config(config, 'EVALUATION', 'batch_size')\n","            self.increase_epochs_every_n_genomes = read_option_from_config(config, 'EVALUATION', 'increase_epochs_every_n_genomes')\n","            self.increase_epochs_add_epochs = read_option_from_config(config, 'EVALUATION', 'increase_epochs_add_epochs')\n","            #  parámetros para calculo fitness\n","            self.calcFitness = read_option_from_config(config, 'FITNESS', 'calc_using_accuracy')\n","            self.penalFitness = read_option_from_config(config, 'FITNESS', 'penalize_based_on_topology')\n","\n","        elif config is None:\n","            # Set up environment as weight training and explicitely supplied parameters\n","            self.eval_genome_fitness = self._eval_genome_fitness_weight_training\n","            self.epochs = kwargs['epochs']\n","            self.batch_size = kwargs['batch_size']\n","            self.increase_epochs_every_n_genomes = kwargs['increase_epochs_every_n_genomes']\n","            self.increase_epochs_add_epochs = kwargs['increase_epochs_add_epochs']\n","            # determina parámetros para calculo fitness\n","            self.calcFitness = kwargs['fitness_calc_using_accuracy']\n","            self.penalFitness = kwargs['fitness_penalize_based_on_topology']\n","\n","        print(\" Definiendo parámetros para cálculo de aptitud: \")\n","        print(\"        calcFitness = \", self.calcFitness)\n","        print(\"        penalFitness = \", self.penalFitness)\n","\n","\n","        ##data_y = np.squeeze(data_y)\n","        if self.calcFitness == \"E\":\n","            # se toman todos los datos para entrenamiento\n","            x_t, x_v, y_t, y_v = data_x, [], data_y, []\n","        else:\n","            # separa al azar usando muestreo al azar del 10%\n","            # para tomar algunos como datos de validación\n","            x_t, x_v, y_t, y_v = train_test_split(data_x,\n","                                                data_y,\n","                                                test_size=0.1)\n","\n","        print(\"  Definiendo datos: de los \", len(x_train), \"ejemplos de entrenamiento: \")\n","        print(\"                      se usan \", len(x_t), \"ejemplos para entrenar \")\n","        print(\"                      y \", len(x_v), \"ejemplos para validar.\")\n","        print(\"\\n\")\n","        self.x_train = np.array(x_t)\n","        self.y_train = np.array(y_t)\n","\n","        # genera salida codificada para entrenamiento con capa softMax\n","        self.y_trainEnc = to_categorical(self.y_train)\n","\n","        self.x_val = np.array(x_v)\n","        self.y_val = np.array(y_v)\n","\n","        # determina neuronas de entrada y salida\n","        self.cantX = len(self.x_train)\n","        self.cantY = len(self.y_train)\n","        return\n","\n","    def eval_genome_fitness(self, genome) -> float:\n","        # TO BE OVERRIDEN\n","        raise RuntimeError()\n","\n","    def _calculate_fitness(self, model, penalFitness=False) -> float:\n","        \"\"\"\n","        The genomes fitness is then calculated and returned as\n","        the percentage of training and/or validation examples classified correctly.\n","        \"\"\"\n","        # calcula para datos de entrenamiento\n","        if len(self.y_train)>0:\n","          self.accuracy_metric.reset_states()\n","          self.accuracy_metric.update_state(self.y_train, np.argmax(model(self.x_train), axis=-1))\n","          evaluated_fitness_train = round(self.accuracy_metric.result().numpy() * 100, 4)\n","        else:\n","          evaluated_fitness_train = 0.0\n","        # calcula para datos de entrenamiento\n","        if len(self.y_val)>0:\n","          self.accuracy_metric.reset_states()\n","          self.accuracy_metric.update_state(self.y_val, np.argmax(model(self.x_val), axis=-1))\n","          evaluated_fitness_val = round(self.accuracy_metric.result().numpy() * 100, 4)\n","        else:\n","          evaluated_fitness_val = 0.0\n","        # calcula final como promedio\n","        if self.calcFitness == \"E\":\n","          # sólo de entrenamiento\n","          evaluated_fitness = evaluated_fitness_train\n","        elif self.calcFitness == \"V\":\n","          # sólo de validación\n","          evaluated_fitness = evaluated_fitness_val\n","        elif self.calcFitness == \"P\":\n","          # promedio ente ambos\n","          evaluated_fitness = (evaluated_fitness_train + evaluated_fitness_val)/2\n","        elif self.calcFitness ==  \"S\":\n","          # suma ente ambos\n","          evaluated_fitness = (evaluated_fitness_train + evaluated_fitness_val)\n","        else:\n","          # mínimo ente ambos\n","          evaluated_fitness = min([evaluated_fitness_train, evaluated_fitness_val])\n","        if False and penalFitness:\n","          # sólo se aplica la penalización\n","          # si está cercano a alcanzar la aptitud máxima\n","          maxFit = self.return_MaxFitness()\n","          if evaluated_fitness >= (maxFit - 11):\n","            # penaliza aptitud teniendo en cuenta la complejidad de la RNA\n","            penalLayers = -1.5\n","            ajusteCantPesos = self.cantX\n","            for i in range(len(model.layers)):\n","              l = model.layers[i]\n","              tipoLay = str(type(l))\n","              if \"Dense\" in tipoLay:\n","                if i > 1:\n","                  # contabiliza en base a la cantidad de pesos de las conexiones\n","                  # nota: no tiene en cuenta los pesos de la capa de entrada ni de salida\n","                  cantPesos = len(l.get_weights()[0])\n","                  penalLayers = penalLayers + (cantPesos / ajusteCantPesos)\n","              elif \"Dropout\" in tipoLay:\n","                penalLayers = penalLayers + 0.8\n","              elif \"Concatenate\" in tipoLay:\n","                penalLayers = penalLayers + 0.9\n","            if penalLayers > 0:\n","              evaluated_fitness = evaluated_fitness + 10.0 - (penalLayers / 10.0)\n","        return round(evaluated_fitness, 5)\n","\n","    def return_MaxFitness(self) -> float:\n","      # devuelve valor máximo posible para la aptitud\n","      if self.calcFitness ==  \"S\":\n","        valMaxFit = 200.0\n","      else:\n","        valMaxFit = 100.0\n","      if self.penalFitness:\n","        valMaxFit = valMaxFit + 10\n","      return valMaxFit\n","\n","    def _eval_genome_fitness_weight_training(self, genome) -> float:\n","        \"\"\"\n","        Evaluates the genome's fitness by obtaining the associated Tensorflow model and optimizer,\n","        compiling them and then training them for the config specified duration.\n","        @param genome: TFNE compatible genome that is to be evaluated\n","        @return: genome calculated fitness\n","        \"\"\"\n","        # Get model and optimizer required for compilation\n","        model = genome.get_model()\n","        optimizer = genome.get_optimizer()\n","\n","        # si corresponde incrementa la cantidad de épocas\n","        gen_id = genome.get_id()\n","        if gen_id > self.increase_epochs_every_n_genomes:\n","          cantEpochsIncr = int((gen_id / self.increase_epochs_every_n_genomes) * self.increase_epochs_add_epochs)\n","          cant_epochs = self.epochs + cantEpochsIncr\n","          #print(\"  > \", gen_id, self.epochs, cantEpochsIncr, cant_epochs)\n","        else:\n","          cant_epochs = self.epochs\n","\n","        # Compile and train model\n","        model.compile(optimizer=optimizer,\n","                      loss='categorical_crossentropy', metrics=['accuracy'])\n","                      #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n","        model.fit(x=self.x_train,\n","                  y=self.y_trainEnc,\n","                  epochs=cant_epochs,\n","                  batch_size=self.batch_size,\n","                  verbose=self.verbosity)\n","\n","        # Evaluate and return its fitness\n","        return self._calculate_fitness(model, self.penalFitness)\n","\n","    def _eval_genome_fitness_non_weight_training(self, genome) -> float:\n","        raise NotImplementedError(\"Non-Weight training evaluation not yet implemented for Environment\")\n","\n","    def replay_genome(self, genome):\n","        \"\"\"\n","        Replay genome on environment by calculating its fitness and printing it.\n","        @param genome: TFNE compatible genome that is to be evaluated\n","        \"\"\"\n","        print(\"> Probando Genome #{}:\".format(genome.get_id()))\n","\n","        # Determine fitness by creating model predictions with test images and then judging the fitness based on the\n","        # achieved model accuracy.\n","        model = genome.get_model()\n","        evaluated_fitness = self._calculate_fitness(model, False)\n","        print(\"  Aptitud lograda:\\t{}\\n\".format(evaluated_fitness))\n","\n","    def duplicate(self) -> RNAEnvironment:\n","        \"\"\"\n","        @return: New instance of the environment with identical parameters\n","        \"\"\"\n","        x = self.x_train.extend(self.x_val)\n","        y = self.y_train.extend(self.y_val)\n","        if hasattr(self, 'epochs'):\n","            return RNAEnvironment(True, data_x=x, data_y=y, verbosity=self.verbosity, epochs=self.epochs, batch_size=self.batch_size)\n","        else:\n","            return RNAEnvironment(False, data_x=x, data_y=y, verbosity=self.verbosity)\n","\n","    def get_input_shape(self) -> (int, int, int):\n","        \"\"\"\"\"\"\n","        if len(self.x_train)>0:\n","          return self.x_train[0].shape\n","        else:\n","          return None\n","\n","    def get_output_shape(self) ->  (int,):\n","        \"\"\"\"\"\"\n","        return (self.cantY,)\n","        #if len(self.y_train)>0:\n","        #  return self.y_train[0].shape\n","        #else:\n","        #  return None\n","\n","print(\"Clase RNAEnvironment definida\")"]},{"cell_type":"markdown","metadata":{"id":"USZcQIWbIpEY"},"source":["3) Ejecutar NeuroEvolution:"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"kHIt18d-AUTc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696947846243,"user_tz":180,"elapsed":898866,"user":{"displayName":"PABLO GONZALO PYTEL","userId":"07736403464797369193"}},"outputId":"d774374f-e134-479c-ec33-5e1405f65141","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["> Preparando el ambiente...\n","Config value for 'EVALUATION/epochs': 50\n","Config value for 'EVALUATION/batch_size': None\n","Config value for 'EVALUATION/increase_epochs_every_n_genomes': 15\n","Config value for 'EVALUATION/increase_epochs_add_epochs': 25\n","Config value for 'FITNESS/calc_using_accuracy': S\n","Config value for 'FITNESS/penalize_based_on_topology': False\n"," Definiendo parámetros para cálculo de aptitud: \n","        calcFitness =  S\n","        penalFitness =  False\n","  Definiendo datos: de los  476 ejemplos de entrenamiento: \n","                      se usan  428 ejemplos para entrenar \n","                      y  48 ejemplos para validar.\n","\n","\n","\n",">  Definiendo Enviroment:\n","input_shape:  (16, 16, 3)\n","output_shape:  (428,)\n","\n",">  Definiendo configuración:\n","Config value for 'POPULATION/bp_pop_size': 5\n","Config value for 'POPULATION/mod_pop_size': 3\n","Config value for 'POPULATION/genomes_per_bp': 3\n","Config value for 'GENOME/dtype': float32\n","Config value for 'GENOME/available_modules': ['Conv2DMaxPool2DDropout']\n","Config value for 'GENOME/available_optimizers': ['SGD', 'Adam']\n","Config value for 'GENOME/output_layers': [{'class_name': 'Flatten', 'config': {}}, {'class_name': 'Dense', 'config': {'units': 10, 'activation': 'softmax'}}]\n","Config value for 'MODULE_SPECIATION/mod_spec_type': param-distance-dynamic\n","Config value for 'MODULE_SPECIATION/mod_spec_species_count': 4\n","Config value for 'MODULE_SPECIATION/mod_spec_distance': 0.3\n","Config value for 'MODULE_SPECIATION/mod_spec_mod_elitism': 2\n","Config value for 'MODULE_SPECIATION/mod_spec_min_offspring': 1\n","Config value for 'MODULE_SPECIATION/mod_spec_reprod_thres': 0.5\n","Config value for 'MODULE_SPECIATION/mod_spec_max_stagnation': 15\n","Config value for 'MODULE_SPECIATION/mod_spec_species_elitism': 2\n","Config value for 'MODULE_SPECIATION/mod_spec_rebase_repr': True\n","Config value for 'MODULE_SPECIATION/mod_spec_reinit_extinct': False\n","Config value for 'MODULE_EVOLUTION/mod_max_mutation': 0.5\n","Config value for 'MODULE_EVOLUTION/mod_mutation_prob': 0.6\n","Config value for 'MODULE_EVOLUTION/mod_crossover_prob': 0.4\n","Config value for 'BP_SPECIATION/bp_spec_type': gene-overlap-dynamic\n","Config value for 'BP_SPECIATION/bp_spec_species_count': 3\n","Config value for 'BP_SPECIATION/bp_spec_distance': 0.3\n","Config value for 'BP_SPECIATION/bp_spec_bp_elitism': 2\n","Config value for 'BP_SPECIATION/bp_spec_min_offspring': 1\n","Config value for 'BP_SPECIATION/bp_spec_reprod_thres': 0.5\n","Config value for 'BP_SPECIATION/bp_spec_max_stagnation': 15\n","Config value for 'BP_SPECIATION/bp_spec_species_elitism': 2\n","Config value for 'BP_SPECIATION/bp_spec_rebase_repr': True\n","Config value for 'BP_SPECIATION/bp_spec_reinit_extinct': True\n","Config value for 'BP_EVOLUTION/bp_max_mutation': 0.3\n","Config value for 'BP_EVOLUTION/bp_mutation_add_conn_prob': 0.2\n","Config value for 'BP_EVOLUTION/bp_mutation_add_node_prob': 0.2\n","Config value for 'BP_EVOLUTION/bp_mutation_rem_conn_prob': 0.05\n","Config value for 'BP_EVOLUTION/bp_mutation_rem_node_prob': 0.05\n","Config value for 'BP_EVOLUTION/bp_mutation_node_spec_prob': 0.3\n","Config value for 'BP_EVOLUTION/bp_mutation_optimizer_prob': 0.1\n","Config value for 'BP_EVOLUTION/bp_crossover_prob': 0.1\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/merge_method': [{'class_name': 'Concatenate', 'config': {'axis': -1}}, {'class_name': 'Add', 'config': {}}]\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/filters': {'min': 8, 'max': 256, 'step': 8, 'stddev': 4}\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/kernel_size': [1, 2, 3]\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/strides': [1]\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/padding': ['valid', 'same']\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/activation': ['linear', 'elu', 'relu']\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/kernel_init': ['glorot_uniform']\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/bias_init': ['zeros']\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/max_pool_flag': 0.8\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/max_pool_size': [1, 2, 3]\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/dropout_flag': 0.5\n","Config value for 'MODULE_CONV2DMAXPOOL2DDROPOUT/dropout_rate': {'min': 0.1, 'max': 0.7, 'step': 0.1, 'stddev': 0.2}\n","Config value for 'OPTIMIZER_SGD/learning_rate': {'min': 0.001, 'max': 0.3, 'step': 0.001, 'stddev': 0.02}\n","Config value for 'OPTIMIZER_SGD/momentum': {'min': 0.3, 'max': 0.7, 'step': 0.1, 'stddev': 0.1}\n","Config value for 'OPTIMIZER_SGD/nesterov': [True, False]\n","Config value for 'OPTIMIZER_ADAM/learning_rate': {'min': 0.0001, 'max': 0.3, 'step': 0.0001, 'stddev': 0.02}\n","Config value for 'OPTIMIZER_ADAM/beta_1': {'min': 0.6, 'max': 1.5, 'step': 0.05, 'stddev': 0.2}\n","Config value for 'OPTIMIZER_ADAM/beta_2': {'min': 0.8, 'max': 1.2, 'step': 0.001, 'stddev': 0.1}\n","Config value for 'OPTIMIZER_ADAM/epsilon': {'min': 1e-08, 'max': 1e-06, 'step': 1e-08, 'stddev': 1e-07}\n","Using Neuroevolution algorithm: CoDeepNEAT\n","Using evaluation environment: RNAEnvironment\n","Maximum number of generations to evolve the population: 5\n","Maximum fitness value to evolve population up to: 200.0\n","Creating TFNE generational Backups to directory: /content/tfne_state_backups/tfne_state_backup_2023-Oct-10_14-09-16/\n","Initializing a new population of 5 blueprints and 3 modules...\n","\n","Evaluating 15 genomes in generation 0...\n","[========================================] 15/15 Genomes | Genome ID 15 achieved fitness of 18.6137\n","\n","\n","\u001b[1m############################################################  Population Summary  ############################################################\n","\n","Generation:    0  ||  Best Genome Fitness: 115.4206  ||  Avg Blueprint Fitness:  30.9268  ||  Avg Module Fitness:   28.695\u001b[0m\n","Best Genome: CoDeepNEAT Genome | ID:      4 | Fitness: 115.4206 | Blueprint ID:      2 | Module Species: {1} | Optimizer:    sgd | Origin Gen:    0\n","\n","\u001b[1mBlueprint Species       || Blueprint Species Avg Fitness       || Blueprint Species Size\u001b[0m\n","     1                  ||  30.9268                            ||        5\n","Best BP of Species 1    || CoDeepNEAT Blueprint | ID:     #2 | Fitness: 49.6495 | Nodes:    2 | Module Species: {1} | Optimizer: sgd\n","\n","\u001b[1mModule Species          || Module Species Avg Fitness          || Module Species Size\u001b[0m\n","     1                  ||   28.695                            ||        3\n","Best Mod of Species 1   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #2 | Fitness: 34.7482 | Filters:  208 | Kernel:      1 | Activ:    elu | Pool Size:      1 | Dropout:  0.6\n","\n","\u001b[1m##############################################################################################################################################\u001b[0m\n","\n","Backed up generation 0 of the CoDeepNEAT evolutionary run to file: /content/tfne_state_backups/tfne_state_backup_2023-Oct-10_14-09-16/tfne_state_backup_gen_0.json\n","\n","Evaluating 15 genomes in generation 1...\n","[========================================] 15/15 Genomes | Genome ID 30 achieved fitness of 187.9478\n","\n","\n","\u001b[1m############################################################  Population Summary  ############################################################\n","\n","Generation:    1  ||  Best Genome Fitness: 187.9478  ||  Avg Blueprint Fitness: 135.1765  ||  Avg Module Fitness: 135.1765\u001b[0m\n","Best Genome: CoDeepNEAT Genome | ID:     30 | Fitness: 187.9478 | Blueprint ID:      8 | Module Species: {1} | Optimizer:   adam | Origin Gen:    1\n","\n","\u001b[1mBlueprint Species       || Blueprint Species Avg Fitness       || Blueprint Species Size\u001b[0m\n","     1                  || 135.1765                            ||        5\n","Best BP of Species 1    || CoDeepNEAT Blueprint | ID:     #8 | Fitness: 186.0981 | Nodes:    3 | Module Species: {1} | Optimizer: adam\n","\n","\u001b[1mModule Species          || Module Species Avg Fitness          || Module Species Size\u001b[0m\n","     1                  || 135.1765                            ||        3\n","Best Mod of Species 1   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #4 | Fitness: 179.8948 | Filters:  208 | Kernel:      1 | Activ:    elu | Pool Size:      1 | Dropout:  0.6\n","\n","\u001b[1m##############################################################################################################################################\u001b[0m\n","\n","Backed up generation 1 of the CoDeepNEAT evolutionary run to file: /content/tfne_state_backups/tfne_state_backup_2023-Oct-10_14-09-16/tfne_state_backup_gen_1.json\n","\n","Evaluating 15 genomes in generation 2...\n","[========================================] 15/15 Genomes | Genome ID 45 achieved fitness of 168.8668\n","\n","\n","\u001b[1m############################################################  Population Summary  ############################################################\n","\n","Generation:    2  ||  Best Genome Fitness: 194.4314  ||  Avg Blueprint Fitness: 147.2339  ||  Avg Module Fitness: 154.2122\u001b[0m\n","Best Genome: CoDeepNEAT Genome | ID:     33 | Fitness: 194.4314 | Blueprint ID:      6 | Module Species: {1} | Optimizer:   adam | Origin Gen:    2\n","\n","\u001b[1mBlueprint Species       || Blueprint Species Avg Fitness       || Blueprint Species Size\u001b[0m\n","     1                  || 147.2339                            ||        5\n","Best BP of Species 1    || CoDeepNEAT Blueprint | ID:     #8 | Fitness: 190.6412 | Nodes:    3 | Module Species: {1} | Optimizer: adam\n","\n","\u001b[1mModule Species          || Module Species Avg Fitness          || Module Species Size\u001b[0m\n","     1                  || 154.2122                            ||        3\n","Best Mod of Species 1   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #5 | Fitness: 187.0781 | Filters:  208 | Kernel:      1 | Activ:    elu | Pool Size:      1 | Dropout:  0.6\n","\n","\u001b[1m##############################################################################################################################################\u001b[0m\n","\n","Backed up generation 2 of the CoDeepNEAT evolutionary run to file: /content/tfne_state_backups/tfne_state_backup_2023-Oct-10_14-09-16/tfne_state_backup_gen_2.json\n","\n","Evaluating 15 genomes in generation 3...\n","[========================================] 15/15 Genomes | Genome ID 60 achieved fitness of 181.912\n","\n","\n","\u001b[1m############################################################  Population Summary  ############################################################\n","\n","Generation:    3  ||  Best Genome Fitness: 195.3466  ||  Avg Blueprint Fitness: 173.1841  ||  Avg Module Fitness: 173.1609\u001b[0m\n","Best Genome: CoDeepNEAT Genome | ID:     54 | Fitness: 195.3466 | Blueprint ID:     12 | Module Species: {1} | Optimizer:   adam | Origin Gen:    3\n","\n","\u001b[1mBlueprint Species       || Blueprint Species Avg Fitness       || Blueprint Species Size\u001b[0m\n","     1                  || 173.1841                            ||        5\n","Best BP of Species 1    || CoDeepNEAT Blueprint | ID:     #8 | Fitness: 188.4865 | Nodes:    3 | Module Species: {1} | Optimizer: adam\n","\n","\u001b[1mModule Species          || Module Species Avg Fitness          || Module Species Size\u001b[0m\n","     1                  || 173.1609                            ||        3\n","Best Mod of Species 1   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #5 | Fitness: 185.8022 | Filters:  208 | Kernel:      1 | Activ:    elu | Pool Size:      1 | Dropout:  0.6\n","\n","\u001b[1m##############################################################################################################################################\u001b[0m\n","\n","Backed up generation 3 of the CoDeepNEAT evolutionary run to file: /content/tfne_state_backups/tfne_state_backup_2023-Oct-10_14-09-16/tfne_state_backup_gen_3.json\n","\n","Evaluating 15 genomes in generation 4...\n","[========================================] 15/15 Genomes | Genome ID 75 achieved fitness of 186.5654\n","\n","\n","\u001b[1m############################################################  Population Summary  ############################################################\n","\n","Generation:    4  ||  Best Genome Fitness:  195.366  ||  Avg Blueprint Fitness:  154.216  ||  Avg Module Fitness: 161.9083\u001b[0m\n","Best Genome: CoDeepNEAT Genome | ID:     62 | Fitness: 195.366 | Blueprint ID:      8 | Module Species: {1} | Optimizer:   adam | Origin Gen:    4\n","\n","\u001b[1mBlueprint Species       || Blueprint Species Avg Fitness       || Blueprint Species Size\u001b[0m\n","     1                  ||  154.216                            ||        5\n","Best BP of Species 1    || CoDeepNEAT Blueprint | ID:     #8 | Fitness: 192.3546 | Nodes:    3 | Module Species: {1} | Optimizer: adam\n","\n","\u001b[1mModule Species          || Module Species Avg Fitness          || Module Species Size\u001b[0m\n","     1                  || 161.9083                            ||        3\n","Best Mod of Species 1   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #7 | Fitness: 188.2885 | Filters:  208 | Kernel:      1 | Activ:    elu | Pool Size:      1 | Dropout:  0.6\n","\n","\u001b[1m##############################################################################################################################################\u001b[0m\n","\n","Backed up generation 4 of the CoDeepNEAT evolutionary run to file: /content/tfne_state_backups/tfne_state_backup_2023-Oct-10_14-09-16/tfne_state_backup_gen_4.json\n","\n","Evaluating 15 genomes in generation 5...\n","[========================================] 15/15 Genomes | Genome ID 90 achieved fitness of 20.4634\n","\n","\n","\u001b[1m############################################################  Population Summary  ############################################################\n","\n","Generation:    5  ||  Best Genome Fitness:  195.366  ||  Avg Blueprint Fitness: 154.2277  ||  Avg Module Fitness: 150.6592\u001b[0m\n","Best Genome: CoDeepNEAT Genome | ID:     62 | Fitness: 195.366 | Blueprint ID:      8 | Module Species: {1} | Optimizer:   adam | Origin Gen:    4\n","\n","\u001b[1mBlueprint Species       || Blueprint Species Avg Fitness       || Blueprint Species Size\u001b[0m\n","     1                  || 154.2277                            ||        5\n","Best BP of Species 1    || CoDeepNEAT Blueprint | ID:    #17 | Fitness: 190.9593 | Nodes:    3 | Module Species: {1} | Optimizer: adam\n","\n","\u001b[1mModule Species          || Module Species Avg Fitness          || Module Species Size\u001b[0m\n","     1                  || 150.6592                            ||        3\n","Best Mod of Species 1   || CoDeepNEAT Conv2D MaxPool Dropout Module | ID:     #4 | Fitness: 186.4564 | Filters:  208 | Kernel:      1 | Activ:    elu | Pool Size:      1 | Dropout:  0.6\n","\n","\u001b[1m##############################################################################################################################################\u001b[0m\n","\n","Backed up generation 5 of the CoDeepNEAT evolutionary run to file: /content/tfne_state_backups/tfne_state_backup_2023-Oct-10_14-09-16/tfne_state_backup_gen_5.json\n","Population reached specified maximum number of generations.\n","Exiting evolutionary training loop...\n","\n","> Mejor RNA generada por la evolución:\n","\n","CoDeepNEAT Genome | ID:     62 | Fitness: 195.366 | Blueprint ID:      8 | Module Species: {1} | Optimizer:   adam | Origin Gen:    4\n","\n","\n","Saved CoDeepNEAT genome (ID: 62) to file: ./best_genome_genotype_ori/genome_62_genotype.json\n"]},{"output_type":"stream","name":"stderr","text":["INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to model_dense_biasadd_readvariableop_resource in the SavedModel.\n","INFO:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","INFO:absl:Writing fingerprint to ./best_genome_model_ori/fingerprint.pb\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","\n","> Re-entrenando mejor RNA por 350 épocas...\n","\n","> Probando Genome #62:\n","  Aptitud lograda:\t194.8987\n","\n","\n","\n","Saved CoDeepNEAT genome (ID: 62) to file: ./best_genome_genotype/genome_62_genotype.json\n"]},{"output_type":"stream","name":"stderr","text":["INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to model_dense_biasadd_readvariableop_resource in the SavedModel.\n","INFO:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","INFO:absl:Writing fingerprint to ./best_genome_model/fingerprint.pb\n"]}],"source":["#@title Ejecutar NeuroEvolution\n","\n","logging_level = logging.INFO\n","config_file_path = confFileName # './codeepneat_xor_basic_example_config.cfg'\n","backup_dir_path = './tfne_state_backups/'\n","max_generations = ce_maximo_generaciones_procesar\n","\n","# Set logging, parse config\n","logging.set_verbosity(logging_level)\n","config = tfne.parse_configuration(config_file_path)\n","\n","# Initialize the environment and the specific NE algorithm\n","environment = RNAEnvironment(weight_training=True,\n","                              data_x=x_train,\n","                              data_y=y_train,\n","                              config=config,\n","                              verbosity=logging_level)\n","\n","print(\"\\n>  Definiendo Enviroment:\")\n","print(\"input_shape: \", environment.get_input_shape())\n","print(\"output_shape: \", environment.get_output_shape())\n","print(\"\")\n","\n","print(\">  Definiendo configuración:\")\n","ne_algorithm = tfne.algorithms.CoDeepNEAT(config)\n","\n","# determina si termina por alcanzar la máxima o no\n","if ce_finalizar_al_encontrar_max_fitness:\n","  max_fitness = environment.return_MaxFitness()\n","else:\n","  max_fitness = None\n","\n","\n","# Initialize evolution engine and supply config as well as initialized NE algorithm and evaluation environment.\n","engine = tfne.EvolutionEngine(ne_algorithm=ne_algorithm,\n","                              environment=environment,\n","                              backup_dir_path=backup_dir_path,\n","                              max_generations=max_generations,\n","                              max_fitness=max_fitness)\n","\n","# Start training process, returning the best genome when training ends\n","best_genome = engine.train()\n","\n","print(\"\\n> Mejor RNA generada por la evolución:\\n\")\n","print(best_genome)\n","print(\"\\n\")\n","\n","# Graba mejor genotipo y su modelo TF antes del re-entrenamiento\n","best_genotype_ori_dir = './best_genome_genotype_ori/'\n","best_model_ori_dir = './best_genome_model_ori/'\n","best_genome.save_genotype(save_dir_path=best_genotype_ori_dir)\n","best_genome.save_model(file_path=best_model_ori_dir)\n","\n","# Re-entrena mejor genotipo para ver si mejora\n","print(\"\\n\\n\")\n","environment.epochs = rna_cant_epocas_reentrenamiento_best_final\n","print(\"> Re-entrenando mejor RNA por \"+str(environment.epochs)+\" épocas...\\n\")\n","environment.eval_genome_fitness(best_genome)\n","environment.replay_genome(best_genome)\n","\n","# Graba mejor genotipo y su modelo TF después del re-entrenamiento\n","print(\"\\n\")\n","best_genotype_new_dir = './best_genome_genotype/'\n","best_model_new_dir = './best_genome_model/'\n","best_genome.save_genotype(save_dir_path=best_genotype_new_dir)\n","best_genome.save_model(file_path=best_model_new_dir)\n"]},{"cell_type":"markdown","metadata":{"id":"s30bw_ff7Zj4"},"source":["4) Evaluar el modelo de la RNA generada:"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"dDr_EuIkNnI-","executionInfo":{"status":"ok","timestamp":1696947869907,"user_tz":180,"elapsed":1399,"user":{"displayName":"PABLO GONZALO PYTEL","userId":"07736403464797369193"}},"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","outputId":"cfbbebe5-4c47-4f5d-813e-b8e3c7511408"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Modelo recuperado de  ./best_genome_model/\n","\n","\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 16, 16, 3)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 16, 16, 208)       832       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 16, 16, 208)       0         \n"," D)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 16, 16, 208)       0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 16, 16, 208)       43472     \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 16, 16, 208)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_1 (Dropout)         (None, 16, 16, 208)       0         \n","                                                                 \n"," flatten (Flatten)           (None, 53248)             0         \n","                                                                 \n"," dense (Dense)               (None, 10)                532490    \n","                                                                 \n","=================================================================\n","Total params: 576794 (2.20 MB)\n","Trainable params: 576794 (2.20 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n"]}],"source":["#@title Cargar modelo de mejor genoma de RNA generada\n","\n","usar_modelo = \"Re-Entrenado\" #@param [\"Original\", \"Re-Entrenado\"]\n","\n","if usar_modelo == \"Original\":\n","  best_model_dir = best_model_ori_dir\n","else:\n","  best_model_dir= best_model_new_dir\n","\n","modelRNA = tf.keras.models.load_model(best_model_dir)\n","print(\"\\nModelo recuperado de \", best_model_dir)\n","\n","print(\"\\n\")\n","modelRNA.summary()\n","print(\"\\n\")\n"]},{"cell_type":"code","execution_count":32,"metadata":{"cellView":"form","id":"kVDw0-o-Oca0","executionInfo":{"status":"ok","timestamp":1696947871611,"user_tz":180,"elapsed":27,"user":{"displayName":"PABLO GONZALO PYTEL","userId":"07736403464797369193"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c15d0ac-60fb-4362-d476-0242ce7c016a"},"outputs":[{"output_type":"stream","name":"stdout","text":["*** Resultados con datos de Entrenamiento: \n","15/15 [==============================] - 0s 3ms/step\n","\n"," Reporte de Clasificación: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        48\n","           1       1.00      1.00      1.00        48\n","           2       1.00      1.00      1.00        44\n","           3       1.00      0.92      0.96        48\n","           4       0.96      1.00      0.98        48\n","           5       0.92      1.00      0.96        48\n","           6       1.00      0.96      0.98        48\n","           7       1.00      1.00      1.00        48\n","           8       1.00      1.00      1.00        48\n","           9       1.00      1.00      1.00        48\n","\n","    accuracy                           0.99       476\n","   macro avg       0.99      0.99      0.99       476\n","weighted avg       0.99      0.99      0.99       476\n","\n","\n","Matriz de Confusión: \n","     p:8  p:3  p:4  p:0  p:6  p:5  p:1  p:9  p:7  p:2\n","r:8   48    0    0    0    0    0    0    0    0    0\n","r:3    0   44    2    0    0    2    0    0    0    0\n","r:4    0    0   48    0    0    0    0    0    0    0\n","r:0    0    0    0   48    0    0    0    0    0    0\n","r:6    0    0    0    0   46    2    0    0    0    0\n","r:5    0    0    0    0    0   48    0    0    0    0\n","r:1    0    0    0    0    0    0   48    0    0    0\n","r:9    0    0    0    0    0    0    0   48    0    0\n","r:7    0    0    0    0    0    0    0    0   48    0\n","r:2    0    0    0    0    0    0    0    0    0   44\n","\n","\n"]}],"source":["#@title Probar RNA con datos de entrenamiento\n","mostrar_detalle_imagenes_entrenamiento = False #@param {type:\"boolean\"}\n","\n","# función auxiliar para probar el modelo entrenado en detalle\n","def probarModelo(x, y, esDAimag, clases_map, mostrarImagenes=False):\n","\n","    # procesa las imágenes de prueba con el modelo\n","    predClass = modelRNA.predict(x)\n","\n","    # muestra los resultados con las imágenes\n","    umbralClas = 0.5\n","    classPreds = []\n","    classReal = []\n","    for i in range(len(x)):\n","\n","        # asigna el nombre de la clase real\n","        clReal = clases_map[ y[i] ]\n","\n","        # determina la clase predecida\n","        if tipo_output_softMax:\n","            ## determina clase predecida de acuerdo a la que tiene mayor valor\n","            idclPred = int( np.argmax(predClass[i], axis=0) )\n","            idclPredRnd = idclPred\n","        else:\n","            ## determina clase predecida de acuerdo al umbral de clasificación\n","            idclPred = predClass[i][0]\n","            idclPredRnd = int(idclPred)\n","            if (idclPred - idclPredRnd)>0.5 and (idclPredRnd+1)<len(clases_map):\n","                    idclPredRnd = idclPredRnd + 1\n","\n","        # asigna el nombre de la clase predecida\n","        if idclPredRnd<0 or idclPredRnd>=len(clases_map):\n","            clPred = \"CLASE \" + str(idclPredRnd) + \" INVÁLIDA!\"\n","        else:\n","            clPred = clases_map[ idclPredRnd ]\n","\n","        # agrega a vevtores auxiliares\n","        classReal.append( clReal )\n","        classPreds.append( clPred )\n","\n","        # sólo muestra las imágenes no generadas por DA\n","        if mostrarImagenes:\n","          strTitulo = 'Real: ' + clReal + ' / RNA: '\n","          strTitulo = strTitulo + clPred + ' (' + str( idclPred ) +')'\n","\n","          # muestra comparación con la imagen\n","          fig = plt.figure()\n","          fig.suptitle( strTitulo )\n","          ax1 = fig.add_subplot(121)\n","          plot_image( x[i] )\n","\n","          plt.tight_layout()\n","          fig = plt.gcf()\n","\n","    # muestra reporte de clasificación\n","    print(\"\\n Reporte de Clasificación: \")\n","    print(classification_report(classReal, classPreds))\n","\n","    # muestra matriz de confusion\n","    print('\\nMatriz de Confusión: ')\n","    cm = confusion_matrix(classReal, classPreds, labels=clases_map)\n","    cmtx = pd.DataFrame(\n","        cm,\n","        index=['r:{:}'.format(x) for x in clases_map],\n","        columns=['p:{:}'.format(x) for x in clases_map]\n","      )\n","    print(cmtx)\n","    print(\"\\n\")\n","\n","    if mostrarImagenes:\n","      print(\"\\n>Resultados: \")\n","\n","\n","# prueba con los datos de entrenamiento\n","print(\"*** Resultados con datos de Entrenamiento: \")\n","probarModelo(x_train, y_train, esDAimag_train, clases_map, mostrar_detalle_imagenes_entrenamiento)\n"]},{"cell_type":"code","execution_count":33,"metadata":{"cellView":"form","id":"OoQ7iOSdQF30","executionInfo":{"status":"ok","timestamp":1696947871612,"user_tz":180,"elapsed":22,"user":{"displayName":"PABLO GONZALO PYTEL","userId":"07736403464797369193"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb4c1240-34c9-4aab-abb0-b07dc0fe8bbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["*** Resultados con datos de Prueba: \n","4/4 [==============================] - 0s 3ms/step\n","\n"," Reporte de Clasificación: \n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.67      0.73        12\n","           1       1.00      0.83      0.91        12\n","           2       1.00      1.00      1.00        12\n","           3       0.86      1.00      0.92        12\n","           4       0.80      0.67      0.73        12\n","           5       0.71      0.83      0.77        12\n","           6       0.60      0.50      0.55        12\n","           7       0.71      0.83      0.77        12\n","           8       0.62      0.83      0.71        12\n","           9       1.00      0.83      0.91        12\n","\n","    accuracy                           0.80       120\n","   macro avg       0.81      0.80      0.80       120\n","weighted avg       0.81      0.80      0.80       120\n","\n","\n","Matriz de Confusión: \n","     p:8  p:3  p:4  p:0  p:6  p:5  p:1  p:9  p:7  p:2\n","r:8   10    2    0    0    0    0    0    0    0    0\n","r:3    0   12    0    0    0    0    0    0    0    0\n","r:4    0    0    8    2    0    0    0    0    2    0\n","r:0    0    0    0    8    2    2    0    0    0    0\n","r:6    2    0    2    0    6    2    0    0    0    0\n","r:5    0    0    0    0    2   10    0    0    0    0\n","r:1    2    0    0    0    0    0   10    0    0    0\n","r:9    0    0    0    0    0    0    0   10    2    0\n","r:7    2    0    0    0    0    0    0    0   10    0\n","r:2    0    0    0    0    0    0    0    0    0   12\n","\n","\n"]}],"source":["#@title Probar RNA con datos de prueba\n","\n","mostrar_detalle_imagenes_prueba = False #@param {type:\"boolean\"}\n","\n","print(\"*** Resultados con datos de Prueba: \")\n","probarModelo(x_test, y_test, esDAimag_train, clases_map, mostrar_detalle_imagenes_prueba)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}