{"cells":[{"cell_type":"markdown","metadata":{"id":"1Tu5MvS864Vv"},"source":["#Demo NeuroEvolution usando Tensorflow-Neuroevolution framework (TFNE) para generar una RNA que pueda aprender a clasificar en base a imágenes\n","Fuente TFNE: https://github.com/PaulPauls/Tensorflow-Neuroevolution"]},{"cell_type":"markdown","metadata":{"id":"ZyCmxopcGYCB"},"source":["0) Preparar ambiente:"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"i79ux8zd64wv"},"outputs":[],"source":["#@title Instalar TFNE\n","!pip install tfne\n","\n","###!git clone https://github.com/PaulPauls/Tensorflow-Neuroevolution\n","###%cd Tensorflow-Neuroevolution\n","###!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"soqbTJnR-vgh"},"source":["1) Cargar librerías:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b4oaPcXw-uzT"},"outputs":[],"source":["#@title Librerías a usar\n","from absl import app, flags, logging\n","from __future__ import annotations\n","\n","import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","import os\n","import csv\n","\n","import tfne\n","from tfne.environments import BaseEnvironment\n","from tfne.helper_functions import read_option_from_config\n","\n","from sklearn.model_selection import train_test_split\n","from keras.utils import np_utils\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","print(\"Librerías cargadas\")"]},{"cell_type":"markdown","metadata":{"id":"cnL_qtVxM_DN"},"source":["2) Determinar configuración:"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"yU_Vllt7GzIW"},"outputs":[],"source":["#@title Parámetros para NeuroEvolution\n","\n","#@markdown Criterio de Paro:\n","ce_maximo_generaciones_procesar = 10 #@param {type:\"integer\"}\n","ce_finalizar_al_encontrar_max_fitness = True #@param {type:\"boolean\"}\n","#@markdown Función de Aptitud:\n","fitness_calc_usando_exactitud = \"Suma Entrenamiento & Validacion\" #@param [\"Entrenamiento\", \"Validacion\", \"Min Entrenamiento & Validacion\", \"Promedio Entrenamiento & Validacion\", \"Suma Entrenamiento & Validacion\"]\n","fitness_penalizar_x_topologia = False #@param {type:\"boolean\"}\n","#@markdown Blueprints (topología & optimizador):\n","ce_cant_poblacion_blueprints =  10#@param {type:\"integer\"}\n","#@markdown  Genomas (instancias de RNAs):\n","ce_cant_genomas_por_blueprint =  8#@param {type:\"integer\"}\n","#@markdown Módulos (capas RNA):\n","ce_cant_poblacion_modulos =  30#@param {type:\"integer\"}\n","ce_tipo_generacion_modulos = \"Dinamica\" #@param [\"Basica\", \"Dinamica\", \"Fija\"]\n","#@markdown Operadores Genéticos:\n","ce_max_mutacion = 0.85 #@param {type:\"number\"}\n","ce_probab_mutacion = 0.4 #@param {type:\"number\"}\n","ce_probab_cruzamiento = 0.6 #@param {type:\"number\"}\n","#@markdown Entrenamiento RNA:\n","rna_cant_epocas_entrenamiento = 50#@param {type:\"integer\"}\n","rna_cant_epocas_entrenamiento_incrementa_por_generacion = 25#@param {type:\"integer\"}\n","rna_cant_epocas_reentrenamiento_best_final =   350#@param {type:\"integer\"}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"a8aPzMxQNCT2"},"outputs":[],"source":["#@title Imágenes a Usar\n","\n","# monta Google Drive:\n","# Nota: la primera vez se debe confirmar el uso logueandose en \"Google Drive File Stream\" y obteniendo código de autentificación.\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# directorio local en Google Drive\n","path = '/content/gdrive/My Drive/IA/demoML/imagenes/IRIS'  #@param {type:\"string\"}\n","\n","#@markdown ### Subdirectorios de las imágenes:\n","\n","path_entrenamiento = '/train'  #@param {type:\"string\"}\n","path_prueba = '/test'  #@param {type:\"string\"}\n","\n","imagPath_train = path + path_entrenamiento\n","imagPath_test = path + path_prueba\n","\n","#@markdown ### Parámetros de imágenes:\n","imagen_largo_ancho = 32 #@param {type:\"integer\"}\n","imagen_color = True #@param {type:\"boolean\"}\n","imagen_usar_generadas_data_augmentation = True #@param {type:\"boolean\"}\n","tipo_output_softMax = True\n","\n","## aplicación de los parámetros elegidos\n","\n","# tamaño de las imágenes\n","if imagen_largo_ancho<=10:\n","  imagen_largo_ancho = 10\n","IMAGE_SHAPE = (imagen_largo_ancho, imagen_largo_ancho, (3 if imagen_color else 1))\n","\n","# indica si se usan las imágenes generadas por data augmentation\n","usarDA = imagen_usar_generadas_data_augmentation\n","\n","# define tamaño de datos de entrada \n","num_inputs = IMAGE_SHAPE[0] * IMAGE_SHAPE[1] * IMAGE_SHAPE[2]\n","\n","print (\"Tamaño Imagen: \", IMAGE_SHAPE)\n"]},{"cell_type":"code","source":["#@title Cargar imágenes\n","# define función para cargar las imágenes\n","def cargarImagenes(imagPath):\n","  classes_ori = [] \n","  images_ori = []\n","  esDA_ori = []\n","\n","  all_dirs = os.listdir( imagPath )\n","  for each_dir in all_dirs:\n","\n","      auxiPath = imagPath + '/' + each_dir \n","      imagFN  = os.listdir( auxiPath )\n","      for each_imagFN in imagFN:\n","\n","            esImagDA = (each_imagFN[:2] == 'da')\n","            \n","            if usarDA or (not esImagDA): \n","                \n","                # abre la imagen\n","                imag = Image.open(auxiPath + \"/\" + each_imagFN)\n","                \n","                # ajusta el tamaño\n","                if IMAGE_SHAPE[2]==1:              \n","                  tipoImage = 'L'\n","                else:                \n","                  tipoImage = 'RGB'\n","                imag = imag.convert(tipoImage)\n","                imag = imag.resize((IMAGE_SHAPE[0], IMAGE_SHAPE[1]), Image.ANTIALIAS)          \n","                \n","                # transforma a un vector de nros\n","                arImag = np.array(imag)\n","                \n","                # agrega a los vectores\n","                classes_ori.append( each_dir )\n","                images_ori.append( arImag )\n","                esDA_ori.append( esImagDA )\n","\n","  return classes_ori, images_ori, esDA_ori, tipoImage\n","\n","# carga las imagenes de entrenamiento\n","classes_train, images_train, esDAimag_train, tipoImage_train = cargarImagenes(imagPath_train)\n","print(\"> Para Entrenamiento: \")\n","print(\"- Clases cargadas: \", len(classes_train))\n","print(\"- Imágenes cargadas: \", len(classes_train))\n","\n","if len(classes_train)>0:\n","  print(\"- Ejemplo \", classes_train[0], \" \", images_train[0].shape, \": \")\n","  display( Image.fromarray(images_train[0], tipoImage_train) )\n","\n","# carga las imagenes de prueba\n","classes_test, images_test, esDAimag_test, tipoImage_test = cargarImagenes(imagPath_test)\n","print(\"\\n\\n> Para Prueba: \")\n","print(\"- Clases cargadas: \", len(classes_test))\n","print(\"- Imágenes cargadas: \", len(images_test))\n","\n","if len(classes_test)>0:\n","  print(\"- Ejemplo \", classes_test[0], \" \", images_test[0].shape, \": \")\n","  display( Image.fromarray(images_test[0], tipoImage_test) )"],"metadata":{"cellView":"form","id":"MSJf_VfTtrQo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Preparar imágenes\n","# define función auxiliar para mostrar imágenes preparadas\n","def plot_image(imag):\n","  if IMAGE_SHAPE[2]==1:\n","    plt.imshow((imag*255).reshape(IMAGE_SHAPE[0], IMAGE_SHAPE[1]).astype(np.uint8))\n","    plt.gray()\n","  else:\n","    plt.imshow((imag*255).reshape(IMAGE_SHAPE).astype(np.uint8))\n","  plt.axis(\"off\")  \n","\n","# define función auxiliar para preparar la lista de imágenes a procesar\n","def prepare_imageList(imagList):    \n","  auxiAr = np.array(imagList).astype('float32') / 255.\n","  auxiAr = auxiAr.reshape((len(auxiAr), num_inputs))  \n","  return np.array(auxiAr)\n","\n","# define función auxiliar para preparar lista de clases \n","def prepare_clasesList(classesList, dictMapeo=None):\n","  if dictMapeo==None:\n","    # genera diccionario de mapeo\n","    auxDict = list(set(classesList))\n","    dictMapeo = dict( zip( auxDict, range(len(auxDict)) ) )\n","  # realiza el mapeo\n","  y = []\n","  for cl in classesList:\n","      y.append( dictMapeo[cl] )\n","  # convierte valores numéricos a columnas de vakores binarios (i.e. one hot encoded)\n","  dummy_y = np_utils.to_categorical(y)\n","  # devuelve\n","  return np.array(y), np.array(dummy_y), dictMapeo\n","\n","# define vector auxiliar de datos de entrada para usar en el entrenamiento y prueba\n","x_train = prepare_imageList(images_train)\n","x_test = prepare_imageList(images_test)\n","\n","# define vector auxiliar de datos de salida para usar en el entrenamiento y prueba\n","# también usa esta información para determinar la cantida de neuronas de salida\n","y_train, y_trainEnc, dictMapeo = prepare_clasesList(classes_train)\n","y_test, y_testEnc,_ = prepare_clasesList(classes_test, dictMapeo)\n","\n","# genera diccionario auxiliar para poder convertir de ID de clase a nombre de clase\n","clases_map = [ x for x,y in dictMapeo.items() ]\n","\n","print(\"> Para Entrenamiento: \")\n","print(\" - x_train (cant ejemplos, datos entrada): \", x_train.shape)\n","if tipo_output_softMax:\n","  print(\" - y_trainEnc (cant): \", len(y_trainEnc))\n","else:\n","  print(\" - y_train (cant): \", len(y_train))\n","print(\"\\n\\n> Para Prueba: \")\n","print(\" - x_test (cant ejemplos, datos entrada): \", x_test.shape)\n","if tipo_output_softMax:\n","  print(\" - y_testEnc (cant): \", len(y_testEnc))\n","else:\n","  print(\" - y_test (cant): \", len(y_test))\n","print(\"\\n\\n> Para Ambos: \")\n","print(\" - dictMapeo: \", dictMapeo)\n","print(\" - clases_map: \", clases_map)\n","if len(y_train)>0:\n","  print(\"\\n - Imagen reconstruida de \", clases_map[y_train[0]],  \"(\", y_train[0], \" / \", y_trainEnc[0], \")\")\n","  plot_image(x_train[0])"],"metadata":{"cellView":"form","id":"sm0DqV9Utywf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G96unKkBIPDW"},"source":["2) Preparar para NeuroEvolution:"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"FCbZ1lpH_wgQ"},"outputs":[],"source":["#@title Crear Archivo Configuración \n","# ver explicación en https://tfne.readthedocs.io/en/latest/codeepneat/codeepneat-config.html \n","\n","confFileName = './codeepneat_config.cfg'\n","\n","s = \"\"\n","with open(confFileName, 'w') as f:\n","    s = s + \"[EVALUATION]\\n\"\n","    s = s + \"epochs        = \" + str(rna_cant_epocas_entrenamiento) + \"\\n\"\n","    s = s + \"batch_size    = None\\n\"\n","    s = s + \"preprocessing = None\\n\"\n","    if rna_cant_epocas_entrenamiento_incrementa_por_generacion > 0:      \n","      s = s + \"increase_epochs_every_n_genomes = \" + str(ce_cant_poblacion_blueprints*ce_cant_genomas_por_blueprint) + \"\\n\"\n","      s = s + \"increase_epochs_add_epochs = \" + str(rna_cant_epocas_entrenamiento_incrementa_por_generacion) + \"\\n\"\n","    else:\n","      s = s + \"increase_epochs_every_n_genomes = 0\\n\"\n","      s = s + \"increase_epochs_add_epochs = 0\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[FITNESS]\\n\"\n","    if fitness_calc_usando_exactitud == \"Entrenamiento\":\n","      s = s + \"calc_using_accuracy    = 'E'\\n\"    \n","    elif fitness_calc_usando_exactitud == \"Validacion\":\n","      s = s + \"calc_using_accuracy    = 'V'\\n\"    \n","    elif fitness_calc_usando_exactitud == \"Min Entrenamiento & Validacion\":\n","      s = s + \"calc_using_accuracy    = 'M'\\n\"    \n","    elif fitness_calc_usando_exactitud == \"Promedio Entrenamiento & Validacion\":\n","      s = s + \"calc_using_accuracy    = 'P'\\n\"    \n","    else:\n","      s = s + \"calc_using_accuracy    = 'S'\\n\"        \n","    s = s + \"penalize_based_on_topology  = \" + str(fitness_penalizar_x_topologia) + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[POPULATION]\\n\"\n","    s = s + \"bp_pop_size    = \" + str(ce_cant_poblacion_blueprints) + \"\\n\"\n","    s = s + \"mod_pop_size   = \" + str(ce_cant_poblacion_modulos) + \"\\n\"\n","    s = s + \"genomes_per_bp = \" + str(ce_cant_genomas_por_blueprint ) + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[GENOME]\\n\"\n","    s = s + \"dtype                = 'float32'\\n\"\n","    s = s + \"available_modules    = ['DenseDropout']\\n\"\n","    s = s + \"available_optimizers = ['SGD','Adam']\\n\"\n","    s = s + \"output_layers        = [{'class_name': 'Dense', 'config': {'units': \"+ str(len(clases_map)) + \", 'activation': 'softmax'}}] \\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[MODULE_SPECIATION]\\n\"\n","    if ce_tipo_generacion_modulos == \"Dinamica\":\n","      # Dinamica      \n","      s = s + \"mod_spec_type            = 'param-distance-dynamic'\\n\"\n","      s = s + \"mod_spec_species_count   = 4\\n\"\n","      s = s + \"mod_spec_distance        = 0.3\\n\"\n","      s = s + \"mod_spec_mod_elitism     = 2\\n\"\n","      s = s + \"mod_spec_min_offspring   = 1\\n\"\n","      s = s + \"mod_spec_reprod_thres    = 0.5\\n\"\n","      s = s + \"mod_spec_max_stagnation  = 10\\n\"\n","      s = s + \"mod_spec_species_elitism = 2\\n\"\n","      s = s + \"mod_spec_rebase_repr     = True\\n\"\n","      s = s + \"mod_spec_reinit_extinct  = False\\n\"\n","    elif ce_tipo_generacion_modulos == \"Fija\":\n","      # Fija\n","      s = s + \"mod_spec_type            = 'param-distance-fixed'\\n\"\n","      s = s + \"mod_spec_distance        = 0.3\\n\"\n","      s = s + \"mod_spec_mod_elitism     = 2\\n\"\n","      s = s + \"mod_spec_min_offspring   = 1\\n\"\n","      s = s + \"mod_spec_reprod_thres    = 0.5\\n\"\n","      s = s + \"mod_spec_max_stagnation  = 10\\n\"\n","      s = s + \"mod_spec_species_elitism = 2\\n\"\n","      s = s + \"mod_spec_rebase_repr     = True\\n\"\n","      s = s + \"mod_spec_reinit_extinct  = False\\n\"\n","    else:\n","      # Basica\n","      s = s + \"mod_spec_type          = 'basic'\\n\"\n","      s = s + \"mod_spec_mod_elitism   = 4\\n\"\n","      s = s + \"mod_spec_min_offspring = 1\\n\"\n","      s = s + \"mod_spec_reprod_thres  = 0.5\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[MODULE_EVOLUTION]\\n\"\n","    s = s + \"mod_max_mutation   = \" + str(ce_max_mutacion) + \"\\n\"\n","    s = s + \"mod_mutation_prob  = \" + str(ce_probab_mutacion) + \"\\n\"\n","    s = s + \"mod_crossover_prob = \" + str(ce_probab_cruzamiento) + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[BP_SPECIATION]\\n\"\n","    if ce_tipo_generacion_modulos == \"Dinamica\":\n","      # Dinamica\n","      s = s + \"bp_spec_type            = 'gene-overlap-dynamic'\\n\"\n","      s = s + \"bp_spec_species_count   = 3\\n\"\n","      s = s + \"bp_spec_distance        = 0.3\\n\"\n","      s = s + \"bp_spec_bp_elitism      = 2\\n\"\n","      s = s + \"bp_spec_min_offspring   = 1\\n\"\n","      s = s + \"bp_spec_reprod_thres    = 0.5\\n\"\n","      s = s + \"bp_spec_max_stagnation  = 15\\n\"\n","      s = s + \"bp_spec_species_elitism = 2\\n\"\n","      s = s + \"bp_spec_rebase_repr     = True\\n\"\n","      s = s + \"bp_spec_reinit_extinct  = True\\n\"\n","    elif ce_tipo_generacion_modulos == \"Fija\":\n","      # Fija\n","      s = s + \"bp_spec_type            = 'gene-overlap-fixed'\\n\"\n","      s = s + \"bp_spec_distance        = 0.3\\n\"\n","      s = s + \"bp_spec_bp_elitism      = 2\\n\"\n","      s = s + \"bp_spec_min_offspring   = 1\\n\"\n","      s = s + \"bp_spec_reprod_thres    = 0.5\\n\"\n","      s = s + \"bp_spec_max_stagnation  = 15\\n\"\n","      s = s + \"bp_spec_species_elitism = 2\\n\"\n","      s = s + \"bp_spec_rebase_repr     = True\\n\"\n","      s = s + \"bp_spec_reinit_extinct  = True\\n\"  \n","    else:\n","      # Basica    \n","      s = s + \"bp_spec_type          = 'basic'\\n\"\n","      s = s + \"bp_spec_bp_elitism    = 2\\n\"\n","      s = s + \"bp_spec_min_offspring = 1\\n\"\n","      s = s + \"bp_spec_reprod_thres  = 0.5\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[BP_EVOLUTION]\\n\"    \n","    if ce_tipo_generacion_modulos == \"Dinamica\":\n","      # Dinamica      \n","      s = s + \"bp_max_mutation            = 0.3\\n\"    \n","      s = s + \"bp_mutation_add_conn_prob  = 0.2\\n\"\n","      s = s + \"bp_mutation_add_node_prob  = 0.2\\n\"\n","      s = s + \"bp_mutation_rem_conn_prob  = 0.05\\n\"\n","      s = s + \"bp_mutation_rem_node_prob  = 0.05\\n\"\n","      s = s + \"bp_mutation_node_spec_prob = 0.3\\n\"\n","      s = s + \"bp_mutation_optimizer_prob = 0.1\\n\"\n","      s = s + \"bp_crossover_prob          = 0.1\\n\"\n","    else:\n","      # Fija o Basica\n","      s = s + \"bp_max_mutation            = 0.3\\n\"    \n","      s = s + \"bp_mutation_add_conn_prob  = 0.3\\n\"\n","      s = s + \"bp_mutation_add_node_prob  = 0.3\\n\"\n","      s = s + \"bp_mutation_rem_conn_prob  = 0.05\\n\"\n","      s = s + \"bp_mutation_rem_node_prob  = 0.05\\n\"\n","      s = s + \"bp_mutation_node_spec_prob = 0.1\\n\"\n","      s = s + \"bp_mutation_optimizer_prob = 0.1\\n\"\n","      s = s + \"bp_crossover_prob          = 0.1\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[MODULE_DENSEDROPOUT]\\n\"\n","    s = s + \"merge_method = [{'class_name': 'Concatenate', 'config': {'axis': -1}}]\\n\"\n","    s = s + \"units        = {'min': 2, 'max': 100, 'step': 4, 'stddev': 6}\\n\"\n","    s = s + \"activation   = ['linear', 'relu', 'sigmoid', 'softmax', 'tanh']\\n\"\n","    s = s + \"kernel_init  = ['glorot_normal', 'he_normal']\\n\"\n","    s = s + \"bias_init    = ['zeros']\\n\"\n","    s = s + \"dropout_flag = 0.5\\n\"\n","    s = s + \"dropout_rate = {'min': 0.1, 'max': 0.4, 'step': 0.1, 'stddev': 0.1}\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[OPTIMIZER_SGD]\\n\"\n","    s = s + \"learning_rate = {'min': 0.1, 'max': 0.3, 'step': 0.05, 'stddev': 0.05}\\n\"\n","    s = s + \"momentum      = {'min': 0.3, 'max': 0.7, 'step': 0.1, 'stddev': 0.1}\\n\"\n","    s = s + \"nesterov      = [True, False] \\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"[OPTIMIZER_ADAM]\\n\"\n","    s = s + \"learning_rate = {'min': 0.0001, 'max': 0.1, 'step': 0.0001, 'stddev': 0.02}\\n\"\n","    s = s + \"beta_1        = {'min': 0.6, 'max': 1.5, 'step': 0.05, 'stddev': 0.2}\\n\"\n","    s = s + \"beta_2        = {'min': 0.8, 'max': 1.2, 'step': 0.001, 'stddev': 0.1}\\n\"\n","    s = s + \"epsilon       = {'min': 1e-8, 'max': 1e-6, 'step': 1e-8, 'stddev': 1e-7}\\n\"\n","    s = s + \"\\n\"\n","    s = s + \"\\n\"\n","    \n","    f.write(s)\n","\n","# muestra nuevo archivo modificado\n","%cat {confFileName}"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"6QNOESjoDj6B"},"outputs":[],"source":["#@title Definir clase para el ambiente RNAEnvironment\n","\n","class RNAEnvironment(BaseEnvironment):\n","    \"\"\"\n","    TFNE compatible environment for the RNA\n","    \"\"\"\n","\n","    def __init__(self, weight_training, data_x, data_y, config=None, verbosity=0, **kwargs):\n","        \"\"\"\n","        Initializes environment by setting up the dataset and processing the supplied config or supplied config\n","        parameters. The configuration of the environment can either be supplied via a config file or via seperate config\n","        parameters in the initialization.\n","        @param weight_training: bool flag, indicating wether evaluation should be weight training or not\n","        @param config: ConfigParser instance holding an 'Environment' section specifying the required environment\n","                       parameters for the chosen evaluation method.\n","        @param verbosity: integer specifying the verbosity of the evaluation\n","        @param kwargs: Optionally supplied dict of each configuration parameter seperately in order to allow the\n","                       creation of the evaluation environment without the requirement of a config file.\n","        \"\"\"\n","        # Initialize corresponding input and output mappings\n","        print(\"> Preparando el ambiente...\")\n","\n","        # Initialize loss function to evaluate performance on either evaluation method and safe verbosity parameter\n","        self.accuracy_metric = tf.keras.metrics.Accuracy()\n","        self.verbosity = verbosity\n","\n","        # Determine and setup explicit evaluation method in accordance to supplied parameters\n","        if not weight_training:\n","            # Set up environment as non-weight training, requiring no parameters\n","            self.eval_genome_fitness = self._eval_genome_fitness_non_weight_training\n","\n","        elif config is None and len(kwargs) == 0:\n","            raise RuntimeError(\"No se han definido los parámetros para poder realizar la evolución y el entrenamiento de las RNA\")\n","\n","        elif len(kwargs) == 0:\n","            # Set up environment as weight training and with a supplied config file\n","            self.eval_genome_fitness = self._eval_genome_fitness_weight_training\n","            self.epochs = read_option_from_config(config, 'EVALUATION', 'epochs')\n","            self.batch_size = read_option_from_config(config, 'EVALUATION', 'batch_size')\n","            self.increase_epochs_every_n_genomes = read_option_from_config(config, 'EVALUATION', 'increase_epochs_every_n_genomes')\n","            self.increase_epochs_add_epochs = read_option_from_config(config, 'EVALUATION', 'increase_epochs_add_epochs')\n","            #  parámetros para calculo fitness\n","            self.calcFitness = read_option_from_config(config, 'FITNESS', 'calc_using_accuracy')\n","            self.penalFitness = read_option_from_config(config, 'FITNESS', 'penalize_based_on_topology')\n","\n","        elif config is None:\n","            # Set up environment as weight training and explicitely supplied parameters\n","            self.eval_genome_fitness = self._eval_genome_fitness_weight_training\n","            self.epochs = kwargs['epochs']\n","            self.batch_size = kwargs['batch_size']\n","            self.increase_epochs_every_n_genomes = kwargs['increase_epochs_every_n_genomes']\n","            self.increase_epochs_add_epochs = kwargs['increase_epochs_add_epochs']            \n","            # determina parámetros para calculo fitness\n","            self.calcFitness = kwargs['fitness_calc_using_accuracy']\n","            self.penalFitness = kwargs['fitness_penalize_based_on_topology']\n","\n","        print(\" Definiendo parámetros para cálculo de aptitud: \")\n","        print(\"        calcFitness = \", self.calcFitness)\n","        print(\"        penalFitness = \", self.penalFitness)\n","\n","        if self.calcFitness == \"E\":\n","            # se toman todos los datos para entrenamiento\n","            x_t, x_v, y_t, y_v = data_x, [], data_y, []\n","        else:\n","            # separa al azar usando muestreo al azar del 10%\n","            # para tomar algunos como datos de validación\n","            x_t, x_v, y_t, y_v = train_test_split(data_x, \n","                                                data_y, \n","                                                test_size=0.1)\n","\n","        print(\"  Definiendo datos: de los \", len(x_train), \"ejemplos de entrenamiento: \")\n","        print(\"                      se usan \", len(x_t), \"ejemplos para entrenar \")\n","        print(\"                      y \", len(x_v), \"ejemplos para validar.\")\n","        print(\"\\n\")\n","        self.x_train = np.array(x_t)\n","        self.y_train = np.array(y_t)\n","\n","        self.x_val = np.array(x_v)\n","        self.y_val = np.array(y_v)\n","\n","        # genera salida codificada para entrenamiento con capa softMax\n","        self.y_trainEnc = np_utils.to_categorical(self.y_train)\n","\n","        # determina neuronas de entrada y salida\n","        self.cantX = self.x_train.shape[1]\n","        self.cantY = self.y_trainEnc.shape[1]\n","        return\n","\n","    def eval_genome_fitness(self, genome) -> float:\n","        # TO BE OVERRIDEN\n","        raise RuntimeError()\n","  \n","    def _calculate_fitness(self, model, penalFitness=False) -> float:\n","        \"\"\"\n","        The genomes fitness is then calculated and returned as\n","        the percentage of training and/or validation examples classified correctly.           \n","        \"\"\"\n","        # calcula para datos de entrenamiento\n","        if len(self.y_train)>0:\n","          self.accuracy_metric.reset_states()\n","          self.accuracy_metric.update_state(self.y_train, np.argmax(model(self.x_train), axis=-1))\n","          evaluated_fitness_train = round(self.accuracy_metric.result().numpy() * 100, 4)        \n","        else:\n","          evaluated_fitness_train = 0.0\n","        # calcula para datos de entrenamiento\n","        if len(self.y_val)>0:\n","          self.accuracy_metric.reset_states()\n","          self.accuracy_metric.update_state(self.y_val, np.argmax(model(self.x_val), axis=-1))\n","          evaluated_fitness_val = round(self.accuracy_metric.result().numpy() * 100, 4)        \n","        else:\n","          evaluated_fitness_val = 0.0\n","        # calcula final como promedio         \n","        if self.calcFitness == \"E\":\n","          # sólo de entrenamiento\n","          evaluated_fitness = evaluated_fitness_train\n","        elif self.calcFitness == \"V\":\n","          # sólo de validación\n","          evaluated_fitness = evaluated_fitness_val\n","        elif self.calcFitness == \"P\":\n","          # promedio ente ambos\n","          evaluated_fitness = (evaluated_fitness_train + evaluated_fitness_val)/2\n","        elif self.calcFitness ==  \"S\":\n","          # suma ente ambos\n","          evaluated_fitness = (evaluated_fitness_train + evaluated_fitness_val)\n","        else:\n","          # mínimo ente ambos\n","          evaluated_fitness = min([evaluated_fitness_train, evaluated_fitness_val])\n","        if penalFitness:\n","          # sólo se aplica la penalización\n","          # si está cercano a alcanzar la aptitud máxima\n","          maxFit = self.return_MaxFitness()\n","          if evaluated_fitness >= (maxFit - 11):\n","            # penaliza aptitud teniendo en cuenta la complejidad de la RNA          \n","            penalLayers = -1.5\n","            ajusteCantPesos = self.cantX\n","            for i in range(len(model.layers)):\n","              l = model.layers[i]\n","              tipoLay = str(type(l))            \n","              if \"Dense\" in tipoLay:                \n","                if i > 1:\n","                  # contabiliza en base a la cantidad de pesos de las conexiones\n","                  # nota: no tiene en cuenta los pesos de la capa de entrada ni de salida\n","                  cantPesos = len(l.get_weights()[0]) \n","                  penalLayers = penalLayers + (cantPesos / ajusteCantPesos)\n","              elif \"Dropout\" in tipoLay:\n","                penalLayers = penalLayers + 0.8\n","              elif \"Concatenate\" in tipoLay:\n","                penalLayers = penalLayers + 0.9\n","            if penalLayers > 0:\n","              evaluated_fitness = evaluated_fitness + 10.0 - (penalLayers / 10.0)\n","        return round(evaluated_fitness, 5)\n","    \n","    def return_MaxFitness(self) -> float:\n","      # devuelve valor máximo posible para la aptitud\n","      if self.calcFitness ==  \"S\":\n","        valMaxFit = 200.0\n","      else:\n","        valMaxFit = 100.0\n","      if self.penalFitness:\n","        valMaxFit = valMaxFit + 10\n","      return valMaxFit\n","\n","    def _eval_genome_fitness_weight_training(self, genome) -> float:\n","        \"\"\"\n","        Evaluates the genome's fitness by obtaining the associated Tensorflow model and optimizer, \n","        compiling them and then training them for the config specified duration.      \n","        @param genome: TFNE compatible genome that is to be evaluated\n","        @return: genome calculated fitness\n","        \"\"\"\n","        # Get model and optimizer required for compilation\n","        model = genome.get_model()\n","        optimizer = genome.get_optimizer()\n","\n","        # si corresponde incrementa la cantidad de épocas\n","        gen_id = genome.get_id()\n","        if gen_id > self.increase_epochs_every_n_genomes:\n","          cantEpochsIncr = int((gen_id / self.increase_epochs_every_n_genomes) * self.increase_epochs_add_epochs)\n","          cant_epochs = self.epochs + cantEpochsIncr\n","          #print(\"  > \", gen_id, self.epochs, cantEpochsIncr, cant_epochs)\n","        else:\n","          cant_epochs = self.epochs\n","\n","        # Compile and train model\n","        model.compile(optimizer=optimizer, \n","                      loss='categorical_crossentropy', metrics=['accuracy'])\n","                      #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))        \n","        model.fit(x=self.x_train, \n","                  y=self.y_trainEnc, \n","                  epochs=cant_epochs, \n","                  batch_size=self.batch_size, \n","                  verbose=self.verbosity)\n","\n","        # Evaluate and return its fitness\n","        return self._calculate_fitness(model, self.penalFitness)\n","\n","    def _eval_genome_fitness_non_weight_training(self, genome) -> float:\n","        raise NotImplementedError(\"Non-Weight training evaluation not yet implemented for Environment\")\n","\n","    def replay_genome(self, genome):\n","        \"\"\"\n","        Replay genome on environment by calculating its fitness and printing it.\n","        @param genome: TFNE compatible genome that is to be evaluated\n","        \"\"\"\n","        print(\"> Probando Genome #{}:\".format(genome.get_id()))\n","\n","        # Determine fitness by creating model predictions with test images and then judging the fitness based on the\n","        # achieved model accuracy.\n","        model = genome.get_model()\n","        evaluated_fitness = self._calculate_fitness(model, False)\n","        print(\"  Aptitud lograda:\\t{}\\n\".format(evaluated_fitness))\n","\n","    def duplicate(self) -> RNAEnvironment:\n","        \"\"\"\n","        @return: New instance of the environment with identical parameters\n","        \"\"\"\n","        x = self.x_train.extend(self.x_val)\n","        y = self.y_train.extend(self.y_val)\n","        if hasattr(self, 'epochs'):\n","            return RNAEnvironment(True, data_x=x, data_y=y, verbosity=self.verbosity, epochs=self.epochs, batch_size=self.batch_size)\n","        else:\n","            return RNAEnvironment(False, data_x=x, data_y=y, verbosity=self.verbosity)\n","\n","    def get_input_shape(self) -> (int,):\n","        \"\"\"\"\"\"\n","        return (self.cantX,)\n","\n","    def get_output_shape(self) -> (int,):\n","        \"\"\"\"\"\"\n","        return (self.cantY,)\n","\n","print(\"Clase RNAEnvironment definida\")"]},{"cell_type":"markdown","metadata":{"id":"USZcQIWbIpEY"},"source":["3) Ejecutar NeuroEvolution:"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"kHIt18d-AUTc"},"outputs":[],"source":["#@title Ejecutar NeuroEvolution\n","\n","logging_level = logging.INFO\n","config_file_path = confFileName # './codeepneat_xor_basic_example_config.cfg'\n","backup_dir_path = './tfne_state_backups/'\n","max_generations = ce_maximo_generaciones_procesar\n","\n","# Set logging, parse config\n","logging.set_verbosity(logging_level)\n","config = tfne.parse_configuration(config_file_path)\n","\n","# Initialize the environment and the specific NE algorithm\n","environment = RNAEnvironment(weight_training=True, \n","                             data_x=x_train,\n","                             data_y=y_train,\n","                             config=config, \n","                             verbosity=logging_level)\n","\n","print(\">  Definiendo configuración:\")\n","ne_algorithm = tfne.algorithms.CoDeepNEAT(config)\n","\n","# determina si termina por alcanzar la máxima o no\n","if ce_finalizar_al_encontrar_max_fitness:\n","  max_fitness = environment.return_MaxFitness()\n","else:\n","  max_fitness = None\n","\n","\n","# Initialize evolution engine and supply config as well as initialized NE algorithm and evaluation environment.\n","engine = tfne.EvolutionEngine(ne_algorithm=ne_algorithm,\n","                              environment=environment,\n","                              backup_dir_path=backup_dir_path,\n","                              max_generations=max_generations,\n","                              max_fitness=max_fitness)\n","\n","# Start training process, returning the best genome when training ends\n","best_genome = engine.train()\n","print(\"\\n> Mejor RNA generada por la evolución:\\n\")\n","print(best_genome)\n","print(\"\\n\")\n","\n","# Graba mejor genotipo y su modelo TF antes del re-entrenamiento\n","best_genotype_ori_dir = './best_genome_genotype_ori/'\n","best_model_ori_dir = './best_genome_model_ori/'\n","best_genome.save_genotype(save_dir_path=best_genotype_ori_dir)\n","best_genome.save_model(file_path=best_model_ori_dir)\n","\n","# Re-entrena mejor genotipo para ver si mejora\n","print(\"\\n\\n\")\n","environment.epochs = rna_cant_epocas_reentrenamiento_best_final\n","print(\"> Re-entrenando mejor RNA por \"+str(environment.epochs)+\" épocas...\\n\")\n","environment.eval_genome_fitness(best_genome)\n","environment.replay_genome(best_genome)\n","\n","# Graba mejor genotipo y su modelo TF después del re-entrenamiento\n","print(\"\\n\")\n","best_genotype_new_dir = './best_genome_genotype/'\n","best_model_new_dir = './best_genome_model/'\n","best_genome.save_genotype(save_dir_path=best_genotype_new_dir)\n","best_genome.save_model(file_path=best_model_new_dir)\n"]},{"cell_type":"markdown","metadata":{"id":"s30bw_ff7Zj4"},"source":["4) Evaluar el modelo de la RNA generada:"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"dDr_EuIkNnI-"},"outputs":[],"source":["#@title Cargar modelo de mejor genoma de RNA generada\n","\n","usar_modelo = \"Original\" #@param [\"Original\", \"Re-Entrenado\"]\n","\n","if usar_modelo == \"Original\":\n","  best_model_dir = best_model_ori_dir\n","else:\n","  best_model_dir= best_model_new_dir\n","\n","modelRNA = tf.keras.models.load_model(best_model_dir)\n","print(\"\\nModelo recuperado de \", best_model_dir)\n","\n","print(\"\\n\")\n","modelRNA.summary()\n","print(\"\\n\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"kVDw0-o-Oca0"},"outputs":[],"source":["#@title Probar RNA con datos de entrenamiento\n","mostrar_detalle_imagenes_entrenamiento = False #@param {type:\"boolean\"}\n","\n","# función auxiliar para probar el modelo entrenado en detalle\n","def probarModelo(x, y, esDAimag, clases_map, mostrarImagenes=False):\n","\n","    # procesa las imágenes de prueba con el modelo \n","    predClass = modelRNA.predict(x)\n","\n","    # muestra los resultados con las imágenes \n","    umbralClas = 0.5\n","    classPreds = []\n","    classReal = []\n","    for i in range(len(x)):\n","\n","        # asigna el nombre de la clase real\n","        clReal = clases_map[ y[i] ] \n","\n","        # determina la clase predecida\n","        if tipo_output_softMax:\n","            ## determina clase predecida de acuerdo a la que tiene mayor valor\n","            idclPred = int( np.argmax(predClass[i], axis=0) )\n","            idclPredRnd = idclPred\n","        else:\n","            ## determina clase predecida de acuerdo al umbral de clasificación\n","            idclPred = predClass[i][0]       \n","            idclPredRnd = int(idclPred)\n","            if (idclPred - idclPredRnd)>0.5 and (idclPredRnd+1)<len(clases_map):\n","                    idclPredRnd = idclPredRnd + 1\n","\n","        # asigna el nombre de la clase predecida\n","        if idclPredRnd<0 or idclPredRnd>=len(clases_map):\n","            clPred = \"CLASE \" + str(idclPredRnd) + \" INVÁLIDA!\"\n","        else:      \n","            clPred = clases_map[ idclPredRnd ]\n","\n","        # agrega a vevtores auxiliares\n","        classReal.append( clReal )\n","        classPreds.append( clPred )\n","\n","        # sólo muestra las imágenes no generadas por DA\n","        if mostrarImagenes:\n","          strTitulo = 'Real: ' + clReal + ' / RNA: ' \n","          strTitulo = strTitulo + clPred + ' (' + str( idclPred ) +')'    \n","\n","          # muestra comparación con la imagen\n","          fig = plt.figure()\n","          fig.suptitle( strTitulo )\n","          ax1 = fig.add_subplot(121)\n","          plot_image( x[i] )\n","          \n","          plt.tight_layout()\n","          fig = plt.gcf()\n","\n","    # muestra reporte de clasificación\n","    print(\"\\n Reporte de Clasificación: \")\n","    print(classification_report(classReal, classPreds))\n","\n","    # muestra matriz de confusion\n","    print('\\nMatriz de Confusión: ')\n","    cm = confusion_matrix(classReal, classPreds, labels=clases_map)\n","    cmtx = pd.DataFrame(\n","        cm, \n","        index=['r:{:}'.format(x) for x in clases_map], \n","        columns=['p:{:}'.format(x) for x in clases_map]\n","      )\n","    print(cmtx)\n","    print(\"\\n\")\n","\n","    if mostrarImagenes:\n","      print(\"\\n>Resultados: \")\n","\n","\n","# prueba con los datos de entrenamiento\n","print(\"*** Resultados con datos de Entrenamiento: \")\n","probarModelo(x_train, y_train, esDAimag_train, clases_map, mostrar_detalle_imagenes_entrenamiento)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"OoQ7iOSdQF30"},"outputs":[],"source":["#@title Probar RNA con datos de prueba\n","\n","mostrar_detalle_imagenes_prueba = False #@param {type:\"boolean\"}\n"," \n","print(\"*** Resultados con datos de Prueba: \")\n","probarModelo(x_test, y_test, esDAimag_train, clases_map, mostrar_detalle_imagenes_prueba)\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"NeuroEvolution-clasificar-imagenes.ipynb","toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyMlRELSyKOoWOuV1tib56LQ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}